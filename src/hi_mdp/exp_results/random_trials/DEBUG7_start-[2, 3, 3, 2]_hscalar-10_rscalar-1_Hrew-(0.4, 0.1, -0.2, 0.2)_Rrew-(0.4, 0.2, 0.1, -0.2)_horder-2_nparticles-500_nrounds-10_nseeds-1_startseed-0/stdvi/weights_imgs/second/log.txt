
ROUND = 0


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.2, 0.1, -0.2), 1, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.8  0.4  0.2 -0.4]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((0.4, 0.1, -0.2, 0.2), 0.041666666666666664, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.07692137673589498, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.13186209709533608, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.13186209709533608
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.13186209709533608, False)
Robot's weighted accuracy = 0.12803727025116432
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.1431384432108643, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.1431384432108643
True human's belief of robot = ((0.4, 0.2, -0.2, 0.1), 0.1431384432108643, False)
Robot's weighted accuracy = 0.14141787683720375
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.18467048813678866, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.18467048813678866
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.18467048813678866, False)
Robot's weighted accuracy = 0.14141787683720375
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 1


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.14141787683720375)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.14141787683720375
True human's confidence = 0.17582426379071342, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.14141787683720375
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.21467200525425223, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.21467200525425223
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.21467200525425223, False)
Robot's weighted accuracy = 0.18299437925837952
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.22090995515579123, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.22090995515579123
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.22090995515579123, False)
Robot's weighted accuracy = 0.191723156972874
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.2205878893630447, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2205878893630447
True human's belief of robot = ((0.4, 0.2, -0.2, 0.1), 0.2205878893630447, False)
Robot's weighted accuracy = 0.1939604081600521
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.2188823998416991, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2188823998416991
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2188823998416991, False)
Robot's weighted accuracy = 0.1939604081600521
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 2


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.1939604081600521)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.1939604081600521
True human's confidence = 0.269410372541252, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.1939604081600521
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.3008232212484431, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3008232212484431
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.3008232212484431, False)
Robot's weighted accuracy = 0.23834943914038628
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.2939927776102183, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.2939927776102183
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2939927776102183, False)
Robot's weighted accuracy = 0.23795241541749668
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.2873060492191718, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2873060492191718
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2873060492191718, False)
Robot's weighted accuracy = 0.23246355618196735
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.25739370403056205, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.25739370403056205
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.25739370403056205, False)
Robot's weighted accuracy = 0.23246355618196735
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 3


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.23246355618196735)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.23246355618196735
True human's confidence = 0.34934734412994317, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.23246355618196735
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.3637648292544721, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3637648292544721
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.3637648292544721, False)
Robot's weighted accuracy = 0.2781212008134219
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.3469849456477825, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3469849456477825
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3469849456477825, False)
Robot's weighted accuracy = 0.2711942582226876
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.35251359413111044, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.35251359413111044
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.35251359413111044, False)
Robot's weighted accuracy = 0.2606286742837384
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.3264454150645636, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.3264454150645636
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3264454150645636, False)
Robot's weighted accuracy = 0.2606286742837384
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 4


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.2606286742837384)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.2606286742837384
True human's confidence = 0.4145260544807752, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.2606286742837384
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4060498746140517, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4060498746140517
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.4060498746140517, False)
Robot's weighted accuracy = 0.30638997180359645
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.38252439083411727, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.38252439083411727
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.38252439083411727, False)
Robot's weighted accuracy = 0.29539604263871005
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.40743054362474723, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.40743054362474723
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.40743054362474723, False)
Robot's weighted accuracy = 0.2817977318782844
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.3888966263073312, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.3888966263073312
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3888966263073312, False)
Robot's weighted accuracy = 0.2817977318782844
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 5


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.2817977318782844)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.2817977318782844
True human's confidence = 0.4669287740994695, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.2817977318782844
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.43230440312430934, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.43230440312430934
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.43230440312430934, False)
Robot's weighted accuracy = 0.3269848899035703
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.41819324308941136, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.41819324308941136
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.41819324308941136, False)
Robot's weighted accuracy = 0.3136647080978556
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.45317163803870275, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.45317163803870275
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.45317163803870275, False)
Robot's weighted accuracy = 0.2983895123051785
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.4436452640060059, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.4436452640060059
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4436452640060059, False)
Robot's weighted accuracy = 0.2983895123051785
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 6


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.2983895123051785)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.2983895123051785
True human's confidence = 0.5091324623286633, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.2983895123051785
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4467917965474878, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4467917965474878
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4467917965474878, False)
Robot's weighted accuracy = 0.3426108714921063
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.4553431557294343, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4553431557294343
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4553431557294343, False)
Robot's weighted accuracy = 0.3281026458605567
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.4913037293373896, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.4913037293373896
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4913037293373896, False)
Robot's weighted accuracy = 0.3120184098652239
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.490679185090015, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.490679185090015
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.490679185090015, False)
Robot's weighted accuracy = 0.3120184098652239
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 7


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.3120184098652239)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.3120184098652239
True human's confidence = 0.5435617495231347, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.3120184098652239
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4528651163384191, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4528651163384191
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4528651163384191, False)
Robot's weighted accuracy = 0.3550536994327815
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.4867782878551217, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4867782878551217
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4867782878551217, False)
Robot's weighted accuracy = 0.34007535457338095
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5233845888606414, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5233845888606414
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5233845888606414, False)
Robot's weighted accuracy = 0.4278277518063144
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5306618273408682, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5306618273408682
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5306618273408682, False)
Robot's weighted accuracy = 0.4278277518063144
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 8


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.4278277518063144)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.4278277518063144
True human's confidence = 0.5721964521864287, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.4278277518063144
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.47649917892448046, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.47649917892448046
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.47649917892448046, False)
Robot's weighted accuracy = 0.47893514122923075
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.513820251884584, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.513820251884584
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.513820251884584, False)
Robot's weighted accuracy = 0.4607727628502793
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5507595913065324, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5507595913065324
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5507595913065324, False)
Robot's weighted accuracy = 0.541805348137674
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5645710701039597, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5645710701039597
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5645710701039597, False)
Robot's weighted accuracy = 0.541805348137674
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 9


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.541805348137674)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.541805348137674
True human's confidence = 0.596542439292667, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.541805348137674
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4999156692131639, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4999156692131639
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4999156692131639, False)
Robot's weighted accuracy = 0.5968847865217658
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.5375035882283031, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.5375035882283031
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5375035882283031, False)
Robot's weighted accuracy = 0.5771019601847676
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5745154102855833, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5745154102855833
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5745154102855833, False)
Robot's weighted accuracy = 0.6418684648811048
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5934555856716844, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5934555856716844
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5934555856716844, False)
Robot's weighted accuracy = 0.6418684648811048
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5
