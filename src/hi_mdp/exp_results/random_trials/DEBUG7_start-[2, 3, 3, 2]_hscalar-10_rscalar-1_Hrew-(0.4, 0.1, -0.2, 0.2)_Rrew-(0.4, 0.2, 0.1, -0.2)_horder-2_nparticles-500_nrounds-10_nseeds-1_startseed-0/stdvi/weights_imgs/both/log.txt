
ROUND = 0


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.2, 0.1, -0.2), 0, 0.020833333333333332)
Robot's own rewards + human pref = [ 0.8  0.4  0.2 -0.4]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((0.4, 0.1, -0.2, 0.2), 0.041666666666666664, False)
Robot's weighted accuracy = 0.020833333333333332
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.07692137673589498, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.13186209709533608, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.13186209709533608
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.13186209709533608, False)
Robot's weighted accuracy = 0.06401863512558216
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.1431384432108643, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.1431384432108643
True human's belief of robot = ((0.4, 0.2, -0.2, 0.1), 0.1431384432108643, False)
Robot's weighted accuracy = 0.07070893841860187
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.18467048813678866, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.18467048813678866
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.18467048813678866, False)
Robot's weighted accuracy = 0.07070893841860187
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 1


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.07070893841860187)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.07070893841860187
True human's confidence = 0.17582426379071342, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.07070893841860187
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.21467200525425223, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.21467200525425223
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.21467200525425223, False)
Robot's weighted accuracy = 0.09149718962918978
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.22090995515579123, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.22090995515579123
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.22090995515579123, False)
Robot's weighted accuracy = 0.095861578486437
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.2205878893630447, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2205878893630447
True human's belief of robot = ((0.4, 0.2, -0.2, 0.1), 0.2205878893630447, False)
Robot's weighted accuracy = 0.09698020408002608
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.2188823998416991, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2188823998416991
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2188823998416991, False)
Robot's weighted accuracy = 0.09698020408002608
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 2


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.09698020408002608)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.09698020408002608
True human's confidence = 0.269410372541252, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.09698020408002608
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.3008232212484431, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3008232212484431
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.3008232212484431, False)
Robot's weighted accuracy = 0.11917471957019318
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.2939927776102183, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.2939927776102183
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2939927776102183, False)
Robot's weighted accuracy = 0.11897620770874834
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.2873060492191718, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.2873060492191718
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.2873060492191718, False)
Robot's weighted accuracy = 0.11623177809098367
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.25739370403056205, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.25739370403056205
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.25739370403056205, False)
Robot's weighted accuracy = 0.11623177809098367
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 3


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.11623177809098367)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.11623177809098367
True human's confidence = 0.34934734412994317, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.11623177809098367
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.3637648292544721, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3637648292544721
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.3637648292544721, False)
Robot's weighted accuracy = 0.139060600406711
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.3469849456477825, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.3469849456477825
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3469849456477825, False)
Robot's weighted accuracy = 0.13559712911134375
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.35251359413111044, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.35251359413111044
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.35251359413111044, False)
Robot's weighted accuracy = 0.13031433714186924
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.3264454150645636, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.3264454150645636
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3264454150645636, False)
Robot's weighted accuracy = 0.13031433714186924
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 4


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.13031433714186924)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.13031433714186924
True human's confidence = 0.4145260544807752, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.13031433714186924
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4060498746140517, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4060498746140517
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.4060498746140517, False)
Robot's weighted accuracy = 0.15319498590179817
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.38252439083411727, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.38252439083411727
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.38252439083411727, False)
Robot's weighted accuracy = 0.14769802131935503
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.40743054362474723, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.40743054362474723
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.40743054362474723, False)
Robot's weighted accuracy = 0.1408988659391422
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.3888966263073312, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.3888966263073312
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.3888966263073312, False)
Robot's weighted accuracy = 0.1408988659391422
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 5


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.1408988659391422)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.1408988659391422
True human's confidence = 0.4669287740994695, confidence scalar = 0.0
True human's acting weight vector = [0.4, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.1408988659391422
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.43230440312430934, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.43230440312430934
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.43230440312430934, False)
Robot's weighted accuracy = 0.16349244495178517
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.41819324308941136, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.41819324308941136
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.41819324308941136, False)
Robot's weighted accuracy = 0.1568323540489278
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.45317163803870275, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.45317163803870275
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.45317163803870275, False)
Robot's weighted accuracy = 0.14919475615258926
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.4436452640060059, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.4436452640060059
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4436452640060059, False)
Robot's weighted accuracy = 0.14919475615258926
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 6


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.14919475615258926)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.14919475615258926
True human's confidence = 0.5091324623286633, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.14919475615258926
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4467917965474878, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4467917965474878
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4467917965474878, False)
Robot's weighted accuracy = 0.17130543574605317
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.4553431557294343, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4553431557294343
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4553431557294343, False)
Robot's weighted accuracy = 0.16405132293027838
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.4913037293373896, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.4913037293373896
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4913037293373896, False)
Robot's weighted accuracy = 0.15600920493261192
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.490679185090015, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.490679185090015
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.490679185090015, False)
Robot's weighted accuracy = 0.15600920493261192
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 7


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 0, 0.15600920493261192)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.15600920493261192
True human's confidence = 0.5435617495231347, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.4, 0.2, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.15600920493261192
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4528651163384191, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4528651163384191
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4528651163384191, False)
Robot's weighted accuracy = 0.17752684971639074
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.4867782878551217, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4867782878551217
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4867782878551217, False)
Robot's weighted accuracy = 0.17003767728669048
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5233845888606414, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5233845888606414
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5233845888606414, False)
Robot's weighted accuracy = 0.23929630535428797
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5306618273408682, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5306618273408682
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5306618273408682, False)
Robot's weighted accuracy = 0.23929630535428797
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 8


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.23929630535428797)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.23929630535428797
True human's confidence = 0.5721964521864287, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.23929630535428797
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.47649917892448046, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.47649917892448046
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.47649917892448046, False)
Robot's weighted accuracy = 0.2688715367586724
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.513820251884584, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.513820251884584
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.513820251884584, False)
Robot's weighted accuracy = 0.25830403343888797
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5507595913065324, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5507595913065324
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5507595913065324, False)
Robot's weighted accuracy = 0.34373614638887373
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5645710701039597, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5645710701039597
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5645710701039597, False)
Robot's weighted accuracy = 0.34373614638887373
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5

ROUND = 9


Current state = [2, 3, 3, 2]
Robot's top human model = ((0.4, 0.1, -0.2, 0.2), 1, 0.34373614638887373)
Robot's own rewards + human pref = [ 0.8  0.3 -0.1  0. ]
Robot's confidence = 0.34373614638887373
True human's confidence = 0.596542439292667, confidence scalar = 1.0
True human's acting weight vector = [0.8, 0.5, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.0, False)
Robot's weighted accuracy = 0.34373614638887373
robot blue, human blue --> [0, 3, 3, 2]

Current state = [0, 3, 3, 2]
True human's confidence = 0.4999156692131639, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, -0.2, 0.2]
True human's accuracy on robot = 0.4999156692131639
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.4999156692131639, False)
Robot's weighted accuracy = 0.3810471191893353
robot green, human yellow --> [0, 2, 3, 1]

Current state = [0, 2, 3, 1]
True human's confidence = 0.5375035882283031, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, 0.2, 0.6000000000000001]
True human's accuracy on robot = 0.5375035882283031
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5375035882283031, False)
Robot's weighted accuracy = 0.36754701713702237
robot green, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.5745154102855833, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.1, None]
True human's accuracy on robot = 0.5745154102855833
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5745154102855833, False)
Robot's weighted accuracy = 0.45991504835393165
No need to update robot beliefs
robot green, human red --> [0, 0, 2, 0]

Current state = [0, 0, 2, 0]
True human's confidence = 0.5934555856716844, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.2, None]
True human's accuracy on robot = 0.5934555856716844
True human's belief of robot = ((0.2, 0.4, 0.1, -0.2), 0.5934555856716844, False)
Robot's weighted accuracy = 0.45991504835393165
No need to update robot beliefs
robot red, human red --> [0, 0, 0, 0]
final_reward = 1.5
