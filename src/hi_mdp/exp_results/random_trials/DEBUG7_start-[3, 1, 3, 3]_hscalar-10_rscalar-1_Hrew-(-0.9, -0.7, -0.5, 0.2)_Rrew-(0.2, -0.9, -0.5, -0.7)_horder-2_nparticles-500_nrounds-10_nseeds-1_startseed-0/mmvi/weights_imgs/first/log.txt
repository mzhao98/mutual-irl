
ROUND = 0


Current state = [3, 1, 3, 3]
Robot's top human model = ((0.2, -0.9, -0.5, -0.7), 0, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.4 -1.8 -1.  -1.4]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.9, -0.7, -0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.10784028605860292, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.10784028605860292
True human's belief of robot = ((0.2, -0.9, -0.7, -0.5), 0.10784028605860292, False)
Robot's weighted accuracy = 0.10666666666666667
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.14302442340300298, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.14302442340300298
True human's belief of robot = ((0.2, -0.9, -0.7, -0.5), 0.14302442340300298, False)
Robot's weighted accuracy = 0.1431167016072676
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.15811266101532642, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, None]
True human's accuracy on robot = 0.15811266101532642
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.15811266101532642, False)
Robot's weighted accuracy = 0.1750226429825083
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.316216304032006, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, None, None]
True human's accuracy on robot = 0.316216304032006
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.316216304032006, False)
Robot's weighted accuracy = 0.3151455187271184
No need to update robot beliefs
robot red, human green --> [0, 0, 0, 0]
final_reward = -0.9999999999999998

ROUND = 1


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.3151455187271184)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.3151455187271184
True human's confidence = 0.36997288749585344, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.36997288749585344
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.36997288749585344, False)
Robot's weighted accuracy = 0.3151455187271184
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.3836958169701444, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.3836958169701444
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.3836958169701444, False)
Robot's weighted accuracy = 0.3305839776347008
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.3885894854017426, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.3885894854017426
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.3885894854017426, False)
Robot's weighted accuracy = 0.3360485652620628
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.3903358672991652, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, None]
True human's accuracy on robot = 0.3903358672991652
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.3903358672991652, False)
Robot's weighted accuracy = 0.3776791537832126
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.42747741960857266, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, None, None]
True human's accuracy on robot = 0.42747741960857266
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.42747741960857266, False)
Robot's weighted accuracy = 0.4279277384858391
No need to update robot beliefs
robot red, human green --> [0, 0, 0, 0]
final_reward = -0.9999999999999998

ROUND = 2


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.4279277384858391)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.4279277384858391
True human's confidence = 0.4513573126063549, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.4513573126063549
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4513573126063549, False)
Robot's weighted accuracy = 0.4279277384858391
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.4521261060572993, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.4521261060572993
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4521261060572993, False)
Robot's weighted accuracy = 0.4295072306834033
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.4524040444742703, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.4524040444742703
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4524040444742703, False)
Robot's weighted accuracy = 0.43006996353027704
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.4525051955733627, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, None]
True human's accuracy on robot = 0.4525051955733627
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4525051955733627, False)
Robot's weighted accuracy = 0.47160677649436283
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.4682142882770463, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, None, None]
True human's accuracy on robot = 0.4682142882770463
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4682142882770463, False)
Robot's weighted accuracy = 0.4857838749699007
No need to update robot beliefs
robot red, human green --> [0, 0, 0, 0]
final_reward = -0.9999999999999998

ROUND = 3


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.4857838749699007)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.4857838749699007
True human's confidence = 0.4786866167189204, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.4786866167189204
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4786866167189204, False)
Robot's weighted accuracy = 0.4857838749699007
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.47872531222444287, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.47872531222444287
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.47872531222444287, False)
Robot's weighted accuracy = 0.485947672807288
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.47873965644380245, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.47873965644380245
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.47873965644380245, False)
Robot's weighted accuracy = 0.4860064386352193
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.47874535195968276, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, None]
True human's accuracy on robot = 0.47874535195968276
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.47874535195968276, False)
Robot's weighted accuracy = 0.5248561579952555
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.4857780145922435, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, None, None]
True human's accuracy on robot = 0.4857780145922435
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4857780145922435, False)
Robot's weighted accuracy = 0.5246978570193265
No need to update robot beliefs
robot red, human green --> [0, 0, 0, 0]
final_reward = -0.9999999999999998

ROUND = 4


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.5246978570193265)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.5246978570193265
True human's confidence = 0.4905175168182607, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.4905175168182607
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.4905175168182607, False)
Robot's weighted accuracy = 0.5246978570193265
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.49051957210698294, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.49051957210698294
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.49051957210698294, False)
Robot's weighted accuracy = 0.5247150940785335
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.49052062486524406, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.49052062486524406
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.49052062486524406, False)
Robot's weighted accuracy = 0.5247212868873282
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.49052150158624885, confidence scalar = 0.0
True human's acting weight vector = [None, -0.7, -0.5, None]
True human's accuracy on robot = 0.49052150158624885
True human's belief of robot = ((0.2, -0.9, -0.5, -0.7), 0.49052150158624885, False)
Robot's weighted accuracy = 0.5611679976440029
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.49371037920432187, confidence scalar = 0.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.5538490081837908
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997

ROUND = 5


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.5538490081837908)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.5538490081837908
True human's confidence = 0.9864672692890115, confidence scalar = 1.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9864672692890115
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9864672692890115, False)
Robot's weighted accuracy = 0.5538490081837908
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.9876009416194661, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9876009416194661
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9876009416194661, False)
Robot's weighted accuracy = 0.553850821677501
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.987601939430347, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, -0.3]
True human's accuracy on robot = 0.987601939430347
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.987601939430347, False)
Robot's weighted accuracy = 0.5538514733720268
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.9876032947916857, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, None]
True human's accuracy on robot = 0.9876032947916857
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9876032947916857, False)
Robot's weighted accuracy = 0.5884684723337735
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.9852915950652518, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.5772862623715136
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997

ROUND = 6


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.5772862623715136)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.5772862623715136
True human's confidence = 0.9960914326109972, confidence scalar = 1.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9960914326109972
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9960914326109972, False)
Robot's weighted accuracy = 0.5772862623715136
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.9961019378812177, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9961019378812177
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961019378812177, False)
Robot's weighted accuracy = 0.5772864521308892
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.9961027142266285, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, -0.3]
True human's accuracy on robot = 0.9961027142266285
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961027142266285, False)
Robot's weighted accuracy = 0.5772865203251746
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.9961039995084707, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, None]
True human's accuracy on robot = 0.9961039995084707
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961039995084707, False)
Robot's weighted accuracy = 0.610522177401578
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.9980365721137616, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.5972184438984787
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997

ROUND = 7


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.5972184438984787)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.5972184438984787
True human's confidence = 0.9960932600607217, confidence scalar = 1.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9960932600607217
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9960932600607217, False)
Robot's weighted accuracy = 0.5972184438984787
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.9961035549362918, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9961035549362918
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961035549362918, False)
Robot's weighted accuracy = 0.597218463630083
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.9961043249046737, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, -0.3]
True human's accuracy on robot = 0.9961043249046737
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961043249046737, False)
Robot's weighted accuracy = 0.5972184707211206
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.9961056078695056, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, None]
True human's accuracy on robot = 0.9961056078695056
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961056078695056, False)
Robot's weighted accuracy = 0.6293720100068096
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.9980389935273662, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.6149303132261636
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997

ROUND = 8


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.6149303132261636)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.6149303132261636
True human's confidence = 0.9960932611985365, confidence scalar = 1.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9960932611985365
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9960932611985365, False)
Robot's weighted accuracy = 0.6149303132261636
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.9961035555439208, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9961035555439208
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961035555439208, False)
Robot's weighted accuracy = 0.6149303152665154
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.9961043253326494, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, -0.3]
True human's accuracy on robot = 0.9961043253326494
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961043253326494, False)
Robot's weighted accuracy = 0.6149303159997668
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.9961056082321522, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, None]
True human's accuracy on robot = 0.9961056082321522
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961056082321522, False)
Robot's weighted accuracy = 0.6461870162484116
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.9980389940647602, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.6311876270264797
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997

ROUND = 9


Current state = [3, 1, 3, 3]
Robot's top human model = ((-0.5, -0.9, -0.7, 0.2), 0, 0.6311876270264797)
Robot's own rewards + human pref = [-0.3 -1.8 -1.2 -0.5]
Robot's confidence = 0.6311876270264797
True human's confidence = 0.9960932612204833, confidence scalar = 1.0
True human's acting weight vector = [-0.9, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.9960932612204833
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9960932612204833, False)
Robot's weighted accuracy = 0.6311876270264797
robot blue, human yellow --> [2, 1, 3, 2]

Current state = [2, 1, 3, 2]
True human's confidence = 0.996103555551943, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.7, -0.5, 0.2]
True human's accuracy on robot = 0.996103555551943
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.996103555551943, False)
Robot's weighted accuracy = 0.6311876272365092
robot blue, human yellow --> [1, 1, 3, 1]

Current state = [1, 1, 3, 1]
True human's confidence = 0.9961043253356106, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, -0.3]
True human's accuracy on robot = 0.9961043253356106
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961043253356106, False)
Robot's weighted accuracy = 0.6311876273119886
robot blue, human yellow --> [0, 1, 3, 0]

Current state = [0, 1, 3, 0]
True human's confidence = 0.9961056082332729, confidence scalar = 1.0
True human's acting weight vector = [None, -1.2, -1.0, None]
True human's accuracy on robot = 0.9961056082332729
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.9961056082332729, False)
Robot's weighted accuracy = 0.6616546241639912
robot red, human red --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.9980389940662042, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.2, -0.7, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.6464502667643663
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -1.1999999999999997
