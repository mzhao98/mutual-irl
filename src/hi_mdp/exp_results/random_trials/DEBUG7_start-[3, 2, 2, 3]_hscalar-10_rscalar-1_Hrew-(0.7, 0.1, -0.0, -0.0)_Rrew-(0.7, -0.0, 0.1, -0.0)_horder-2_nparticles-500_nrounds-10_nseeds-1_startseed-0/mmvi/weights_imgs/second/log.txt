
ROUND = 0


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.0, 0.1, 0.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [1.4 0.  0.2 0. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.7, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((0.7, 0.1, 0.0, 0.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human blue --> [1, 2, 2, 3]

Current state = [1, 2, 2, 3]
True human's confidence = 0.2916492506354745, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.2916492506354745
True human's belief of robot = ((0.7, 0.1, 0.0, 0.0), 0.2916492506354745, False)
Robot's weighted accuracy = 0.0
robot blue, human green --> [0, 1, 2, 3]

Current state = [0, 1, 2, 3]
True human's confidence = 0.3266650237486772, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.0, False)
Robot's weighted accuracy = 0.729795652880915
robot red, human green --> [0, 0, 1, 3]

Current state = [0, 0, 1, 3]
True human's confidence = 0.9797895564606062, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.0]
True human's accuracy on robot = 0.9797895564606062
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.9797895564606062, False)
Robot's weighted accuracy = 0.7370609543492935
No need to update robot beliefs
robot red, human yellow --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.9799520498843419, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.0]
True human's accuracy on robot = 0.9799520498843419
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.9799520498843419, False)
Robot's weighted accuracy = 0.7370609543492935
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 1


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.7370609543492935)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.7370609543492935
True human's confidence = 0.979936853434566, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.0, False)
Robot's weighted accuracy = 0.7370609543492935
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.8749349967169566, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.0, False)
Robot's weighted accuracy = 0.8999600422177559
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.5000956852199058, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.0, False)
Robot's weighted accuracy = 0.9215752808658911
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.8045013009120102, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, 0.0]
True human's accuracy on robot = 0.8045013009120102
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8045013009120102, False)
Robot's weighted accuracy = 0.9209478465593545
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8746988101778889, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.8746988101778889
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8746988101778889, False)
Robot's weighted accuracy = 0.9740297177221812
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 2


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.9740297177221812)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9740297177221812
True human's confidence = 0.8741688631229809, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.0, 0.7]
True human's accuracy on robot = 0.8741688631229809
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8741688631229809, False)
Robot's weighted accuracy = 0.9740297177221812
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9789610240986306, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.9789610240986306
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.9789610240986306, False)
Robot's weighted accuracy = 0.9726036625336542
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9960187587896107, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.0, False)
Robot's weighted accuracy = 0.9704278769653242
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.911339545608814, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.911339545608814
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.911339545608814, False)
Robot's weighted accuracy = 0.9679636006172943
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9679598081730724, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9679598081730724
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9679598081730724, False)
Robot's weighted accuracy = 0.9750540392424493
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 3


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.9750540392424493)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9750540392424493
True human's confidence = 0.9883060333274764, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9883060333274764
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883060333274764, False)
Robot's weighted accuracy = 0.9750540392424493
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9883200698694924, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9883200698694924
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883200698694924, False)
Robot's weighted accuracy = 0.9733175543424006
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9883225242806304, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9883225242806304
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883225242806304, False)
Robot's weighted accuracy = 0.970705163255394
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999935843602866, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999935843602866
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999935843602866, False)
Robot's weighted accuracy = 0.9678161110729141
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999944031956647, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999944031956647
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999944031956647, False)
Robot's weighted accuracy = 0.9729665398450792
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 4


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.9729665398450792)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9729665398450792
True human's confidence = 0.9999946743967619, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999946743967619
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999946743967619, False)
Robot's weighted accuracy = 0.9729665398450792
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.99999753849799, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.99999753849799
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.99999753849799, False)
Robot's weighted accuracy = 0.9709461317193696
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999984169785073, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999984169785073
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999984169785073, False)
Robot's weighted accuracy = 0.9679092426114227
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949949520562, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949949520562
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949949520562, False)
Robot's weighted accuracy = 0.9645546624758227
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949954440381, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949954440381
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949954440381, False)
Robot's weighted accuracy = 0.969326759384447
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 5


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.969326759384447)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.969326759384447
True human's confidence = 0.9999949954469531, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949954469531
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949954469531, False)
Robot's weighted accuracy = 0.969326759384447
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.999997713551442, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.999997713551442
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999997713551442, False)
Robot's weighted accuracy = 0.9669845698561192
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985711733408, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985711733408
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985711733408, False)
Robot's weighted accuracy = 0.9634670084956606
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949984454579, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949984454579
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949984454579, False)
Robot's weighted accuracy = 0.9595856704731897
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949989275355, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949989275355
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989275355, False)
Robot's weighted accuracy = 0.964642624267837
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 6


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.964642624267837)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.964642624267837
True human's confidence = 0.9999949989275267, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949989275267
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989275267, False)
Robot's weighted accuracy = 0.964642624267837
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140503656, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140503656
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140503656, False)
Robot's weighted accuracy = 0.9619335145503187
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712462696, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712462696
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712462696, False)
Robot's weighted accuracy = 0.9578688993598586
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985164803, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985164803
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985164803, False)
Robot's weighted accuracy = 0.9533894991201841
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949989985687, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949989985687
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989985687, False)
Robot's weighted accuracy = 0.9590478083899794
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 7


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.9590478083899794)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9590478083899794
True human's confidence = 0.9999949989985707, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949989985707
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989985707, False)
Robot's weighted accuracy = 0.9590478083899794
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.999997714060516, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.999997714060516
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999997714060516, False)
Robot's weighted accuracy = 0.9559205832606487
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477197, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477197
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477197, False)
Robot's weighted accuracy = 0.9512339652275167
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985179308, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985179308
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985179308, False)
Robot's weighted accuracy = 0.9460764691337687
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000193, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000193
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000193, False)
Robot's weighted accuracy = 0.9525239594727495
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 8


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.9525239594727495)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9525239594727495
True human's confidence = 0.9999949990000218, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949990000218
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000218, False)
Robot's weighted accuracy = 0.9525239594727495
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140607232, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140607232
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140607232, False)
Robot's weighted accuracy = 0.9489216174629018
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477493, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477493
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477493, False)
Robot's weighted accuracy = 0.9435300117976048
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985179604, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985179604
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985179604, False)
Robot's weighted accuracy = 0.9376064463520329
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000488, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000488
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000488, False)
Robot's weighted accuracy = 0.944986928937163
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 9


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 1, 0.944986928937163)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.944986928937163
True human's confidence = 0.9999949990000513, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949990000513
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000513, False)
Robot's weighted accuracy = 0.944986928937163
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140607275, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140607275
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140607275, False)
Robot's weighted accuracy = 0.9408468855576714
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477499, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477499
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477499, False)
Robot's weighted accuracy = 0.9346598010920877
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.999994998517961, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.999994998517961
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999994998517961, False)
Robot's weighted accuracy = 0.9278750895070668
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000495, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000495
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000495, False)
Robot's weighted accuracy = 0.9363205390624448
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5
