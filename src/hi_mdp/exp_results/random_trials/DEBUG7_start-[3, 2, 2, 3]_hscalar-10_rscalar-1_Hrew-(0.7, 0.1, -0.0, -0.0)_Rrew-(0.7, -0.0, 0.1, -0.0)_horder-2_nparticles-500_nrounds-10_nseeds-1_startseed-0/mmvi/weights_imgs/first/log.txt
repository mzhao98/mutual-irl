
ROUND = 0


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.0, 0.1, 0.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [1.4 0.  0.2 0. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.7, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((0.7, 0.1, 0.0, 0.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human blue --> [1, 2, 2, 3]

Current state = [1, 2, 2, 3]
True human's confidence = 0.2916492506354745, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.2916492506354745
True human's belief of robot = ((0.7, 0.1, 0.0, 0.0), 0.2916492506354745, False)
Robot's weighted accuracy = 0.0
robot blue, human green --> [0, 1, 2, 3]

Current state = [0, 1, 2, 3]
True human's confidence = 0.3266650237486772, confidence scalar = 0.0
True human's acting weight vector = [None, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.0, False)
Robot's weighted accuracy = 0.729795652880915
robot red, human green --> [0, 0, 1, 3]

Current state = [0, 0, 1, 3]
True human's confidence = 0.9797895564606062, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.0]
True human's accuracy on robot = 0.9797895564606062
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.9797895564606062, False)
Robot's weighted accuracy = 0.801669980398777
No need to update robot beliefs
robot red, human yellow --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.9799520498843419, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.0]
True human's accuracy on robot = 0.9799520498843419
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.9799520498843419, False)
Robot's weighted accuracy = 0.801669980398777
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 1


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.801669980398777)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.801669980398777
True human's confidence = 0.979936853434566, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, 0.0, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.7, 0.0, 0.1, 0.0), 0.0, False)
Robot's weighted accuracy = 0.801669980398777
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.8749349967169566, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.0, False)
Robot's weighted accuracy = 0.9585182738903318
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.5000956852199058, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.0, False)
Robot's weighted accuracy = 0.9814820077558033
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.8045013009120102, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, 0.0]
True human's accuracy on robot = 0.8045013009120102
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8045013009120102, False)
Robot's weighted accuracy = 0.9839457129899776
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8746988101778889, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.8746988101778889
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8746988101778889, False)
Robot's weighted accuracy = 0.995363425908375
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 2


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.995363425908375)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.995363425908375
True human's confidence = 0.8741688631229809, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.0, 0.7]
True human's accuracy on robot = 0.8741688631229809
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.8741688631229809, False)
Robot's weighted accuracy = 0.995363425908375
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9789610240986306, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.9789610240986306
True human's belief of robot = ((0.1, 0.0, 0.7, 0.0), 0.9789610240986306, False)
Robot's weighted accuracy = 0.9959266092419198
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9960187587896107, confidence scalar = 1.0
True human's acting weight vector = [0.7, 0.1, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.0, False)
Robot's weighted accuracy = 0.9955823493682423
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.911339545608814, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.911339545608814
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.911339545608814, False)
Robot's weighted accuracy = 0.9951173630246051
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9679598081730724, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9679598081730724
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9679598081730724, False)
Robot's weighted accuracy = 0.9982703084913227
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 3


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9982703084913227)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9982703084913227
True human's confidence = 0.9883060333274764, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9883060333274764
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883060333274764, False)
Robot's weighted accuracy = 0.9982703084913227
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9883200698694924, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9883200698694924
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883200698694924, False)
Robot's weighted accuracy = 0.9982721757333526
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9883225242806304, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9883225242806304
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9883225242806304, False)
Robot's weighted accuracy = 0.9980629168774293
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999935843602866, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999935843602866
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999935843602866, False)
Robot's weighted accuracy = 0.9978273539553203
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999944031956647, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999944031956647
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999944031956647, False)
Robot's weighted accuracy = 0.9991686651195864
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 4


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9991686651195864)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9991686651195864
True human's confidence = 0.9999946743967619, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999946743967619
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999946743967619, False)
Robot's weighted accuracy = 0.9991686651195864
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.99999753849799, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.99999753849799
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.99999753849799, False)
Robot's weighted accuracy = 0.9991686735859518
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999984169785073, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999984169785073
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999984169785073, False)
Robot's weighted accuracy = 0.9990653573939469
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949949520562, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949949520562
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949949520562, False)
Robot's weighted accuracy = 0.998949151400354
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949954440381, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949954440381
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949954440381, False)
Robot's weighted accuracy = 0.9995923009918126
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 5


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9995923009918126)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9995923009918126
True human's confidence = 0.9999949954469531, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949954469531
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949954469531, False)
Robot's weighted accuracy = 0.9995923009918126
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.999997713551442, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.999997713551442
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999997713551442, False)
Robot's weighted accuracy = 0.9995923011366731
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985711733408, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985711733408
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985711733408, False)
Robot's weighted accuracy = 0.9995414039829111
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949984454579, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949984454579
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949984454579, False)
Robot's weighted accuracy = 0.9994841508771939
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949989275355, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949989275355
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989275355, False)
Robot's weighted accuracy = 0.9997994310368019
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 6


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9997994310368019)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9997994310368019
True human's confidence = 0.9999949989275267, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949989275267
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989275267, False)
Robot's weighted accuracy = 0.9997994310368019
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140503656, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140503656
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140503656, False)
Robot's weighted accuracy = 0.9997994310428784
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712462696, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712462696
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712462696, False)
Robot's weighted accuracy = 0.999774369067293
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985164803, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985164803
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985164803, False)
Robot's weighted accuracy = 0.9997461758465548
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949989985687, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949989985687
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989985687, False)
Robot's weighted accuracy = 0.9999012838191453
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 7


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9999012838191453)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9999012838191453
True human's confidence = 0.9999949989985707, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949989985707
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949989985707, False)
Robot's weighted accuracy = 0.9999012838191453
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.999997714060516, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.999997714060516
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999997714060516, False)
Robot's weighted accuracy = 0.9999012838194323
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477197, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477197
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477197, False)
Robot's weighted accuracy = 0.9998889459578735
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985179308, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985179308
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985179308, False)
Robot's weighted accuracy = 0.9998750662275577
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000193, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000193
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000193, False)
Robot's weighted accuracy = 0.9999514116449074
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 8


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9999514116449074)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9999514116449074
True human's confidence = 0.9999949990000218, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949990000218
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000218, False)
Robot's weighted accuracy = 0.9999514116449074
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140607232, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140607232
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140607232, False)
Robot's weighted accuracy = 0.9999514116449211
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477493, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477493
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477493, False)
Robot's weighted accuracy = 0.9999453384567494
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.9999949985179604, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.9999949985179604
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949985179604, False)
Robot's weighted accuracy = 0.9999385062082347
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000488, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000488
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000488, False)
Robot's weighted accuracy = 0.9999760849081424
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5

ROUND = 9


Current state = [3, 2, 2, 3]
Robot's top human model = ((0.7, 0.1, 0.0, 0.0), 0, 0.9999760849081424)
Robot's own rewards + human pref = [1.4 0.1 0.1 0. ]
Robot's confidence = 0.9999760849081424
True human's confidence = 0.9999949990000513, confidence scalar = 1.0
True human's acting weight vector = [1.4, 0.7999999999999999, 0.1, 0.7]
True human's accuracy on robot = 0.9999949990000513
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000513, False)
Robot's weighted accuracy = 0.9999760849081424
robot red, human blue --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.9999977140607275, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999977140607275
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999977140607275, False)
Robot's weighted accuracy = 0.9999760849081429
robot red, human blue --> [1, 2, 0, 3]

Current state = [1, 2, 0, 3]
True human's confidence = 0.9999985712477499, confidence scalar = 1.0
True human's acting weight vector = [0.7999999999999999, 0.2, None, 0.1]
True human's accuracy on robot = 0.9999985712477499
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999985712477499, False)
Robot's weighted accuracy = 0.9999730956041073
robot yellow, human blue --> [0, 2, 0, 2]

Current state = [0, 2, 0, 2]
True human's confidence = 0.999994998517961, confidence scalar = 1.0
True human's acting weight vector = [None, 0.2, None, 0.0]
True human's accuracy on robot = 0.999994998517961
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.999994998517961, False)
Robot's weighted accuracy = 0.99996973265843
robot yellow, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.9999949990000495, confidence scalar = 1.0
True human's acting weight vector = [None, 0.1, None, None]
True human's accuracy on robot = 0.9999949990000495
True human's belief of robot = ((0.0, 0.0, 0.7, 0.1), 0.9999949990000495, False)
Robot's weighted accuracy = 0.9999882291543801
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.5
