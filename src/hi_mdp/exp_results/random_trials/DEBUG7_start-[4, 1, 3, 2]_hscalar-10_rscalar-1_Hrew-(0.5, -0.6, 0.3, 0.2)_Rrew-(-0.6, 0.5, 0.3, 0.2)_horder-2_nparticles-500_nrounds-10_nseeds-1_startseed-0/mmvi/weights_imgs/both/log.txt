
ROUND = 0


Current state = [4, 1, 3, 2]
Robot's top human model = ((-0.6, 0.5, 0.3, 0.2), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.2  1.   0.6  0.4]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.06547558841383189, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.06547558841383189
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.06547558841383189, False)
Robot's weighted accuracy = 0.03581242339082447
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.10398907547755748, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.10398907547755748
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.10398907547755748, False)
Robot's weighted accuracy = 0.0452349494892209
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.10877675027694751, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.10877675027694751
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.10877675027694751, False)
Robot's weighted accuracy = 0.054535917510768646
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.12033153649473989, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.12033153649473989
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.12033153649473989, False)
Robot's weighted accuracy = 0.07426821499820932
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 1


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.07426821499820932)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.07426821499820932
True human's confidence = 0.19052121727579796, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.07426821499820932
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.20656546086918964, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.20656546086918964
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.20656546086918964, False)
Robot's weighted accuracy = 0.08544249032200539
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.21157204951100836, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.21157204951100836
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.21157204951100836, False)
Robot's weighted accuracy = 0.09633117484794596
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.2246340514141892, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.2246340514141892
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.2246340514141892, False)
Robot's weighted accuracy = 0.10682338941105413
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.2468309040842449, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.2468309040842449
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.2468309040842449, False)
Robot's weighted accuracy = 0.12891239603486182
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 2


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.12891239603486182)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.12891239603486182
True human's confidence = 0.2915907987474311, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.12891239603486182
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.29249727028476097, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.29249727028476097
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.29249727028476097, False)
Robot's weighted accuracy = 0.14032295624250193
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.29949468365304777, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.29949468365304777
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.29949468365304777, False)
Robot's weighted accuracy = 0.15122015876856862
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.3249168301774735, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.3249168301774735
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3249168301774735, False)
Robot's weighted accuracy = 0.16159131319804398
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.3500920052561526, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.3500920052561526
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3500920052561526, False)
Robot's weighted accuracy = 0.181720130505025
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 3


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.181720130505025)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.181720130505025
True human's confidence = 0.3676346389960299, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.181720130505025
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.3435897746994296, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3435897746994296
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3435897746994296, False)
Robot's weighted accuracy = 0.19258485494452135
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.3693897269410021, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3693897269410021
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3693897269410021, False)
Robot's weighted accuracy = 0.2029217248406972
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.3949106210141835, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.3949106210141835
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3949106210141835, False)
Robot's weighted accuracy = 0.21275337616690768
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.4200419125321895, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.4200419125321895
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4200419125321895, False)
Robot's weighted accuracy = 0.2290995852268551
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 4


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.2290995852268551)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.2290995852268551
True human's confidence = 0.42565299843215076, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.2290995852268551
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.3968185693629657, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3968185693629657
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3968185693629657, False)
Robot's weighted accuracy = 0.2391294347895677
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.42191932282021255, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.42191932282021255
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.42191932282021255, False)
Robot's weighted accuracy = 0.24868837227065071
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.4466744595714788, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.4466744595714788
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4466744595714788, False)
Robot's weighted accuracy = 0.2578057585098083
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.4710037548896362, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.4710037548896362
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4710037548896362, False)
Robot's weighted accuracy = 0.27007807110223814
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 5


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.27007807110223814)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.27007807110223814
True human's confidence = 0.4726632599352937, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.27007807110223814
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.4402605798031974, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.4402605798031974
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4402605798031974, False)
Robot's weighted accuracy = 0.2791931226713888
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.46455903462715903, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.46455903462715903
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.46455903462715903, False)
Robot's weighted accuracy = 0.2879057384590154
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.488487618647118, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.488487618647118
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.488487618647118, False)
Robot's weighted accuracy = 0.29623985646087864
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.5119776130453078, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.5119776130453078
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5119776130453078, False)
Robot's weighted accuracy = 0.3057253401547298
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 6


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.3057253401547298)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.3057253401547298
True human's confidence = 0.5124505045094032, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.3057253401547298
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.4773457469913785, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.4773457469913785
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4773457469913785, False)
Robot's weighted accuracy = 0.3139498361369698
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.5009317650592275, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.5, 0.7]
True human's accuracy on robot = 0.5009317650592275
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5009317650592275, False)
Robot's weighted accuracy = 0.32182688633476847
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.5241277827667042, confidence scalar = 1.0
True human's acting weight vector = [0.7, None, None, 0.4]
True human's accuracy on robot = 0.5241277827667042
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5241277827667042, False)
Robot's weighted accuracy = 0.3552655261572711
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.5468692887802421, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.5468692887802421
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5468692887802421, False)
Robot's weighted accuracy = 0.3598980222667056
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 7


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 1, 0.3598980222667056)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.3598980222667056
True human's confidence = 0.5469998745013319, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.3598980222667056
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.5098515565473444, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.5098515565473444
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5098515565473444, False)
Robot's weighted accuracy = 0.3678254015945094
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.5328180303447164, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.5, 0.7]
True human's accuracy on robot = 0.5328180303447164
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5328180303447164, False)
Robot's weighted accuracy = 0.3754219180246879
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.5553690222253549, confidence scalar = 1.0
True human's acting weight vector = [0.7, None, None, 0.4]
True human's accuracy on robot = 0.5553690222253549
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5553690222253549, False)
Robot's weighted accuracy = 0.41243170494370057
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.5774420340035605, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.5774420340035605
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5774420340035605, False)
Robot's weighted accuracy = 0.4150808211476432
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 8


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 1, 0.4150808211476432)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.4150808211476432
True human's confidence = 0.5774758474546449, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.4150808211476432
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.5388236549813114, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.5388236549813114
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5388236549813114, False)
Robot's weighted accuracy = 0.42266107437571165
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.5612339988658106, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.5, 0.7]
True human's accuracy on robot = 0.5612339988658106
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5612339988658106, False)
Robot's weighted accuracy = 0.42991955312791097
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.5831976189057176, confidence scalar = 1.0
True human's acting weight vector = [0.7, None, None, 0.4]
True human's accuracy on robot = 0.5831976189057176
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5831976189057176, False)
Robot's weighted accuracy = 0.4673953332927993
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.6046538084301636, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.6046538084301636
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6046538084301636, False)
Robot's weighted accuracy = 0.4686726579156319
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 9


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 1, 0.4686726579156319)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.4686726579156319
True human's confidence = 0.604660560454865, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.4686726579156319
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.564967121753273, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.8, 0.7]
True human's accuracy on robot = 0.564967121753273
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.564967121753273, False)
Robot's weighted accuracy = 0.4758153069603984
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.5868581814542878, confidence scalar = 1.0
True human's acting weight vector = [1.0, None, 0.5, 0.7]
True human's accuracy on robot = 0.5868581814542878
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5868581814542878, False)
Robot's weighted accuracy = 0.48264426718352654
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.6082672569732608, confidence scalar = 1.0
True human's acting weight vector = [0.7, None, None, 0.4]
True human's accuracy on robot = 0.6082672569732608
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6082672569732608, False)
Robot's weighted accuracy = 0.5198649622632998
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.6291359357392162, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.6291359357392162
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6291359357392162, False)
Robot's weighted accuracy = 0.5202415016296916
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003
