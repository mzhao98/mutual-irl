
ROUND = 0


Current state = [4, 1, 3, 2]
Robot's top human model = ((-0.6, 0.5, 0.3, 0.2), 0, 0.041666666666666664)
Robot's own rewards + human pref = [-1.2  1.   0.6  0.4]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.06547558841383189, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.06547558841383189
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.06547558841383189, False)
Robot's weighted accuracy = 0.0716248467816489
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.10398907547755748, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.10398907547755748
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.10398907547755748, False)
Robot's weighted accuracy = 0.09046989897844179
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.10877675027694751, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.10877675027694751
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.10877675027694751, False)
Robot's weighted accuracy = 0.10907183502153728
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.12033153649473989, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.12033153649473989
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.12033153649473989, False)
Robot's weighted accuracy = 0.1485364299964186
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 1


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.1485364299964186)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.1485364299964186
True human's confidence = 0.19052121727579796, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.1485364299964186
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.20656546086918964, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.20656546086918964
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.20656546086918964, False)
Robot's weighted accuracy = 0.1708849806440108
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.21157204951100836, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.21157204951100836
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.21157204951100836, False)
Robot's weighted accuracy = 0.19266234969589185
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.2246340514141892, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.2246340514141892
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.2246340514141892, False)
Robot's weighted accuracy = 0.21364677882210825
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.2468309040842449, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.2468309040842449
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.2468309040842449, False)
Robot's weighted accuracy = 0.25782479206972353
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 2


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.25782479206972353)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.25782479206972353
True human's confidence = 0.2915907987474311, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.5, 0.3, 0.2), 0.0, False)
Robot's weighted accuracy = 0.25782479206972353
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.29249727028476097, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.29249727028476097
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.29249727028476097, False)
Robot's weighted accuracy = 0.2806459124850038
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.29949468365304777, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.29949468365304777
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.29949468365304777, False)
Robot's weighted accuracy = 0.3024403175371371
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.3249168301774735, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.3249168301774735
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3249168301774735, False)
Robot's weighted accuracy = 0.32318262639608797
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.3500920052561526, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.3500920052561526
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3500920052561526, False)
Robot's weighted accuracy = 0.3634402610100498
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 3


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.3634402610100498)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.3634402610100498
True human's confidence = 0.3676346389960299, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.3634402610100498
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.3435897746994296, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3435897746994296
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3435897746994296, False)
Robot's weighted accuracy = 0.38516970988904253
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.3693897269410021, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3693897269410021
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3693897269410021, False)
Robot's weighted accuracy = 0.40584344968139424
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.3949106210141835, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.3949106210141835
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3949106210141835, False)
Robot's weighted accuracy = 0.425506752333815
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.4200419125321895, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.4200419125321895
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4200419125321895, False)
Robot's weighted accuracy = 0.45819917045371
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 4


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.45819917045371)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.45819917045371
True human's confidence = 0.42565299843215076, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.45819917045371
robot green, human blue --> [3, 0, 3, 2]

Current state = [3, 0, 3, 2]
True human's confidence = 0.3968185693629657, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.3968185693629657
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.3968185693629657, False)
Robot's weighted accuracy = 0.47825886957913527
robot red, human blue --> [2, 0, 2, 2]

Current state = [2, 0, 2, 2]
True human's confidence = 0.42191932282021255, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, 0.3, 0.2]
True human's accuracy on robot = 0.42191932282021255
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.42191932282021255, False)
Robot's weighted accuracy = 0.49737674454130143
robot red, human blue --> [1, 0, 1, 2]

Current state = [1, 0, 1, 2]
True human's confidence = 0.4466744595714788, confidence scalar = 0.0
True human's acting weight vector = [0.5, None, None, 0.2]
True human's accuracy on robot = 0.4466744595714788
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4466744595714788, False)
Robot's weighted accuracy = 0.5156115170196166
robot red, human blue --> [0, 0, 0, 2]

Current state = [0, 0, 0, 2]
True human's confidence = 0.4710037548896362, confidence scalar = 0.0
True human's acting weight vector = [None, None, None, 0.2]
True human's accuracy on robot = 0.4710037548896362
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4710037548896362, False)
Robot's weighted accuracy = 0.5401561422044759
No need to update robot beliefs
robot yellow, human yellow --> [0, 0, 0, 0]
final_reward = 3.8000000000000003

ROUND = 5


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.5401561422044759)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.5401561422044759
True human's confidence = 0.4726632599352937, confidence scalar = 0.0
True human's acting weight vector = [0.5, -0.6, 0.3, 0.2]
True human's accuracy on robot = 0.4726632599352937
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.4726632599352937, False)
Robot's weighted accuracy = 0.5401561422044759
robot red, human blue --> [3, 1, 2, 2]

Current state = [3, 1, 2, 2]
True human's confidence = 0.5133469442428885, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.6, 0.7]
True human's accuracy on robot = 0.5133469442428885
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5133469442428885, False)
Robot's weighted accuracy = 0.5584612685337015
robot red, human blue --> [2, 1, 1, 2]

Current state = [2, 1, 1, 2]
True human's confidence = 0.5512530680951002, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.5512530680951002
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5512530680951002, False)
Robot's weighted accuracy = 0.5740645201732212
robot red, human blue --> [1, 1, 0, 2]

Current state = [1, 1, 0, 2]
True human's confidence = 0.5858909929624551, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.588128027314387
robot yellow, human blue --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.5896952709767513, confidence scalar = 1.0
True human's acting weight vector = [None, -0.6, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.5967789649603558
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.7000000000000006

ROUND = 6


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.5967789649603558)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.5967789649603558
True human's confidence = 0.5896871345093196, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.8, 0.7]
True human's accuracy on robot = 0.5896871345093196
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5896871345093196, False)
Robot's weighted accuracy = 0.5967789649603558
robot red, human blue --> [3, 1, 2, 2]

Current state = [3, 1, 2, 2]
True human's confidence = 0.6157003671788788, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.6, 0.7]
True human's accuracy on robot = 0.6157003671788788
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6157003671788788, False)
Robot's weighted accuracy = 0.6061947649353117
robot red, human blue --> [2, 1, 1, 2]

Current state = [2, 1, 1, 2]
True human's confidence = 0.6382763964841766, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.6382763964841766
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6382763964841766, False)
Robot's weighted accuracy = 0.6140165547746891
robot red, human blue --> [1, 1, 0, 2]

Current state = [1, 1, 0, 2]
True human's confidence = 0.6576489784165584, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.6152013514064095
robot yellow, human blue --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6476178279766477, confidence scalar = 1.0
True human's acting weight vector = [None, -0.6, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.6130708605491793
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.7000000000000006

ROUND = 7


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.6130708605491793)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.6130708605491793
True human's confidence = 0.6349084806781388, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.8, 0.7]
True human's accuracy on robot = 0.6349084806781388
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6349084806781388, False)
Robot's weighted accuracy = 0.6130708605491793
robot red, human blue --> [3, 1, 2, 2]

Current state = [3, 1, 2, 2]
True human's confidence = 0.6477628740714576, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.6, 0.7]
True human's accuracy on robot = 0.6477628740714576
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6477628740714576, False)
Robot's weighted accuracy = 0.617464935798243
robot red, human blue --> [2, 1, 1, 2]

Current state = [2, 1, 1, 2]
True human's confidence = 0.658486078418748, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.658486078418748
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.658486078418748, False)
Robot's weighted accuracy = 0.6210768718620548
robot red, human blue --> [1, 1, 0, 2]

Current state = [1, 1, 0, 2]
True human's confidence = 0.6673882445669469, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.6148582903006387
robot yellow, human blue --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6481052108263624, confidence scalar = 1.0
True human's acting weight vector = [None, -0.6, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.6068197339549671
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.7000000000000006

ROUND = 8


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.6068197339549671)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.6068197339549671
True human's confidence = 0.626924860776626, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.8, 0.7]
True human's accuracy on robot = 0.626924860776626
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.626924860776626, False)
Robot's weighted accuracy = 0.6068197339549671
robot red, human blue --> [3, 1, 2, 2]

Current state = [3, 1, 2, 2]
True human's confidence = 0.6324856776249719, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.6, 0.7]
True human's accuracy on robot = 0.6324856776249719
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6324856776249719, False)
Robot's weighted accuracy = 0.6087950031808926
robot red, human blue --> [2, 1, 1, 2]

Current state = [2, 1, 1, 2]
True human's confidence = 0.6370431602529774, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.6370431602529774
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.6370431602529774, False)
Robot's weighted accuracy = 0.6104130317578035
robot red, human blue --> [1, 1, 0, 2]

Current state = [1, 1, 0, 2]
True human's confidence = 0.6407735330209494, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.6003001020057893
robot yellow, human blue --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6160626596937551, confidence scalar = 1.0
True human's acting weight vector = [None, -0.6, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.5892183839061629
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.7000000000000006

ROUND = 9


Current state = [4, 1, 3, 2]
Robot's top human model = ((0.5, 0.3, 0.2, -0.6), 0, 0.5892183839061629)
Robot's own rewards + human pref = [-0.1  0.8  0.5 -0.4]
Robot's confidence = 0.5892183839061629
True human's confidence = 0.5901321950802974, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.8, 0.7]
True human's accuracy on robot = 0.5901321950802974
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5901321950802974, False)
Robot's weighted accuracy = 0.5892183839061629
robot red, human blue --> [3, 1, 2, 2]

Current state = [3, 1, 2, 2]
True human's confidence = 0.5924283882715385, confidence scalar = 1.0
True human's acting weight vector = [1.0, -0.09999999999999998, 0.6, 0.7]
True human's accuracy on robot = 0.5924283882715385
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5924283882715385, False)
Robot's weighted accuracy = 0.5900999687022667
robot red, human blue --> [2, 1, 1, 2]

Current state = [2, 1, 1, 2]
True human's confidence = 0.5942980028746774, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.5942980028746774
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.5942980028746774, False)
Robot's weighted accuracy = 0.5908216349543948
robot red, human blue --> [1, 1, 0, 2]

Current state = [1, 1, 0, 2]
True human's confidence = 0.595821079781224, confidence scalar = 1.0
True human's acting weight vector = [0.8, -0.39999999999999997, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.5787034168256391
robot yellow, human blue --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.5681589946772709, confidence scalar = 1.0
True human's acting weight vector = [None, -0.6, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.6, 0.3, 0.5, 0.2), 0.0, False)
Robot's weighted accuracy = 0.5660692014000617
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = 2.7000000000000006
