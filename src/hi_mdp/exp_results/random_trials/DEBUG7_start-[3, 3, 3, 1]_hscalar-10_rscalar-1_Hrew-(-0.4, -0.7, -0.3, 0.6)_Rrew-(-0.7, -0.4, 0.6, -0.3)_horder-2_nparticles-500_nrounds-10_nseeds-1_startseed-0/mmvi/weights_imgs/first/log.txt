
ROUND = 0


Current state = [3, 3, 3, 1]
Robot's top human model = ((-0.7, -0.4, 0.6, -0.3), 0, 0.041666666666666664)
Robot's own rewards + human pref = [-1.4 -0.8  1.2 -0.6]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, -0.3, 0.6]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.4, -0.7, 0.6, -0.3), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human yellow --> [3, 3, 2, 0]

Current state = [3, 3, 2, 0]
True human's confidence = 0.1083307000019337, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, -0.3, None]
True human's accuracy on robot = 0.1083307000019337
True human's belief of robot = ((-0.4, -0.7, 0.6, -0.3), 0.1083307000019337, False)
Robot's weighted accuracy = 0.10726072607260724
robot red, human red --> [3, 3, 0, 0]

Current state = [3, 3, 0, 0]
True human's confidence = 0.14969900367371847, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human blue --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.2993807562356248, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, None, None]
True human's accuracy on robot = 0.2993807562356248
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.2993807562356248, False)
Robot's weighted accuracy = 0.33005499885488127
robot green, human blue --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.3436502662743146, confidence scalar = 0.0
True human's acting weight vector = [-0.4, None, None, None]
True human's accuracy on robot = 0.3436502662743146
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.3436502662743146, False)
Robot's weighted accuracy = 0.3447759009451277
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = -0.9000000000000001

ROUND = 1


Current state = [3, 3, 3, 1]
Robot's top human model = ((-0.4, -0.7, -0.3, 0.6), 0, 0.3447759009451277)
Robot's own rewards + human pref = [-1.1 -1.1  0.3  0.3]
Robot's confidence = 0.3447759009451277
True human's confidence = 0.37108029691786715, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, -0.3, 0.6]
True human's accuracy on robot = 0.37108029691786715
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.37108029691786715, False)
Robot's weighted accuracy = 0.3447759009451277
robot red, human yellow --> [3, 3, 2, 0]

Current state = [3, 3, 2, 0]
True human's confidence = 0.43381455287436493, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, -0.3, None]
True human's accuracy on robot = 0.43381455287436493
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.43381455287436493, False)
Robot's weighted accuracy = 0.4715790490826631
robot red, human red --> [3, 3, 0, 0]

Current state = [3, 3, 0, 0]
True human's confidence = 0.46902101445697486, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, None, None]
True human's accuracy on robot = 0.46902101445697486
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.46902101445697486, False)
Robot's weighted accuracy = 0.5148178693060292
robot green, human blue --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.487488031761117, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, None, None]
True human's accuracy on robot = 0.487488031761117
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.487488031761117, False)
Robot's weighted accuracy = 0.5105092294808381
robot green, human blue --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.49772565559001225, confidence scalar = 0.0
True human's acting weight vector = [-0.4, None, None, None]
True human's accuracy on robot = 0.49772565559001225
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.49772565559001225, False)
Robot's weighted accuracy = 0.5043623466528403
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = -0.9000000000000001

ROUND = 2


Current state = [3, 3, 3, 1]
Robot's top human model = ((-0.4, -0.7, -0.3, 0.6), 0, 0.5043623466528403)
Robot's own rewards + human pref = [-1.1 -1.1  0.3  0.3]
Robot's confidence = 0.5043623466528403
True human's confidence = 0.5033568270938169, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, 0.3, 1.2]
True human's accuracy on robot = 0.5033568270938169
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.5033568270938169, False)
Robot's weighted accuracy = 0.5043623466528403
robot red, human yellow --> [3, 3, 2, 0]

Current state = [3, 3, 2, 0]
True human's confidence = 0.5171333189282755, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, -0.7, None]
True human's accuracy on robot = 0.5171333189282755
True human's belief of robot = ((-0.7, -0.4, 0.6, -0.3), 0.5171333189282755, False)
Robot's weighted accuracy = 0.0
robot red, human blue --> [2, 3, 1, 0]

Current state = [2, 3, 1, 0]
True human's confidence = 0.5353931798328931, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, -0.7, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human blue --> [1, 2, 1, 0]

Current state = [1, 2, 1, 0]
True human's confidence = 0.49811419476370006, confidence scalar = 0.0
True human's acting weight vector = [-0.4, -0.7, -0.3, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human red --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.5422722968174646, confidence scalar = 1.0
True human's acting weight vector = [-0.4, None, None, None]
True human's accuracy on robot = 0.5422722968174646
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.5422722968174646, False)
Robot's weighted accuracy = 0.5300453561949903
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = -0.9000000000000001

ROUND = 3


Current state = [3, 3, 3, 1]
Robot's top human model = ((-0.4, -0.7, -0.3, 0.6), 0, 0.5300453561949903)
Robot's own rewards + human pref = [-1.1 -1.1  0.3  0.3]
Robot's confidence = 0.5300453561949903
True human's confidence = 0.5445777082374276, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, 0.3, 1.2]
True human's accuracy on robot = 0.5445777082374276
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.5445777082374276, False)
Robot's weighted accuracy = 0.5300453561949903
robot red, human yellow --> [3, 3, 2, 0]

Current state = [3, 3, 2, 0]
True human's confidence = 0.5586708006849346, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, -0.6, None]
True human's accuracy on robot = 0.5586708006849346
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.5586708006849346, False)
Robot's weighted accuracy = 0.0
robot red, human blue --> [2, 3, 1, 0]

Current state = [2, 3, 1, 0]
True human's confidence = 0.5466920105453116, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, -0.6, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.0, False)
Robot's weighted accuracy = 0.5273431359227005
robot green, human blue --> [1, 2, 1, 0]

Current state = [1, 2, 1, 0]
True human's confidence = 0.5967100953616005, confidence scalar = 1.0
True human's acting weight vector = [0.19999999999999996, -0.09999999999999998, -0.6, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.0, False)
Robot's weighted accuracy = 0.59723767567419
robot green, human blue --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.6365293167456267, confidence scalar = 1.0
True human's acting weight vector = [None, None, -0.3, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -0.3, 0.6, -0.4), 0.0, False)
Robot's weighted accuracy = 0.6620899301234868
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = -0.9000000000000001
