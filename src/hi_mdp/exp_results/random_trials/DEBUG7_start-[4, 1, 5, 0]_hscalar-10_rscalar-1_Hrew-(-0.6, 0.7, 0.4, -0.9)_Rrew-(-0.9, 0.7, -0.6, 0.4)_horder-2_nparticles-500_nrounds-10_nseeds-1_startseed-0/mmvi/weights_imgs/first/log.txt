
ROUND = 0


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, 0.7, -0.6, 0.4), 0, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8  1.4 -1.2  0.8]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, 0.7, -0.6, 0.4), 0.041666666666666664, False)
Robot's weighted accuracy = 0.041666666666666664
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.10526158815680764, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.10526158815680764
True human's belief of robot = ((-0.9, 0.7, -0.6, 0.4), 0.10526158815680764, False)
Robot's weighted accuracy = 0.08262918482839457
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.21050405710923056, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.21050405710923056
True human's belief of robot = ((-0.9, 0.7, -0.6, 0.4), 0.21050405710923056, False)
Robot's weighted accuracy = 0.1051908194971749
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.22798038348933156, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.22798038348933156
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.22798038348933156, False)
Robot's weighted accuracy = 0.12171260071934116
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.2345029033341206, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.2345029033341206
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.2345029033341206, False)
Robot's weighted accuracy = 0.12171260071934116
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 1


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.12171260071934116)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.12171260071934116
True human's confidence = 0.38231349157090927, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.38231349157090927
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.38231349157090927, False)
Robot's weighted accuracy = 0.12171260071934116
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.40341409543324575, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.40341409543324575
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.40341409543324575, False)
Robot's weighted accuracy = 0.13578742939678812
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.38655977585400797, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, 0.4, None]
True human's accuracy on robot = 0.38655977585400797
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.38655977585400797, False)
Robot's weighted accuracy = 0.14844714159518138
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.3593485361328368, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.3593485361328368
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.3593485361328368, False)
Robot's weighted accuracy = 0.1600909033504008
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.49603493679907806, confidence scalar = 0.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.49603493679907806
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.49603493679907806, False)
Robot's weighted accuracy = 0.1600909033504008
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 2


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.1600909033504008)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.1600909033504008
True human's confidence = 0.545440455953139, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.545440455953139
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.545440455953139, False)
Robot's weighted accuracy = 0.1600909033504008
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.5857290312859975, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.5857290312859975
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.5857290312859975, False)
Robot's weighted accuracy = 0.1709113419380788
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.5729376570474726, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.5729376570474726
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.5729376570474726, False)
Robot's weighted accuracy = 0.18100839616608524
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.5582967856858098, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.5582967856858098
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.5582967856858098, False)
Robot's weighted accuracy = 0.19043375712008798
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.5897152577668205, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.5897152577668205
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.5897152577668205, False)
Robot's weighted accuracy = 0.19043375712008798
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 3


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.19043375712008798)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.19043375712008798
True human's confidence = 0.5977261526587704, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.5977261526587704
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.5977261526587704, False)
Robot's weighted accuracy = 0.19043375712008798
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.6445700218260966, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.6445700218260966
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6445700218260966, False)
Robot's weighted accuracy = 0.1992150734521352
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.6355530567741287, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.6355530567741287
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6355530567741287, False)
Robot's weighted accuracy = 0.20737053010225426
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.6262311169943413, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.6262311169943413
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6262311169943413, False)
Robot's weighted accuracy = 0.2149172637406064
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.6311879262832396, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.6311879262832396
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6311879262832396, False)
Robot's weighted accuracy = 0.2149172637406064
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 4


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.2149172637406064)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.2149172637406064
True human's confidence = 0.6323807768765661, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.6323807768765661
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6323807768765661, False)
Robot's weighted accuracy = 0.2149172637406064
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.6788898294278531, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.6788898294278531
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6788898294278531, False)
Robot's weighted accuracy = 0.22187563064076135
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.6709114688696539, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.6709114688696539
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6709114688696539, False)
Robot's weighted accuracy = 0.2282707940606034
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.662809742558089, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.662809742558089
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.662809742558089, False)
Robot's weighted accuracy = 0.2341327024868011
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.663553737086573, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.663553737086573
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.663553737086573, False)
Robot's weighted accuracy = 0.2341327024868011
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 5


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.2341327024868011)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.2341327024868011
True human's confidence = 0.663732090770837, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.663732090770837
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.663732090770837, False)
Robot's weighted accuracy = 0.2341327024868011
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.7083522108081147, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7083522108081147
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7083522108081147, False)
Robot's weighted accuracy = 0.239495207828879
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.7008812722995521, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.7008812722995521
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7008812722995521, False)
Robot's weighted accuracy = 0.2443948203378976
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.6933022100797955, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.6933022100797955
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6933022100797955, False)
Robot's weighted accuracy = 0.24886940896490164
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.6934109058146561, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.6934109058146561
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6934109058146561, False)
Robot's weighted accuracy = 0.24886940896490164
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 6


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.24886940896490164)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.24886940896490164
True human's confidence = 0.6934377758206602, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.6934377758206602
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.6934377758206602, False)
Robot's weighted accuracy = 0.24886940896490164
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.7357246777825611, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7357246777825611
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7357246777825611, False)
Robot's weighted accuracy = 0.25295702193331693
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.7287011288252877, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.7287011288252877
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7287011288252877, False)
Robot's weighted accuracy = 0.25669491136258854
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.721565472519474, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.721565472519474
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.721565472519474, False)
Robot's weighted accuracy = 0.26011878749858
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7215782427531855, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7215782427531855
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7215782427531855, False)
Robot's weighted accuracy = 0.26011878749858
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 7


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.26011878749858)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.26011878749858
True human's confidence = 0.7215823041699262, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7215823041699262
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7215823041699262, False)
Robot's weighted accuracy = 0.26011878749858
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.7613295563834674, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7613295563834674
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7613295563834674, False)
Robot's weighted accuracy = 0.263262293557778
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.7547616501243536, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.7547616501243536
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7547616501243536, False)
Robot's weighted accuracy = 0.26615667409181837
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.7480773945653334, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7480773945653334
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7480773945653334, False)
Robot's weighted accuracy = 0.26883060246511525
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7480755327125779, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7480755327125779
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7480755327125779, False)
Robot's weighted accuracy = 0.26883060246511525
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 8


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.26883060246511525)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.26883060246511525
True human's confidence = 0.7480761465049212, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7480761465049212
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7480761465049212, False)
Robot's weighted accuracy = 0.26883060246511525
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.7851685622479051, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7851685622479051
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7851685622479051, False)
Robot's weighted accuracy = 0.2713101323249651
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.7790663292216191, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.7790663292216191
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7790663292216191, False)
Robot's weighted accuracy = 0.27361874088867516
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.7728457414888272, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7728457414888272
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7728457414888272, False)
Robot's weighted accuracy = 0.27577743651959613
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7728415464093803, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7728415464093803
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7728415464093803, False)
Robot's weighted accuracy = 0.27577743651959613
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3

ROUND = 9


Current state = [4, 1, 5, 0]
Robot's top human model = ((-0.9, -0.6, 0.7, 0.4), 0, 0.27577743651959613)
Robot's own rewards + human pref = [-1.8  0.1  0.1  0.8]
Robot's confidence = 0.27577743651959613
True human's confidence = 0.7728416389353744, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.7728416389353744
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7728416389353744, False)
Robot's weighted accuracy = 0.27577743651959613
robot green, human red --> [4, 0, 4, 0]

Current state = [4, 0, 4, 0]
True human's confidence = 0.807227952185265, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.8, None]
True human's accuracy on robot = 0.807227952185265
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.807227952185265, False)
Robot's weighted accuracy = 0.27780490819261416
robot red, human red --> [4, 0, 2, 0]

Current state = [4, 0, 2, 0]
True human's confidence = 0.8015936935359341, confidence scalar = 1.0
True human's acting weight vector = [-0.19999999999999996, None, 0.4, None]
True human's accuracy on robot = 0.8015936935359341
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.8015936935359341, False)
Robot's weighted accuracy = 0.27971769935881036
robot red, human red --> [4, 0, 0, 0]

Current state = [4, 0, 0, 0]
True human's confidence = 0.7958414135216945, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7958414135216945
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7958414135216945, False)
Robot's weighted accuracy = 0.28153039305563465
No need to update robot beliefs
robot blue, human blue --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7958367543773512, confidence scalar = 1.0
True human's acting weight vector = [-0.6, None, None, None]
True human's accuracy on robot = 0.7958367543773512
True human's belief of robot = ((-0.6, 0.7, 0.4, -0.9), 0.7958367543773512, False)
Robot's weighted accuracy = 0.28153039305563465
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = -2.3
