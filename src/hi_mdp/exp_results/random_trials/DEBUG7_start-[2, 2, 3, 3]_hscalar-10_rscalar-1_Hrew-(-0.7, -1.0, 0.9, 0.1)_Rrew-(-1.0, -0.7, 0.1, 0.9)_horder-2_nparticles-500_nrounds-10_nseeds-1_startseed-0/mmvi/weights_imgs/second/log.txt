
ROUND = 0


Current state = [2, 2, 3, 3]
Robot's top human model = ((-1.0, -0.7, 0.1, 0.9), 1, 0.041666666666666664)
Robot's own rewards + human pref = [-2.  -1.4  0.2  1.8]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, -1.0, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.0
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.09595778632812578, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.09595778632812578
True human's belief of robot = ((-0.7, -1.0, 0.1, 0.9), 0.09595778632812578, False)
Robot's weighted accuracy = 0.09500000000000001
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.12253799920060127, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, None]
True human's accuracy on robot = 0.12253799920060127
True human's belief of robot = ((-0.7, -1.0, 0.1, 0.9), 0.12253799920060127, False)
Robot's weighted accuracy = 0.12251131221719458
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.13912139061580522, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, 0.1, -0.7, 0.9), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human blue --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.2782448554056974, confidence scalar = 0.0
True human's acting weight vector = [-0.7, None, None, None]
True human's accuracy on robot = 0.2782448554056974
True human's belief of robot = ((-1.0, 0.1, -0.7, 0.9), 0.2782448554056974, False)
Robot's weighted accuracy = 0.28734830258213306
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = 2.6

ROUND = 1


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.28734830258213306)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.28734830258213306
True human's confidence = 0.3115750434218546, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.3115750434218546
True human's belief of robot = ((-1.0, 0.1, -0.7, 0.9), 0.3115750434218546, False)
Robot's weighted accuracy = 0.28734830258213306
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.3361084976010713, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.3361084976010713
True human's belief of robot = ((-1.0, 0.1, -0.7, 0.9), 0.3361084976010713, False)
Robot's weighted accuracy = 0.313722626906341
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.3517243524540485, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, None, 0.1]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human yellow --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.7126718049323594, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.0, None, None]
True human's accuracy on robot = 0.7126718049323594
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.7126718049323594, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7126607322308087, confidence scalar = 1.0
True human's acting weight vector = [-0.7, None, None, None]
True human's accuracy on robot = 0.7126607322308087
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.7126607322308087, False)
Robot's weighted accuracy = 0.31256808520233964
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = 0.4000000000000006

ROUND = 2


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.1, 0.9), 1, 0.31256808520233964)
Robot's own rewards + human pref = [-1.7 -1.7  0.2  1.8]
Robot's confidence = 0.31256808520233964
True human's confidence = 0.7126254691977129, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.7126254691977129
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.7126254691977129, False)
Robot's weighted accuracy = 0.0
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.741726094077019, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.741726094077019
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.741726094077019, False)
Robot's weighted accuracy = 0.22922680380390215
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.759614835046868, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 0.20000000000000007, None]
True human's accuracy on robot = 0.759614835046868
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.759614835046868, False)
Robot's weighted accuracy = 0.29925846110549376
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.7703633029291068, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.0, None, None]
True human's accuracy on robot = 0.7703633029291068
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.7703633029291068, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [2, 0, 0, 0]

Current state = [2, 0, 0, 0]
True human's confidence = 0.7703472060713751, confidence scalar = 1.0
True human's acting weight vector = [-0.7, None, None, None]
True human's accuracy on robot = 0.7703472060713751
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.7703472060713751, False)
Robot's weighted accuracy = 0.48709401966087496
No need to update robot beliefs
robot blue, human blue --> [0, 0, 0, 0]
final_reward = 2.0

ROUND = 3


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, 0.1, 0.9, -1.0), 1, 0.48709401966087496)
Robot's own rewards + human pref = [-1.7 -0.6  1.  -0.1]
Robot's confidence = 0.48709401966087496
True human's confidence = 0.7702880557750461, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.48709401966087496
robot red, human red --> [2, 2, 1, 3]

Current state = [2, 2, 1, 3]
True human's confidence = 0.8984530388212534, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, None, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human yellow --> [2, 2, 0, 2]

Current state = [2, 2, 0, 2]
True human's confidence = 0.9211481974588209, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, None, -0.6]
True human's accuracy on robot = 0.9211481974588209
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9211481974588209, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 2, 0, 1]

Current state = [1, 2, 0, 1]
True human's confidence = 0.930950391073972, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.7, None, None]
True human's accuracy on robot = 0.930950391073972
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.930950391073972, False)
Robot's weighted accuracy = 0.4360148601608477
robot yellow, human blue --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9391448468939144, confidence scalar = 1.0
True human's acting weight vector = [None, -1.0, None, None]
True human's accuracy on robot = 0.9391448468939144
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9391448468939144, False)
Robot's weighted accuracy = 0.7151520242683501
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -0.09999999999999987

ROUND = 4


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.7151520242683501)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.7151520242683501
True human's confidence = 0.9391374231939394, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.9391374231939394
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9391374231939394, False)
Robot's weighted accuracy = 0.7151520242683501
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.9595867959519179, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.9595867959519179
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9595867959519179, False)
Robot's weighted accuracy = 0.7575088185562177
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.9718363242830472, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 0.20000000000000007, None]
True human's accuracy on robot = 0.9718363242830472
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9718363242830472, False)
Robot's weighted accuracy = 0.7913827294373058
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.9790730984614603, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.7, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.8130343852963261
robot blue, human blue --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8571464412057781, confidence scalar = 1.0
True human's acting weight vector = [None, -1.0, None, None]
True human's accuracy on robot = 0.8571464412057781
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.8571464412057781, False)
Robot's weighted accuracy = 0.921133491255013
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 2.0

ROUND = 5


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.921133491255013)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.921133491255013
True human's confidence = 0.9867407366472607, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.9867407366472607
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9867407366472607, False)
Robot's weighted accuracy = 0.921133491255013
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.9910490152271726, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.9910490152271726
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9910490152271726, False)
Robot's weighted accuracy = 0.9344903082691393
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.9935577675960073, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 0.20000000000000007, None]
True human's accuracy on robot = 0.9935577675960073
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9935577675960073, False)
Robot's weighted accuracy = 0.9460161348475055
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.9950169604260902, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.7, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.9534652422571366
robot blue, human blue --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8668362636269348, confidence scalar = 1.0
True human's acting weight vector = [None, -1.0, None, None]
True human's accuracy on robot = 0.8668362636269348
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.8668362636269348, False)
Robot's weighted accuracy = 0.9785156473685039
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 2.0

ROUND = 6


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.9785156473685039)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.9785156473685039
True human's confidence = 0.9971569486787035, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.9971569486787035
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9971569486787035, False)
Robot's weighted accuracy = 0.9785156473685039
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.9980126996213051, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.9980126996213051
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9980126996213051, False)
Robot's weighted accuracy = 0.9815046916043966
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.998506036584128, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 0.20000000000000007, None]
True human's accuracy on robot = 0.998506036584128
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.998506036584128, False)
Robot's weighted accuracy = 0.9854241414473646
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.9987928198537905, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.7, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.0, False)
Robot's weighted accuracy = 0.9881937091406815
robot blue, human blue --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.868334475452345, confidence scalar = 1.0
True human's acting weight vector = [None, -1.0, None, None]
True human's accuracy on robot = 0.868334475452345
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.868334475452345, False)
Robot's weighted accuracy = 0.992854926448474
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 2.0

ROUND = 7


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.992854926448474)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.992854926448474
True human's confidence = 0.9985772627589333, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.9985772627589333
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9985772627589333, False)
Robot's weighted accuracy = 0.992854926448474
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.9987487456059401, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.9987487456059401
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9987487456059401, False)
Robot's weighted accuracy = 0.9934719600175517
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.9988452821967075, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 0.20000000000000007, None]
True human's accuracy on robot = 0.9988452821967075
True human's belief of robot = ((-1.0, -0.7, 0.1, 0.9), 0.9988452821967075, False)
Robot's weighted accuracy = 0.9951025658786343
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.9989021240272925, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -1.7, None, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.0, False)
Robot's weighted accuracy = 0.9963534654423126
robot blue, human blue --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4349398622676384, confidence scalar = 0.0
True human's acting weight vector = [None, -1.0, None, None]
True human's accuracy on robot = 0.4349398622676384
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.4349398622676384, False)
Robot's weighted accuracy = 0.9973234750018383
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 2.0

ROUND = 8


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.9973234750018383)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.9973234750018383
True human's confidence = 0.4441588345134288, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.4441588345134288
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.4441588345134288, False)
Robot's weighted accuracy = 0.9973234750018383
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.44416289019799576, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, 0.1]
True human's accuracy on robot = 0.44416289019799576
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.44416289019799576, False)
Robot's weighted accuracy = 0.9974486077330935
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.44416433785136117, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, 0.9, None]
True human's accuracy on robot = 0.44416433785136117
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.44416433785136117, False)
Robot's weighted accuracy = 0.9975210673516034
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.444165595532405, confidence scalar = 0.0
True human's acting weight vector = [-0.7, -1.0, None, None]
True human's accuracy on robot = 0.444165595532405
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.444165595532405, False)
Robot's weighted accuracy = 0.9981147657550105
robot green, human blue --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.6293489558962668, confidence scalar = 1.0
True human's acting weight vector = [-0.7, None, None, None]
True human's accuracy on robot = 0.6293489558962668
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6293489558962668, False)
Robot's weighted accuracy = 0.9980535287883127
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = 2.6

ROUND = 9


Current state = [2, 2, 3, 3]
Robot's top human model = ((-0.7, -1.0, 0.9, 0.1), 1, 0.9980535287883127)
Robot's own rewards + human pref = [-1.7 -1.7  1.   1. ]
Robot's confidence = 0.9980535287883127
True human's confidence = 0.6771198405267926, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 1.0]
True human's accuracy on robot = 0.6771198405267926
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6771198405267926, False)
Robot's weighted accuracy = 0.9980535287883127
robot yellow, human red --> [2, 2, 2, 2]

Current state = [2, 2, 2, 2]
True human's confidence = 0.6771221659713336, confidence scalar = 1.0
True human's acting weight vector = [0.20000000000000007, -0.09999999999999998, 1.8, 0.2]
True human's accuracy on robot = 0.6771221659713336
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6771221659713336, False)
Robot's weighted accuracy = 0.9980911074309561
robot yellow, human red --> [2, 2, 1, 1]

Current state = [2, 2, 1, 1]
True human's confidence = 0.6771234589119028, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -0.9, 1.0, None]
True human's accuracy on robot = 0.6771234589119028
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6771234589119028, False)
Robot's weighted accuracy = 0.9986233621338736
robot yellow, human red --> [2, 2, 0, 0]

Current state = [2, 2, 0, 0]
True human's confidence = 0.6771248470807057, confidence scalar = 1.0
True human's acting weight vector = [-0.6, -1.0, None, None]
True human's accuracy on robot = 0.6771248470807057
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6771248470807057, False)
Robot's weighted accuracy = 0.9989453243282551
robot green, human blue --> [1, 1, 0, 0]

Current state = [1, 1, 0, 0]
True human's confidence = 0.6525466001382463, confidence scalar = 1.0
True human's acting weight vector = [-0.7, None, None, None]
True human's accuracy on robot = 0.6525466001382463
True human's belief of robot = ((-0.7, 0.1, -1.0, 0.9), 0.6525466001382463, False)
Robot's weighted accuracy = 0.998917283608541
No need to update robot beliefs
robot green, human blue --> [0, 0, 0, 0]
final_reward = 2.6
