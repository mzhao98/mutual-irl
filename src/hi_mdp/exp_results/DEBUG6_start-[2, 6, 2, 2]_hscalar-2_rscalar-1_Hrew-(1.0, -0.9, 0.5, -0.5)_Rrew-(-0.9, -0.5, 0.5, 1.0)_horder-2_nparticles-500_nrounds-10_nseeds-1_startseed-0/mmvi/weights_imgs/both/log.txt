
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, None]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, 0.5, None]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.11327368168887536)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.11327368168887536
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.11327368168887536
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.12415027422637664
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.15864689755195557
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2455927251767097)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2455927251767097
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.2455927251767097
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.7472208884492556
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7472208884492556, False)
Robot's weighted accuracy = 0.26139296836891657
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7869952504818568, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.7869952504818568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7869952504818568, False)
Robot's weighted accuracy = 0.3329550827668498
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273282, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8214225257273282
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8214225257273282, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8216590931070864, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8217097224033024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8217097224033024, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.3544734171612952)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.3544734171612952
True human's confidence = 0.821719605437636, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.821719605437636
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.821719605437636, False)
Robot's weighted accuracy = 0.3544734171612952
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8576496009580737, False)
Robot's weighted accuracy = 0.3697238979507007
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603414, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.8861823382603414
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8861823382603414, False)
Robot's weighted accuracy = 0.4524046838665382
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948706087917568, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.894867546234916, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.894867546234916
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.894867546234916, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602975, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8948678929602975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948678929602975, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4500609082716315)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.4500609082716315
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8948676789039607
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948676789039607, False)
Robot's weighted accuracy = 0.4500609082716315
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9188500665403389, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9188500665403389
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9188500665403389, False)
Robot's weighted accuracy = 0.4624447823105862
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9373563415651059, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9373563415651059
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9373563415651059, False)
Robot's weighted accuracy = 0.5449018952400122
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9383457033307511, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383457033307511
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383457033307511, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9383392698173356, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383392698173356
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383392698173356, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9383391665376024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9383391665376024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383391665376024, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5364606038492142)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.5364606038492142
True human's confidence = 0.9383390559555314, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9383390559555314
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383390559555314, False)
Robot's weighted accuracy = 0.5364606038492142
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9533640444125245, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5457465836406582
robot red, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9395622532403541, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.9202127796304438, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.12226095912465039
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.900073156412395, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.13188124928339437
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8754327905969677, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.1265269831212555
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -0.6999999999999997

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8134288298082929)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8134288298082929
True human's confidence = 0.8453799299693082, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8453799299693082
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8453799299693082, False)
Robot's weighted accuracy = 0.1265269831212555
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.88079189858425, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.88079189858425
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.88079189858425, False)
Robot's weighted accuracy = 0.12022778019483978
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9088269989053575, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9088269989053575
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9088269989053575, False)
Robot's weighted accuracy = 0.11047661598599956
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9051638720555164, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9051638720555164
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9051638720555164, False)
Robot's weighted accuracy = 0.09937205018972714
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9051576820931908, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9051576820931908
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9051576820931908, False)
Robot's weighted accuracy = 0.09937205018972714
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9051576466758856, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9051576466758856
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9051576466758856, False)
Robot's weighted accuracy = 0.09937205018972714
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8655786061901328)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8655786061901328
True human's confidence = 0.9051576113177959, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9051576113177959
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9051576113177959, False)
Robot's weighted accuracy = 0.09937205018972714
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9281847535732024, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9281847535732024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9281847535732024, False)
Robot's weighted accuracy = 0.09363987414659654
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.945912575824957, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.945912575824957
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.945912575824957, False)
Robot's weighted accuracy = 0.08543776061598306
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9431925767681909, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9431925767681909
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9431925767681909, False)
Robot's weighted accuracy = 0.07648690492526429
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9431861561925826, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9431861561925826
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9431861561925826, False)
Robot's weighted accuracy = 0.07648690492526429
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9431861452332518, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9431861452332518
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9431861452332518, False)
Robot's weighted accuracy = 0.07648690492526429
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9026828825494104)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9026828825494104
True human's confidence = 0.9431861343373033, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9431861343373033
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9431861343373033, False)
Robot's weighted accuracy = 0.07648690492526429
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9574611910642392, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9574611910642392
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9574611910642392, False)
Robot's weighted accuracy = 0.07169085369917795
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9682556625437139, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9682556625437139
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9682556625437139, False)
Robot's weighted accuracy = 0.06508893686371375
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9664831809145016, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9664831809145016
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9664831809145016, False)
Robot's weighted accuracy = 0.058113674539802075
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9664766129435052, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9664766129435052
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9664766129435052, False)
Robot's weighted accuracy = 0.058113674539802075
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9664766096181365, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9664766096181365
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9664766096181365, False)
Robot's weighted accuracy = 0.058113674539802075
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9292494495160818)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9292494495160818
True human's confidence = 0.9664766063582049, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9664766063582049
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9664766063582049, False)
Robot's weighted accuracy = 0.058113674539802075
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9750695194796833, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9750695194796833
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9750695194796833, False)
Robot's weighted accuracy = 0.054281568321568927
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9814959206091293, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9814959206091293
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9814959206091293, False)
Robot's weighted accuracy = 0.04911498850231133
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9804073378220253, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9804073378220253
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9804073378220253, False)
Robot's weighted accuracy = 0.04377316894920669
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9804006798488925, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9804006798488925
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9804006798488925, False)
Robot's weighted accuracy = 0.04377316894920669
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9804006788249232, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9804006788249232
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9804006788249232, False)
Robot's weighted accuracy = 0.04377316894920669
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003
