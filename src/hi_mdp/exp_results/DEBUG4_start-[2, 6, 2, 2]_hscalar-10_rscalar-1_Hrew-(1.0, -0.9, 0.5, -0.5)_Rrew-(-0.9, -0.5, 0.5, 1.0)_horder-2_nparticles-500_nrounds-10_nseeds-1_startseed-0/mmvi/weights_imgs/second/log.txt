
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, 1.0, -0.5), 1, 0.292238297014615)
Robot's own rewards + human pref = [-0.4 -1.4  1.5  0.5]
Robot's confidence = 0.292238297014615
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.26806260663795894
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.3734290603858591)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.3734290603858591
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.3734290603858591
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.448376931105453
robot red, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7354725378756957, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5211958970642625
robot red, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.6850856199947247, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6850856199947247
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6850856199947247, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6990671485886669, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6990671485886669
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6990671485886669, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6991857432841315, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6991857432841315
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6991857432841315, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.5249337765793578)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.5249337765793578
True human's confidence = 0.6992120320252431, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6992120320252431
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6992120320252431, False)
Robot's weighted accuracy = 0.5249337765793578
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.75865431871843, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.75865431871843
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.75865431871843, False)
Robot's weighted accuracy = 0.5942508763576115
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8093124528282366, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.6480443593486472
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8348718226294429, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.660952116413946
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8321422897763148, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8321422897763148
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321422897763148, False)
Robot's weighted accuracy = 0.671458127777354
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8321622933728758, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8321622933728758
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321622933728758, False)
Robot's weighted accuracy = 0.671458127777354
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.671458127777354)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.671458127777354
True human's confidence = 0.8321595147617552, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8321595147617552
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321595147617552, False)
Robot's weighted accuracy = 0.671458127777354
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8594163829735956, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8594163829735956
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8594163829735956, False)
Robot's weighted accuracy = 0.7344408810544454
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.880659545410585, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.7884302409335313
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.789732438622416, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.7861354547985351
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5649316494524457, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.5649316494524457
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649316494524457, False)
Robot's weighted accuracy = 0.7796465733540517
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5649258507706505, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.5649258507706505
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649258507706505, False)
Robot's weighted accuracy = 0.7796465733540517
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.7796465733540517)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.7796465733540517
True human's confidence = 0.5649105467455274, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.5649105467455274
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649105467455274, False)
Robot's weighted accuracy = 0.7796465733540517
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5710827571237295, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5710827571237295
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5710827571237295, False)
Robot's weighted accuracy = 0.8271880934286906
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5757148497031027, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.8672378754707939
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.6949136604501865, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.6949136604501865
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.6949136604501865, False)
Robot's weighted accuracy = 0.8653230934153016
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8761131250879881, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.8761131250879881
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761131250879881, False)
Robot's weighted accuracy = 0.8633732311868826
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8761221059788495, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8761221059788495
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761221059788495, False)
Robot's weighted accuracy = 0.8633732311868826
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8633732311868826)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8633732311868826
True human's confidence = 0.8761280130703047, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8761280130703047
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761280130703047, False)
Robot's weighted accuracy = 0.8633732311868826
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8810813516430775, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8810813516430775
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8810813516430775, False)
Robot's weighted accuracy = 0.8946380648998064
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8847638553445577, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8847638553445577
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8847638553445577, False)
Robot's weighted accuracy = 0.9198935013913041
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9554223996029163, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9554223996029163
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9554223996029163, False)
Robot's weighted accuracy = 0.9187438144775076
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9771251035689709, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9771251035689709
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771251035689709, False)
Robot's weighted accuracy = 0.9175662100283112
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9771265534487945, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9771265534487945
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771265534487945, False)
Robot's weighted accuracy = 0.9175662100283112
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9175662100283112)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9175662100283112
True human's confidence = 0.9771270675095637, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9771270675095637
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771270675095637, False)
Robot's weighted accuracy = 0.9175662100283112
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9806251294777693, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9806251294777693
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9806251294777693, False)
Robot's weighted accuracy = 0.9368663625568264
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9832150888465288, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9832150888465288
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9832150888465288, False)
Robot's weighted accuracy = 0.9519062504274355
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9894122646734763, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9894122646734763
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9894122646734763, False)
Robot's weighted accuracy = 0.9512707165571943
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9908424054841344, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9908424054841344
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908424054841344, False)
Robot's weighted accuracy = 0.9506118640075552
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9908431215658623, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9908431215658623
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908431215658623, False)
Robot's weighted accuracy = 0.9506118640075552
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9506118640075552)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9506118640075552
True human's confidence = 0.9908431145334604, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9908431145334604
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908431145334604, False)
Robot's weighted accuracy = 0.9506118640075552
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9930382487336258, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9930382487336258
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9930382487336258, False)
Robot's weighted accuracy = 0.962129981818635
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9946582840971634, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9946582840971634
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9946582840971634, False)
Robot's weighted accuracy = 0.9707268231197372
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9949202652272191, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9949202652272191
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9949202652272191, False)
Robot's weighted accuracy = 0.9704164161583712
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9947772191216918, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9947772191216918
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947772191216918, False)
Robot's weighted accuracy = 0.9700847858764755
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9947778967141834, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9947778967141834
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947778967141834, False)
Robot's weighted accuracy = 0.9700847858764755
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9700847858764755)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9700847858764755
True human's confidence = 0.9947778652628411, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9947778652628411
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947778652628411, False)
Robot's weighted accuracy = 0.9700847858764755
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9961343032413169, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9961343032413169
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9961343032413169, False)
Robot's weighted accuracy = 0.9768641477645008
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9971324809347121, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9971324809347121
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9971324809347121, False)
Robot's weighted accuracy = 0.9815832977442451
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9969964805250697, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9969964805250697
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9969964805250697, False)
Robot's weighted accuracy = 0.9814767818589347
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9968240646180148, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9968240646180148
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9968240646180148, False)
Robot's weighted accuracy = 0.9813489744632915
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9968247532492, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9968247532492
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9968247532492, False)
Robot's weighted accuracy = 0.9813489744632915
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, 1.0, -0.5), 1, 0.292238297014615)
Robot's own rewards + human pref = [-0.4 -1.4  1.5  0.5]
Robot's confidence = 0.292238297014615
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.26806260663795894
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.3734290603858591)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.3734290603858591
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.3734290603858591
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.448376931105453
robot red, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7354725378756957, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5211958970642625
robot red, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.6850856199947247, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6850856199947247
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6850856199947247, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6990671485886669, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6990671485886669
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6990671485886669, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6991857432841315, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6991857432841315
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6991857432841315, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.5249337765793578)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.5249337765793578
True human's confidence = 0.6992120320252431, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6992120320252431
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6992120320252431, False)
Robot's weighted accuracy = 0.5249337765793578
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.75865431871843, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.75865431871843
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.75865431871843, False)
Robot's weighted accuracy = 0.5942508763576115
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8093124528282366, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.6480443593486472
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8348718226294429, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.660952116413946
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8321422897763148, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8321422897763148
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321422897763148, False)
Robot's weighted accuracy = 0.671458127777354
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8321622933728758, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8321622933728758
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321622933728758, False)
Robot's weighted accuracy = 0.671458127777354
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.671458127777354)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.671458127777354
True human's confidence = 0.8321595147617552, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8321595147617552
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8321595147617552, False)
Robot's weighted accuracy = 0.671458127777354
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8594163829735956, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8594163829735956
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8594163829735956, False)
Robot's weighted accuracy = 0.7344408810544454
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.880659545410585, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.7884302409335313
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.789732438622416, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.7861354547985351
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5649316494524457, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.5649316494524457
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649316494524457, False)
Robot's weighted accuracy = 0.7796465733540517
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5649258507706505, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.5649258507706505
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649258507706505, False)
Robot's weighted accuracy = 0.7796465733540517
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.7796465733540517)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.7796465733540517
True human's confidence = 0.5649105467455274, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.5649105467455274
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5649105467455274, False)
Robot's weighted accuracy = 0.7796465733540517
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5710827571237295, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5710827571237295
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5710827571237295, False)
Robot's weighted accuracy = 0.8271880934286906
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5757148497031027, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.8672378754707939
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.6949136604501865, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.6949136604501865
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.6949136604501865, False)
Robot's weighted accuracy = 0.8653230934153016
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8761131250879881, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.8761131250879881
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761131250879881, False)
Robot's weighted accuracy = 0.8633732311868826
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8761221059788495, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8761221059788495
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761221059788495, False)
Robot's weighted accuracy = 0.8633732311868826
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8633732311868826)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8633732311868826
True human's confidence = 0.8761280130703047, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8761280130703047
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8761280130703047, False)
Robot's weighted accuracy = 0.8633732311868826
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8810813516430775, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8810813516430775
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8810813516430775, False)
Robot's weighted accuracy = 0.8946380648998064
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8847638553445577, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8847638553445577
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8847638553445577, False)
Robot's weighted accuracy = 0.9198935013913041
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9554223996029163, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9554223996029163
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9554223996029163, False)
Robot's weighted accuracy = 0.9187438144775076
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9771251035689709, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9771251035689709
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771251035689709, False)
Robot's weighted accuracy = 0.9175662100283112
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9771265534487945, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9771265534487945
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771265534487945, False)
Robot's weighted accuracy = 0.9175662100283112
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9175662100283112)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9175662100283112
True human's confidence = 0.9771270675095637, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9771270675095637
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9771270675095637, False)
Robot's weighted accuracy = 0.9175662100283112
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9806251294777693, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9806251294777693
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9806251294777693, False)
Robot's weighted accuracy = 0.9368663625568264
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9832150888465288, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9832150888465288
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9832150888465288, False)
Robot's weighted accuracy = 0.9519062504274355
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9894122646734763, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9894122646734763
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9894122646734763, False)
Robot's weighted accuracy = 0.9512707165571943
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9908424054841344, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9908424054841344
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908424054841344, False)
Robot's weighted accuracy = 0.9506118640075552
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9908431215658623, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9908431215658623
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908431215658623, False)
Robot's weighted accuracy = 0.9506118640075552
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9506118640075552)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9506118640075552
True human's confidence = 0.9908431145334604, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9908431145334604
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9908431145334604, False)
Robot's weighted accuracy = 0.9506118640075552
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9930382487336258, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9930382487336258
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9930382487336258, False)
Robot's weighted accuracy = 0.962129981818635
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9946582840971634, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9946582840971634
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9946582840971634, False)
Robot's weighted accuracy = 0.9707268231197372
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9949202652272191, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9949202652272191
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9949202652272191, False)
Robot's weighted accuracy = 0.9704164161583712
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9947772191216918, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9947772191216918
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947772191216918, False)
Robot's weighted accuracy = 0.9700847858764755
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9947778967141834, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9947778967141834
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947778967141834, False)
Robot's weighted accuracy = 0.9700847858764755
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9700847858764755)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9700847858764755
True human's confidence = 0.9947778652628411, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9947778652628411
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9947778652628411, False)
Robot's weighted accuracy = 0.9700847858764755
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9961343032413169, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9961343032413169
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9961343032413169, False)
Robot's weighted accuracy = 0.9768641477645008
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9971324809347121, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9971324809347121
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9971324809347121, False)
Robot's weighted accuracy = 0.9815832977442451
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9969964805250697, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9969964805250697
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9969964805250697, False)
Robot's weighted accuracy = 0.9814767818589347
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9968240646180148, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9968240646180148
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9968240646180148, False)
Robot's weighted accuracy = 0.9813489744632915
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9968247532492, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9968247532492
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9968247532492, False)
Robot's weighted accuracy = 0.9813489744632915
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002
