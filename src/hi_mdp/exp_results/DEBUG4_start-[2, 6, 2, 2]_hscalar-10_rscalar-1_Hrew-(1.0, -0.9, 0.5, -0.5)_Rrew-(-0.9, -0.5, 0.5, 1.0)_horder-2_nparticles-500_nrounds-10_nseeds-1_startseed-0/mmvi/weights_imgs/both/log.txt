
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.17137438852248016)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.17137438852248016
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.17137438852248016
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.19643344745975755
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.2652282096916179
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2968909832546043)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2968909832546043
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.2968909832546043
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7472208884492556
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7472208884492556, False)
Robot's weighted accuracy = 0.32271616451642526
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7869952504818568, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.7869952504818568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7869952504818568, False)
Robot's weighted accuracy = 0.4087292114652168
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273282, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8214225257273282
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8214225257273282, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8216590931070864, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033024, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8217097224033024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8217097224033024, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4067346603353936)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.4067346603353936
True human's confidence = 0.821719605437636, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.821719605437636
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.821719605437636, False)
Robot's weighted accuracy = 0.4067346603353936
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8576496009580737, False)
Robot's weighted accuracy = 0.430708480825263
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603414, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.8861823382603414
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8861823382603414, False)
Robot's weighted accuracy = 0.5165267814539174
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948706087917568, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.894867546234916, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.894867546234916
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.894867546234916, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602975, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8948678929602975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948678929602975, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5069358389078272)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.5069358389078272
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5069358389078272
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.868016054906262, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, -100, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5309669589125594
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.830396232737845, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.46972323975354097
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.7925803650039405, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.748454332694475, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6974745890459544, confidence scalar = 1.0
True human's acting weight vector = [-100, -100, -100, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.04972121809836244
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.7404387216046814)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.7404387216046814
True human's confidence = 0.6388063453122869, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6388063453122869
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6388063453122869, False)
Robot's weighted accuracy = 0.04972121809836244
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7036640954323179, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7036640954323179
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7036640954323179, False)
Robot's weighted accuracy = 0.04858004396253008
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7603016878379896, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.045609573808082005
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7676853082153653, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.03706068173964989
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6978616950728858, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6978616950728858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978616950728858, False)
Robot's weighted accuracy = 0.03262486628584118
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6978703318926834, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6978703318926834
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978703318926834, False)
Robot's weighted accuracy = 0.03262486628584118
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.816646795424525)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.816646795424525
True human's confidence = 0.6978621573503377, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6978621573503377
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978621573503377, False)
Robot's weighted accuracy = 0.03262486628584118
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7240788341925567, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7240788341925567
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7240788341925567, False)
Robot's weighted accuracy = 0.03134122890798908
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7446461316665638, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.028947322605591325
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5165986846988182, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.023453415927756616
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7102746663443382, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.7102746663443382
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7102746663443382, False)
Robot's weighted accuracy = 0.019224553016516713
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7102922866078215, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7102922866078215
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7102922866078215, False)
Robot's weighted accuracy = 0.019224553016516713
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8784262583971791)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8784262583971791
True human's confidence = 0.7103043521147616, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.7103043521147616
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7103043521147616, False)
Robot's weighted accuracy = 0.019224553016516713
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7186751894209664, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7186751894209664
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7186751894209664, False)
Robot's weighted accuracy = 0.018225995314367163
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7249649898288614, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7249649898288614
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7249649898288614, False)
Robot's weighted accuracy = 0.018453501393894633
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8887329583831054, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8887329583831054
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8887329583831054, False)
Robot's weighted accuracy = 0.018651959894174352
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9485878422183676, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9485878422183676
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485878422183676, False)
Robot's weighted accuracy = 0.01883920572635524
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9485907558607357, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9485907558607357
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485907558607357, False)
Robot's weighted accuracy = 0.01883920572635524
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9177882304555176)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9177882304555176
True human's confidence = 0.9485923073147383, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9485923073147383
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485923073147383, False)
Robot's weighted accuracy = 0.01883920572635524
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.95478981948588, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.95478981948588
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.95478981948588, False)
Robot's weighted accuracy = 0.017713164793357345
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9594048401485552, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9594048401485552
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9594048401485552, False)
Robot's weighted accuracy = 0.017797052158598104
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9777159103286032, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9777159103286032
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9777159103286032, False)
Robot's weighted accuracy = 0.017968849388264645
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.982421286907034, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.982421286907034
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.982421286907034, False)
Robot's weighted accuracy = 0.018134416989624133
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9824220826542678, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9824220826542678
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9824220826542678, False)
Robot's weighted accuracy = 0.018134416989624133
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9419206759039239)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9419206759039239
True human's confidence = 0.9824221259831132, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9824221259831132
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9824221259831132, False)
Robot's weighted accuracy = 0.018134416989624133
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9864018582787579, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9864018582787579
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9864018582787579, False)
Robot's weighted accuracy = 0.01696497644901552
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9893513328303194, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9893513328303194
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9893513328303194, False)
Robot's weighted accuracy = 0.016966332216640446
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9904472197037768, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9904472197037768
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9904472197037768, False)
Robot's weighted accuracy = 0.017120326887452367
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9903616260462637, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9903616260462637
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9903616260462637, False)
Robot's weighted accuracy = 0.017270827314951172
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9903622797364124, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9903622797364124
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9903622797364124, False)
Robot's weighted accuracy = 0.017270827314951172
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.17137438852248016
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.17137438852248016)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.17137438852248016
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.17137438852248016
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.19643344745975755
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.2652282096916179
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.2968909832546043
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2968909832546043)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2968909832546043
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.2968909832546043
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7472208884492556
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7472208884492556, False)
Robot's weighted accuracy = 0.32271616451642526
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7869952504818568, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.7869952504818568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7869952504818568, False)
Robot's weighted accuracy = 0.4087292114652168
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273282, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8214225257273282
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8214225257273282, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8216590931070864, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033024, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8217097224033024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8217097224033024, False)
Robot's weighted accuracy = 0.4067346603353936
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4067346603353936)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.4067346603353936
True human's confidence = 0.821719605437636, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.821719605437636
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.821719605437636, False)
Robot's weighted accuracy = 0.4067346603353936
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8576496009580737, False)
Robot's weighted accuracy = 0.430708480825263
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603414, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.8861823382603414
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8861823382603414, False)
Robot's weighted accuracy = 0.5165267814539174
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948706087917568, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.894867546234916, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.894867546234916
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.894867546234916, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602975, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8948678929602975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948678929602975, False)
Robot's weighted accuracy = 0.5069358389078272
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5069358389078272)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.5069358389078272
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5069358389078272
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.868016054906262, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, -100, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5309669589125594
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.830396232737845, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.46972323975354097
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.7925803650039405, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.748454332694475, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6974745890459544, confidence scalar = 1.0
True human's acting weight vector = [-100, -100, -100, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.04972121809836244
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.7404387216046814)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.7404387216046814
True human's confidence = 0.6388063453122869, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6388063453122869
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6388063453122869, False)
Robot's weighted accuracy = 0.04972121809836244
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7036640954323179, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7036640954323179
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7036640954323179, False)
Robot's weighted accuracy = 0.04858004396253008
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7603016878379896, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.045609573808082005
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7676853082153653, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.03706068173964989
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6978616950728858, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6978616950728858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978616950728858, False)
Robot's weighted accuracy = 0.03262486628584118
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6978703318926834, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6978703318926834
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978703318926834, False)
Robot's weighted accuracy = 0.03262486628584118
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.816646795424525)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.816646795424525
True human's confidence = 0.6978621573503377, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6978621573503377
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6978621573503377, False)
Robot's weighted accuracy = 0.03262486628584118
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7240788341925567, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7240788341925567
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7240788341925567, False)
Robot's weighted accuracy = 0.03134122890798908
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7446461316665638, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.028947322605591325
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5165986846988182, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.023453415927756616
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7102746663443382, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.7102746663443382
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7102746663443382, False)
Robot's weighted accuracy = 0.019224553016516713
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7102922866078215, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7102922866078215
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7102922866078215, False)
Robot's weighted accuracy = 0.019224553016516713
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8784262583971791)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8784262583971791
True human's confidence = 0.7103043521147616, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.7103043521147616
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7103043521147616, False)
Robot's weighted accuracy = 0.019224553016516713
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7186751894209664, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7186751894209664
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7186751894209664, False)
Robot's weighted accuracy = 0.018225995314367163
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7249649898288614, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.7249649898288614
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7249649898288614, False)
Robot's weighted accuracy = 0.018453501393894633
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8887329583831054, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.8887329583831054
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.8887329583831054, False)
Robot's weighted accuracy = 0.018651959894174352
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9485878422183676, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9485878422183676
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485878422183676, False)
Robot's weighted accuracy = 0.01883920572635524
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9485907558607357, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9485907558607357
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485907558607357, False)
Robot's weighted accuracy = 0.01883920572635524
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9177882304555176)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9177882304555176
True human's confidence = 0.9485923073147383, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9485923073147383
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9485923073147383, False)
Robot's weighted accuracy = 0.01883920572635524
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.95478981948588, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.95478981948588
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.95478981948588, False)
Robot's weighted accuracy = 0.017713164793357345
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9594048401485552, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9594048401485552
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9594048401485552, False)
Robot's weighted accuracy = 0.017797052158598104
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9777159103286032, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9777159103286032
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9777159103286032, False)
Robot's weighted accuracy = 0.017968849388264645
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.982421286907034, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.982421286907034
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.982421286907034, False)
Robot's weighted accuracy = 0.018134416989624133
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9824220826542678, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9824220826542678
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9824220826542678, False)
Robot's weighted accuracy = 0.018134416989624133
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9419206759039239)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9419206759039239
True human's confidence = 0.9824221259831132, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9824221259831132
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9824221259831132, False)
Robot's weighted accuracy = 0.018134416989624133
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9864018582787579, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9864018582787579
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9864018582787579, False)
Robot's weighted accuracy = 0.01696497644901552
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9893513328303194, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9893513328303194
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9893513328303194, False)
Robot's weighted accuracy = 0.016966332216640446
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9904472197037768, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9904472197037768
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9904472197037768, False)
Robot's weighted accuracy = 0.017120326887452367
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9903616260462637, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, -100, -100]
True human's accuracy on robot = 0.9903616260462637
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9903616260462637, False)
Robot's weighted accuracy = 0.017270827314951172
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9903622797364124, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9903622797364124
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9903622797364124, False)
Robot's weighted accuracy = 0.017270827314951172
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002
