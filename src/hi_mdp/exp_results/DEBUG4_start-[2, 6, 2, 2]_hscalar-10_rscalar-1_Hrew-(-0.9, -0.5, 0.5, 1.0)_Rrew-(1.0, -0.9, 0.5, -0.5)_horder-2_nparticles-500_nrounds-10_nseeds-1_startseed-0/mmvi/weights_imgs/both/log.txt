
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.020833333333333332
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.0, False)
Robot's weighted accuracy = 0.04207920792079207
robot red, human yellow --> [1, 6, 1, 0]

Current state = [1, 6, 1, 0]
True human's confidence = 0.1670811159029145, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, -100, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.0, False)
Robot's weighted accuracy = 0.05201583873290134
robot red, human green --> [1, 5, 0, 0]

Current state = [1, 5, 0, 0]
True human's confidence = 0.2157852439306359, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.2157852439306359
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.2157852439306359, False)
Robot's weighted accuracy = 0.08019669979437648
No need to update robot beliefs
robot blue, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.25229218899775163, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.25229218899775163
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.25229218899775163, False)
Robot's weighted accuracy = 0.08019669979437648
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.36168613917871645, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.36168613917871645
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.36168613917871645, False)
Robot's weighted accuracy = 0.08019669979437648
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, 0.5, -0.5, 1.0), 0, 0.08019669979437648)
Robot's own rewards + human pref = [ 0.1 -0.4  0.   0.5]
Robot's confidence = 0.08019669979437648
True human's confidence = 0.4678779898682239, confidence scalar = 1.0
True human's acting weight vector = [0.09999999999999998, 0.5, 1.5, 2.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.08019669979437648
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.4545915158286429, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.4545915158286429
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4545915158286429, False)
Robot's weighted accuracy = 0.08730907419505919
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5279276663069964, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.5279276663069964
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5279276663069964, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.5219577733468725, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5219577733468725
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5219577733468725, False)
Robot's weighted accuracy = 0.19286663797061335
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5573371229040437, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5573371229040437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5573371229040437, False)
Robot's weighted accuracy = 0.19286663797061335
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5654940462670671, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.5654940462670671
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5654940462670671, False)
Robot's weighted accuracy = 0.19286663797061335
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.2724933893088826)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.2724933893088826
True human's confidence = 0.5672601927385797, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.5672601927385797
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5672601927385797, False)
Robot's weighted accuracy = 0.19286663797061335
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6392957949697735, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6392957949697735
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6392957949697735, False)
Robot's weighted accuracy = 0.20214605117387796
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.704352768665877, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.1925788899418224
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7256668519668248, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.18984352451512887
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6787444638690738, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6787444638690738
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787444638690738, False)
Robot's weighted accuracy = 0.19400252622311095
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6787544456401579, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6787544456401579
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787544456401579, False)
Robot's weighted accuracy = 0.19400252622311095
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.4607277862931198)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.4607277862931198
True human's confidence = 0.6787474073491075, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6787474073491075
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787474073491075, False)
Robot's weighted accuracy = 0.19400252622311095
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7139218500496695, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.7139218500496695
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7139218500496695, False)
Robot's weighted accuracy = 0.19768123588991202
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7420628433368337, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.18801378164749583
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5381079149941013, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.15881343236954018
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6536831304275558, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.6536831304275558
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6536831304275558, False)
Robot's weighted accuracy = 0.1327306554855064
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.653701047904437, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.653701047904437
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.653701047904437, False)
Robot's weighted accuracy = 0.1327306554855064
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.5828262495837653)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.5828262495837653
True human's confidence = 0.6537133003457248, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6537133003457248
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6537133003457248, False)
Robot's weighted accuracy = 0.1327306554855064
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6675160101557064, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6675160101557064
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6675160101557064, False)
Robot's weighted accuracy = 0.13148516393265644
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.6780483317289008, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.6780483317289008
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6780483317289008, False)
Robot's weighted accuracy = 0.121290334443544
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8539430251736613, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.8539430251736613
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.8539430251736613, False)
Robot's weighted accuracy = 0.10058468146790828
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9196445018971217, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9196445018971217
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9196445018971217, False)
Robot's weighted accuracy = 0.08300116015988973
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.919647524515601, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.919647524515601
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.919647524515601, False)
Robot's weighted accuracy = 0.08300116015988973
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.6738804722210827)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.6738804722210827
True human's confidence = 0.9196491319921591, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9196491319921591
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9196491319921591, False)
Robot's weighted accuracy = 0.08300116015988973
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9318153073182329, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9318153073182329
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9318153073182329, False)
Robot's weighted accuracy = 0.08062434888432367
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9409838378606769, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9409838378606769
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9409838378606769, False)
Robot's weighted accuracy = 0.0728499409696998
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9613121185709562, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9613121185709562
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9613121185709562, False)
Robot's weighted accuracy = 0.059858897614526944
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9659648431349058, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9659648431349058
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659648431349058, False)
Robot's weighted accuracy = 0.055927571154797705
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9659655423331397, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9659655423331397
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659655423331397, False)
Robot's weighted accuracy = 0.055927571154797705
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.7359667142759249)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.7359667142759249
True human's confidence = 0.9659655014303848, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9659655014303848
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659655014303848, False)
Robot's weighted accuracy = 0.055927571154797705
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.974017369891418, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.974017369891418
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.974017369891418, False)
Robot's weighted accuracy = 0.053641044922761276
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9800331090343731, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9800331090343731
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9800331090343731, False)
Robot's weighted accuracy = 0.053087439914866266
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9808571390147179, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9808571390147179
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9808571390147179, False)
Robot's weighted accuracy = 0.05423997488186562
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9802756659711547, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9802756659711547
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802756659711547, False)
Robot's weighted accuracy = 0.0552957336506329
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9802762412519936, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9802762412519936
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802762412519936, False)
Robot's weighted accuracy = 0.0552957336506329
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.7758087531399357)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.7758087531399357
True human's confidence = 0.9802761225394518, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9802761225394518
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802761225394518, False)
Robot's weighted accuracy = 0.0552957336506329
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9853379148212926, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9853379148212926
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9853379148212926, False)
Robot's weighted accuracy = 0.05261398223572461
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9890975795997264, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9890975795997264
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9890975795997264, False)
Robot's weighted accuracy = 0.055186941071888915
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.988590045845315, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.988590045845315
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.988590045845315, False)
Robot's weighted accuracy = 0.052612093507269676
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9879377085773392, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9879377085773392
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879377085773392, False)
Robot's weighted accuracy = 0.053521734306586535
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9879383257822124, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9879383257822124
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879383257822124, False)
Robot's weighted accuracy = 0.053521734306586535
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8006156318569722)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8006156318569722
True human's confidence = 0.9879382442805891, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9879382442805891
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879382442805891, False)
Robot's weighted accuracy = 0.053521734306586535
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9910834716423802, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9910834716423802
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9910834716423802, False)
Robot's weighted accuracy = 0.05066962333966239
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9934101882427278, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9934101882427278
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9934101882427278, False)
Robot's weighted accuracy = 0.05961616938954161
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9930101296002868, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9930101296002868
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9930101296002868, False)
Robot's weighted accuracy = 0.05404177890322946
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9925826647885279, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9925826647885279
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925826647885279, False)
Robot's weighted accuracy = 0.05115240980905943
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9925833182030012, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9925833182030012
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925833182030012, False)
Robot's weighted accuracy = 0.05115240980905943
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8158133780394337)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8158133780394337
True human's confidence = 0.9925832671868698, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9925832671868698
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925832671868698, False)
Robot's weighted accuracy = 0.05115240980905943
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9945280634428852, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9945280634428852
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9945280634428852, False)
Robot's weighted accuracy = 0.048266161607328155
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9959622849818344, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9959622849818344
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9959622849818344, False)
Robot's weighted accuracy = 0.06379706041833409
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9957061547432933, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9957061547432933
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9957061547432933, False)
Robot's weighted accuracy = 0.057818304773474063
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.995440503103397, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.995440503103397
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.995440503103397, False)
Robot's weighted accuracy = 0.052338342227310916
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9954411798314852, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9954411798314852
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9954411798314852, False)
Robot's weighted accuracy = 0.052338342227310916
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036
