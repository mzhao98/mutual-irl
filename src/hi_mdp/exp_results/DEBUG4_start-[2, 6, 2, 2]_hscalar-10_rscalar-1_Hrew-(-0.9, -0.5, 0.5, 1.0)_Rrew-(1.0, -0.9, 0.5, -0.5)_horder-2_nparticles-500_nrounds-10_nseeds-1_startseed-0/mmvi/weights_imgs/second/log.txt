
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.0, False)
Robot's weighted accuracy = 0.08415841584158418
robot red, human yellow --> [1, 6, 1, 0]

Current state = [1, 6, 1, 0]
True human's confidence = 0.1670811159029145, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, -100, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.0, False)
Robot's weighted accuracy = 0.1040316774658027
robot red, human green --> [1, 5, 0, 0]

Current state = [1, 5, 0, 0]
True human's confidence = 0.2157852439306359, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.2157852439306359
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.2157852439306359, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot blue, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.25229218899775163, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.25229218899775163
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.25229218899775163, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.36168613917871645, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.36168613917871645
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.36168613917871645, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, 0.5, -0.9, 1.0), 1, 0.1309061729759762)
Robot's own rewards + human pref = [ 0.5 -0.4 -0.4  0.5]
Robot's confidence = 0.1309061729759762
True human's confidence = 0.4678779898682239, confidence scalar = 1.0
True human's acting weight vector = [0.09999999999999998, 0.5, 1.5, 2.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.1309061729759762
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.4545915158286429, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.4545915158286429
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4545915158286429, False)
Robot's weighted accuracy = 0.15081269891655386
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5279276663069964, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.5279276663069964
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5279276663069964, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.5219577733468725, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5219577733468725
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5219577733468725, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5573371229040437, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5573371229040437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5573371229040437, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5654940462670671, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.5654940462670671
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5654940462670671, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.4528697683358175)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.4528697683358175
True human's confidence = 0.5672601927385797, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.5672601927385797
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5672601927385797, False)
Robot's weighted accuracy = 0.4528697683358175
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6392957949697735, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6392957949697735
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6392957949697735, False)
Robot's weighted accuracy = 0.5065402005953551
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.704352768665877, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.5211726650175337
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7256668519668248, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.5778471283637285
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6787444638690738, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6787444638690738
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787444638690738, False)
Robot's weighted accuracy = 0.6713537034576962
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6787544456401579, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6787544456401579
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787544456401579, False)
Robot's weighted accuracy = 0.6713537034576962
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.6713537034576962)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.6713537034576962
True human's confidence = 0.6787474073491075, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6787474073491075
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6787474073491075, False)
Robot's weighted accuracy = 0.6713537034576962
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7139218500496695, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.7139218500496695
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7139218500496695, False)
Robot's weighted accuracy = 0.7296434370074913
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7420628433368337, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.7660213350575757
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5381079149941013, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.7646913515851371
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6536831304275558, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.6536831304275558
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6536831304275558, False)
Robot's weighted accuracy = 0.7627444893407604
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.653701047904437, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.653701047904437
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.653701047904437, False)
Robot's weighted accuracy = 0.7627444893407604
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.7627444893407604)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.7627444893407604
True human's confidence = 0.6537133003457248, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6537133003457248
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6537133003457248, False)
Robot's weighted accuracy = 0.7627444893407604
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6675160101557064, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6675160101557064
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6675160101557064, False)
Robot's weighted accuracy = 0.8055580438761216
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.6780483317289008, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.6780483317289008
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.6780483317289008, False)
Robot's weighted accuracy = 0.8267060627033166
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8539430251736613, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.8539430251736613
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.8539430251736613, False)
Robot's weighted accuracy = 0.8258407789002485
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9196445018971217, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9196445018971217
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9196445018971217, False)
Robot's weighted accuracy = 0.8248371793098286
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.919647524515601, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.919647524515601
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.919647524515601, False)
Robot's weighted accuracy = 0.8248371793098286
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8248371793098286)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8248371793098286
True human's confidence = 0.9196491319921591, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9196491319921591
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9196491319921591, False)
Robot's weighted accuracy = 0.8248371793098286
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9318153073182329, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9318153073182329
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9318153073182329, False)
Robot's weighted accuracy = 0.8551655833128443
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9409838378606769, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9409838378606769
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9409838378606769, False)
Robot's weighted accuracy = 0.8652798548092749
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9613121185709562, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9613121185709562
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9613121185709562, False)
Robot's weighted accuracy = 0.86521039513891
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9659648431349058, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9659648431349058
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659648431349058, False)
Robot's weighted accuracy = 0.8649864192701209
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9659655423331397, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9659655423331397
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659655423331397, False)
Robot's weighted accuracy = 0.8649864192701209
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8649864192701209)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8649864192701209
True human's confidence = 0.9659655014303848, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9659655014303848
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9659655014303848, False)
Robot's weighted accuracy = 0.8649864192701209
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.974017369891418, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.974017369891418
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.974017369891418, False)
Robot's weighted accuracy = 0.8865702712844739
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9800331090343731, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9800331090343731
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9800331090343731, False)
Robot's weighted accuracy = 0.8894876316987822
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9808571390147179, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9808571390147179
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9808571390147179, False)
Robot's weighted accuracy = 0.890060967027577
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9802756659711547, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9802756659711547
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802756659711547, False)
Robot's weighted accuracy = 0.8904524712765893
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9802762412519936, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9802762412519936
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802762412519936, False)
Robot's weighted accuracy = 0.8904524712765893
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8904524712765893)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8904524712765893
True human's confidence = 0.9802761225394518, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9802761225394518
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9802761225394518, False)
Robot's weighted accuracy = 0.8904524712765893
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9853379148212926, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9853379148212926
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9853379148212926, False)
Robot's weighted accuracy = 0.906231549075004
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9890975795997264, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9890975795997264
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9890975795997264, False)
Robot's weighted accuracy = 0.9045673236505903
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.988590045845315, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.988590045845315
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.988590045845315, False)
Robot's weighted accuracy = 0.9056939697777036
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9879377085773392, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9879377085773392
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879377085773392, False)
Robot's weighted accuracy = 0.90660572916801
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9879383257822124, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9879383257822124
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879383257822124, False)
Robot's weighted accuracy = 0.90660572916801
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.90660572916801)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.90660572916801
True human's confidence = 0.9879382442805891, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9879382442805891
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9879382442805891, False)
Robot's weighted accuracy = 0.90660572916801
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9910834716423802, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9910834716423802
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9910834716423802, False)
Robot's weighted accuracy = 0.9185272779402278
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9934101882427278, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9934101882427278
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9934101882427278, False)
Robot's weighted accuracy = 0.9138403989988709
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9930101296002868, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9930101296002868
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9930101296002868, False)
Robot's weighted accuracy = 0.9154897853824242
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9925826647885279, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.9925826647885279
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925826647885279, False)
Robot's weighted accuracy = 0.9168850730331011
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9925833182030012, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9925833182030012
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925833182030012, False)
Robot's weighted accuracy = 0.9168850730331011
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.9168850730331011)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.9168850730331011
True human's confidence = 0.9925832671868698, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9925832671868698
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9925832671868698, False)
Robot's weighted accuracy = 0.9168850730331011
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9945280634428852, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9945280634428852
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9945280634428852, False)
Robot's weighted accuracy = 0.9261406809212276
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9959622849818344, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9959622849818344
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9959622849818344, False)
Robot's weighted accuracy = 0.919265325406527
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9957061547432933, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, -100]
True human's accuracy on robot = 0.9957061547432933
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9957061547432933, False)
Robot's weighted accuracy = 0.921449657763954
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.995440503103397, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, -100, -100]
True human's accuracy on robot = 0.995440503103397
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.995440503103397, False)
Robot's weighted accuracy = 0.9233340138782409
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9954411798314852, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9954411798314852
True human's belief of robot = ((1.0, 0.5, -0.5, -0.9), 0.9954411798314852, False)
Robot's weighted accuracy = 0.9233340138782409
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036
