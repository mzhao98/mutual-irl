
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.020833333333333332
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083802, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, -100]
True human's accuracy on robot = 0.10500240700083802
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.10500240700083802, False)
Robot's weighted accuracy = 0.06391570135371297
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.21000654452150003, False)
Robot's weighted accuracy = 0.1713743885224802
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.3437165464086288, False)
Robot's weighted accuracy = 0.1713743885224802
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595855, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.4492923398595855
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4492923398595855, False)
Robot's weighted accuracy = 0.1713743885224802
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.1713743885224802)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.1713743885224802
True human's confidence = 0.48070515402728814, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.48070515402728814
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.48070515402728814, False)
Robot's weighted accuracy = 0.1713743885224802
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245772, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.5413770316245772
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5413770316245772, False)
Robot's weighted accuracy = 0.19643344745975758
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069077, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.5884064503069077
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5884064503069077, False)
Robot's weighted accuracy = 0.2652282096916178
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.6793929394751769, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6793929394751769
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6793929394751769, False)
Robot's weighted accuracy = 0.2968909832546042
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183346, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6947308595183346
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6947308595183346, False)
Robot's weighted accuracy = 0.2968909832546042
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075372, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6980829022075372
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6980829022075372, False)
Robot's weighted accuracy = 0.2968909832546042
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.2968909832546042)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.2968909832546042
True human's confidence = 0.6987978089480569, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6987978089480569
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6987978089480569, False)
Robot's weighted accuracy = 0.2968909832546042
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492555, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.7472208884492555
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7472208884492555, False)
Robot's weighted accuracy = 0.3227161645164254
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.786995250481857, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.786995250481857
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.786995250481857, False)
Robot's weighted accuracy = 0.4087292114652169
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273281, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8214225257273281
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8214225257273281, False)
Robot's weighted accuracy = 0.40673466033539374
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8216590931070864, False)
Robot's weighted accuracy = 0.40673466033539374
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033023, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8217097224033023
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8217097224033023, False)
Robot's weighted accuracy = 0.40673466033539374
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.40673466033539374)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.40673466033539374
True human's confidence = 0.8217196054376359, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8217196054376359
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8217196054376359, False)
Robot's weighted accuracy = 0.40673466033539374
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8576496009580737, False)
Robot's weighted accuracy = 0.4307084808252629
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603411, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.8861823382603411
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8861823382603411, False)
Robot's weighted accuracy = 0.5165267814539175
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8948706087917568, False)
Robot's weighted accuracy = 0.5069358389078271
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8948675462349159, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8948675462349159
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8948675462349159, False)
Robot's weighted accuracy = 0.5069358389078271
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602973, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8948678929602973
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8948678929602973, False)
Robot's weighted accuracy = 0.5069358389078271
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.5069358389078271)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.5069358389078271
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8948676789039607
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8948676789039607, False)
Robot's weighted accuracy = 0.5069358389078271
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9188500665403389, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9188500665403389
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9188500665403389, False)
Robot's weighted accuracy = 0.5274213182752652
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9373563415651057, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9373563415651057
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9373563415651057, False)
Robot's weighted accuracy = 0.607180879211618
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9383457033307511, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9383457033307511
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9383457033307511, False)
Robot's weighted accuracy = 0.5957203592372043
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9383392698173353, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9383392698173353
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9383392698173353, False)
Robot's weighted accuracy = 0.5957203592372043
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9383391665376024, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9383391665376024
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9383391665376024, False)
Robot's weighted accuracy = 0.5957203592372043
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.5957203592372043)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.5957203592372043
True human's confidence = 0.9383390559555314, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9383390559555314
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9383390559555314, False)
Robot's weighted accuracy = 0.5957203592372043
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9533640444125245, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9533640444125245
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9533640444125245, False)
Robot's weighted accuracy = 0.6122973389383769
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9647430448542946, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9647430448542946
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9647430448542946, False)
Robot's weighted accuracy = 0.68377191972183
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9640181763208248, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9640181763208248
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9640181763208248, False)
Robot's weighted accuracy = 0.6720601011598503
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9640115986047526, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9640115986047526
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9640115986047526, False)
Robot's weighted accuracy = 0.6720601011598503
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9640115650018919, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9640115650018919
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9640115650018919, False)
Robot's weighted accuracy = 0.6720601011598503
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.6720601011598503)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.6720601011598503
True human's confidence = 0.9640115313680409, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9640115313680409
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9640115313680409, False)
Robot's weighted accuracy = 0.6720601011598503
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9730968913520859, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9730968913520859
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9730968913520859, False)
Robot's weighted accuracy = 0.6849903024616908
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9798980805353044, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9798980805353044
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9798980805353044, False)
Robot's weighted accuracy = 0.7474763203436611
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9790815517368663, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9790815517368663
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9790815517368663, False)
Robot's weighted accuracy = 0.7362711402274628
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9790748947147245, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9790748947147245
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9790748947147245, False)
Robot's weighted accuracy = 0.7362711402274628
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9790748847653353, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9790748847653353
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9790748847653353, False)
Robot's weighted accuracy = 0.7362711402274628
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.7362711402274628)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.7362711402274628
True human's confidence = 0.9790748748805803, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9790748748805803
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9790748748805803, False)
Robot's weighted accuracy = 0.7362711402274628
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9844604644317697, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9844604644317697
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9844604644317697, False)
Robot's weighted accuracy = 0.7460787399516826
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.988463207124498, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.988463207124498
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.988463207124498, False)
Robot's weighted accuracy = 0.7996597414801944
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9878723272486288, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9878723272486288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9878723272486288, False)
Robot's weighted accuracy = 0.7893989694099413
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9878656182980504, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9878656182980504
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9878656182980504, False)
Robot's weighted accuracy = 0.7893989694099413
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9878656153598788, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9878656153598788
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9878656153598788, False)
Robot's weighted accuracy = 0.7893989694099413
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.7893989694099413)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.7893989694099413
True human's confidence = 0.9878656124885694, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9878656124885694
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9878656124885694, False)
Robot's weighted accuracy = 0.7893989694099413
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9910228150787201, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9910228150787201
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9910228150787201, False)
Robot's weighted accuracy = 0.7966642384949849
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9933584542708326, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9933584542708326
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9933584542708326, False)
Robot's weighted accuracy = 0.8418742229496227
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9929817515077732, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9929817515077732
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9929817515077732, False)
Robot's weighted accuracy = 0.8327855520619837
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9929750106123764, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9929750106123764
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9929750106123764, False)
Robot's weighted accuracy = 0.8327855520619837
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9929750097165214, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9929750097165214
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9929750097165214, False)
Robot's weighted accuracy = 0.8327855520619837
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.8327855520619837)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.8327855520619837
True human's confidence = 0.9929750088880178, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9929750088880178
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9929750088880178, False)
Robot's weighted accuracy = 0.8327855520619837
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9948148927573446, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9948148927573446
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9948148927573446, False)
Robot's weighted accuracy = 0.8380545832006427
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9961712947472521, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9961712947472521
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9961712947472521, False)
Robot's weighted accuracy = 0.8756843870003352
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9959430878997986, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9959430878997986
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9959430878997986, False)
Robot's weighted accuracy = 0.8678400353943152
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9959363279746815, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9959363279746815
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9959363279746815, False)
Robot's weighted accuracy = 0.8678400353943152
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9959363276689817, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9959363276689817
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9959363276689817, False)
Robot's weighted accuracy = 0.8678400353943152
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003
