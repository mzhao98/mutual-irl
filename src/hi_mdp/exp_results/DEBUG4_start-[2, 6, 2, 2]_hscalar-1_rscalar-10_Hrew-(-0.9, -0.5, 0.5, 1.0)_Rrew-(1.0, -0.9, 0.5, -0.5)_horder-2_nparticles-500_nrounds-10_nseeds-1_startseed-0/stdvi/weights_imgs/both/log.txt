
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.020833333333333332
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083802, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, -100]
True human's accuracy on robot = 0.10500240700083802
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.10500240700083802, False)
Robot's weighted accuracy = 0.06391570135371297
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 1.0
True human's acting weight vector = [-100, -9.5, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.21000654452150003, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.3437165464086288, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595855, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.4492923398595855
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4492923398595855, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.21216027188954972)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.21216027188954972
True human's confidence = 0.48070515402728814, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.48070515402728814
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.48070515402728814, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.5413770316245772, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.5413770316245772
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5413770316245772, False)
Robot's weighted accuracy = 0.37580739205429964
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.6315893885871271, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.6315893885871271
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6315893885871271, False)
Robot's weighted accuracy = 0.4279178282364922
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.6528349233325377, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6528349233325377
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6528349233325377, False)
Robot's weighted accuracy = 0.4384904792560557
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.659380035285494, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.659380035285494
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.659380035285494, False)
Robot's weighted accuracy = 0.4384904792560557
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6607901863024207, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6607901863024207
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6607901863024207, False)
Robot's weighted accuracy = 0.4384904792560557
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.4384904792560557)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.4384904792560557
True human's confidence = 0.6610902553142691, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6610902553142691
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6610902553142691, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7240489505821456, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7240489505821456
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7240489505821456, False)
Robot's weighted accuracy = 0.47777051216544886
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7228171126451196, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7228171126451196
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7228171126451196, False)
Robot's weighted accuracy = 0.47259614050607995
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.713668445558397, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.713668445558397
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.713668445558397, False)
Robot's weighted accuracy = 0.4757424336530533
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7137285451106544, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7137285451106544
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137285451106544, False)
Robot's weighted accuracy = 0.4757424336530533
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7137425435671229, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7137425435671229
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137425435671229, False)
Robot's weighted accuracy = 0.4757424336530533
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4757424336530533)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.4757424336530533
True human's confidence = 0.7137454526300796, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7137454526300796
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137454526300796, False)
Robot's weighted accuracy = 0.4757424336530533
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7717632218286734, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7717632218286734
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717632218286734, False)
Robot's weighted accuracy = 0.5506392450209336
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.761915160010201, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.761915160010201
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.761915160010201, False)
Robot's weighted accuracy = 0.5377515158594032
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7510786495647405, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7510786495647405
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510786495647405, False)
Robot's weighted accuracy = 0.5404534806625173
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7510729900426527, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7510729900426527
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510729900426527, False)
Robot's weighted accuracy = 0.5404534806625173
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7510731244007368, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7510731244007368
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510731244007368, False)
Robot's weighted accuracy = 0.5404534806625173
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5404534806625173)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.5404534806625173
True human's confidence = 0.7510731465699969, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7510731465699969
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510731465699969, False)
Robot's weighted accuracy = 0.5404534806625173
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.803718628948884, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.803718628948884
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.803718628948884, False)
Robot's weighted accuracy = 0.6088072954261341
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7941191522875096, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7941191522875096
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7941191522875096, False)
Robot's weighted accuracy = 0.5945041027829885
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7841157671860204, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7841157671860204
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841157671860204, False)
Robot's weighted accuracy = 0.596776818104006
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7841091757008031, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7841091757008031
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091757008031, False)
Robot's weighted accuracy = 0.596776818104006
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7841091762923512, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7841091762923512
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091762923512, False)
Robot's weighted accuracy = 0.596776818104006
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.596776818104006)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.596776818104006
True human's confidence = 0.7841091758189433, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7841091758189433
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091758189433, False)
Robot's weighted accuracy = 0.596776818104006
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8313437440000634, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8313437440000634
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313437440000634, False)
Robot's weighted accuracy = 0.6611457821776892
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.822732289283442, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.822732289283442
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.822732289283442, False)
Robot's weighted accuracy = 0.6471940862489824
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8137743519325505, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8137743519325505
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137743519325505, False)
Robot's weighted accuracy = 0.6490680336928942
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8137675071579438, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8137675071579438
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137675071579438, False)
Robot's weighted accuracy = 0.6490680336928942
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.813767507027604, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.813767507027604
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.813767507027604, False)
Robot's weighted accuracy = 0.6490680336928942
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.6490680336928942)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.6490680336928942
True human's confidence = 0.8137675069543859, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8137675069543859
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137675069543859, False)
Robot's weighted accuracy = 0.6490680336928942
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.855707882408424, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.855707882408424
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.855707882408424, False)
Robot's weighted accuracy = 0.7090225179501617
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8481076444066388, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8481076444066388
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8481076444066388, False)
Robot's weighted accuracy = 0.6960192392234694
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8401813863926879, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8401813863926879
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401813863926879, False)
Robot's weighted accuracy = 0.6975348734945809
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8401743215892592, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8401743215892592
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215892592, False)
Robot's weighted accuracy = 0.6975348734945809
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8401743215110946, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8401743215110946
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215110946, False)
Robot's weighted accuracy = 0.6975348734945809
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.6975348734945809)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.6975348734945809
True human's confidence = 0.8401743215034707, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8401743215034707
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215034707, False)
Robot's weighted accuracy = 0.6975348734945809
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.87706664526403, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.87706664526403
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.87706664526403, False)
Robot's weighted accuracy = 0.7523558483878395
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8704206931027546, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8704206931027546
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8704206931027546, False)
Robot's weighted accuracy = 0.740547885646041
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8634713582879924, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8634713582879924
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634713582879924, False)
Robot's weighted accuracy = 0.7417513856728704
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8634640995435596, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8634640995435596
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640995435596, False)
Robot's weighted accuracy = 0.7417513856728704
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8634640994701803, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8634640994701803
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640994701803, False)
Robot's weighted accuracy = 0.7417513856728704
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.7417513856728704)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.7417513856728704
True human's confidence = 0.8634640994693933, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8634640994693933
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640994693933, False)
Robot's weighted accuracy = 0.7417513856728704
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8956487323231971, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8956487323231971
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956487323231971, False)
Robot's weighted accuracy = 0.7909682535668123
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8898813013004102, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8898813013004102
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8898813013004102, False)
Robot's weighted accuracy = 0.7804531653988122
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8838364881137106, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8838364881137106
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838364881137106, False)
Robot's weighted accuracy = 0.7813927680477672
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8838290598631652, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8838290598631652
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838290598631652, False)
Robot's weighted accuracy = 0.7813927680477672
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.883829059788793, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.883829059788793
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.883829059788793, False)
Robot's weighted accuracy = 0.7813927680477672
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.7813927680477672)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.7813927680477672
True human's confidence = 0.8838290597887094, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8838290597887094
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838290597887094, False)
Robot's weighted accuracy = 0.7813927680477672
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9117046696944069, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9117046696944069
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9117046696944069, False)
Robot's weighted accuracy = 0.8248503671354916
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9067323494187258, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9067323494187258
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9067323494187258, False)
Robot's weighted accuracy = 0.8156371655540219
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9015103257897921, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9015103257897921
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015103257897921, False)
Robot's weighted accuracy = 0.8163596515338327
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9015027504963864, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9015027504963864
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015027504963864, False)
Robot's weighted accuracy = 0.8163596515338327
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9015027504206174, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9015027504206174
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015027504206174, False)
Robot's weighted accuracy = 0.8163596515338327
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.020833333333333332
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083802, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, -100]
True human's accuracy on robot = 0.10500240700083802
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.10500240700083802, False)
Robot's weighted accuracy = 0.06391570135371297
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.21000654452150003, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.3437165464086288, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595855, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.4492923398595855
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4492923398595855, False)
Robot's weighted accuracy = 0.21216027188954972
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.21216027188954972)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.21216027188954972
True human's confidence = 0.48070515402728814, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.48070515402728814
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.48070515402728814, False)
Robot's weighted accuracy = 0.21216027188954972
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245772, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, 5.5, 6.0]
True human's accuracy on robot = 0.5413770316245772
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5413770316245772, False)
Robot's weighted accuracy = 0.2437113784032622
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069077, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, -100]
True human's accuracy on robot = 0.5884064503069077
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5884064503069077, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.6793929394751769, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6793929394751769
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6793929394751769, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6973305740283453, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6973305740283453
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6973305740283453, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7182595441686, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7182595441686
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7182595441686, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, 0.5, -0.5, 1.0), 0, 0.12733760161121618)
Robot's own rewards + human pref = [ 0.1 -0.4  0.   0.5]
Robot's confidence = 0.12733760161121618
True human's confidence = 0.7228767288415244, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7228767288415244
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7228767288415244, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7760899422280437, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7760899422280437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7760899422280437, False)
Robot's weighted accuracy = 0.2809365812961432
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7780627848696251, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7780627848696251
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7780627848696251, False)
Robot's weighted accuracy = 0.2956933270807328
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7710282978922527, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7710282978922527
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7710282978922527, False)
Robot's weighted accuracy = 0.32837449986970774
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7716026016584243, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7716026016584243
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7716026016584243, False)
Robot's weighted accuracy = 0.32837449986970774
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7717262356440154, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7717262356440154
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717262356440154, False)
Robot's weighted accuracy = 0.32837449986970774
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.32837449986970774)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.32837449986970774
True human's confidence = 0.7717524813754815, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7717524813754815
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717524813754815, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.820773635465447, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.820773635465447
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.820773635465447, False)
Robot's weighted accuracy = 0.3015925374281035
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8127689765620019, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8127689765620019
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8127689765620019, False)
Robot's weighted accuracy = 0.311144471619485
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8037135765943846, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8037135765943846
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037135765943846, False)
Robot's weighted accuracy = 0.33995770854042945
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8037123078161096, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8037123078161096
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037123078161096, False)
Robot's weighted accuracy = 0.33995770854042945
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8037134705615637, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8037134705615637
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037134705615637, False)
Robot's weighted accuracy = 0.33995770854042945
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.33995770854042945)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.33995770854042945
True human's confidence = 0.8037137121944862, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8037137121944862
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037137121944862, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.847468724457685, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.847468724457685
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.847468724457685, False)
Robot's weighted accuracy = 0.2984211060820079
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8396028984479204, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8396028984479204
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8396028984479204, False)
Robot's weighted accuracy = 0.3083330366567856
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8313455536250145, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8313455536250145
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313455536250145, False)
Robot's weighted accuracy = 0.3341152634216114
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8313386165934259, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8313386165934259
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386165934259, False)
Robot's weighted accuracy = 0.3341152634216114
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8313386275298719, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8313386275298719
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386275298719, False)
Robot's weighted accuracy = 0.3341152634216114
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.3341152634216114)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.3341152634216114
True human's confidence = 0.8313386293616, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8313386293616
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386293616, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8699525633259175, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8699525633259175
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8699525633259175, False)
Robot's weighted accuracy = 0.35708668701105767
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8629894850632587, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8629894850632587
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8629894850632587, False)
Robot's weighted accuracy = 0.3460468490087678
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8557097370300997, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8557097370300997
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557097370300997, False)
Robot's weighted accuracy = 0.3673102206428923
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8557025434006614, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8557025434006614
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025434006614, False)
Robot's weighted accuracy = 0.3673102206428923
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8557025433871235, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8557025433871235
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025433871235, False)
Robot's weighted accuracy = 0.3673102206428923
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.3673102206428923)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.3673102206428923
True human's confidence = 0.8557025433542109, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8557025433542109
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025433542109, False)
Robot's weighted accuracy = 0.3673102206428923
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8894822051105004, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8894822051105004
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8894822051105004, False)
Robot's weighted accuracy = 0.4188189177622523
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8834189054137013, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8834189054137013
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8834189054137013, False)
Robot's weighted accuracy = 0.4072323648724645
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8770684779450681, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8770684779450681
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770684779450681, False)
Robot's weighted accuracy = 0.4289894922685004
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8770611060192149, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8770611060192149
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770611060192149, False)
Robot's weighted accuracy = 0.4289894922685004
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8770611059414763, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8770611059414763
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770611059414763, False)
Robot's weighted accuracy = 0.4289894922685004
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4289894922685004)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.4289894922685004
True human's confidence = 0.877061105936558, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.877061105936558
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.877061105936558, False)
Robot's weighted accuracy = 0.4289894922685004
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9063884665121331, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9063884665121331
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9063884665121331, False)
Robot's weighted accuracy = 0.48186493809812964
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9011492328981039, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9011492328981039
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9011492328981039, False)
Robot's weighted accuracy = 0.4700983160764904
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8956505427646103, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8956505427646103
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956505427646103, False)
Robot's weighted accuracy = 0.4916684535990258
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8956430162165834, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8956430162165834
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430162165834, False)
Robot's weighted accuracy = 0.4916684535990258
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8956430161408544, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8956430161408544
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430161408544, False)
Robot's weighted accuracy = 0.4916684535990258
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4916684535990258)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.4916684535990258
True human's confidence = 0.8956430161403883, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8956430161403883
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430161403883, False)
Robot's weighted accuracy = 0.4916684535990258
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9209378091828663, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9209378091828663
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9209378091828663, False)
Robot's weighted accuracy = 0.5443162950005432
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9164378806838094, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9164378806838094
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9164378806838094, False)
Robot's weighted accuracy = 0.5327297426849494
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9117064588878001, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9117064588878001
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9117064588878001, False)
Robot's weighted accuracy = 0.5534778304235528
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9116987987912082, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9116987987912082
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987912082, False)
Robot's weighted accuracy = 0.5534778304235528
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9116987987145572, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9116987987145572
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987145572, False)
Robot's weighted accuracy = 0.5534778304235528
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5534778304235528)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.5534778304235528
True human's confidence = 0.9116987987145133, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9116987987145133
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987145133, False)
Robot's weighted accuracy = 0.5534778304235528
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9333919086913021, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9333919086913021
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9333919086913021, False)
Robot's weighted accuracy = 0.604386883476686
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9295467181432352, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9295467181432352
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9295467181432352, False)
Robot's weighted accuracy = 0.5933020730237648
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9254973598027871, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9254973598027871
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254973598027871, False)
Robot's weighted accuracy = 0.6127041728584919
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9254895850358145, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9254895850358145
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254895850358145, False)
Robot's weighted accuracy = 0.6127041728584919
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9254895849580554, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9254895849580554
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254895849580554, False)
Robot's weighted accuracy = 0.6127041728584919
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996
