
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158418
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083802, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, -100]
True human's accuracy on robot = 0.10500240700083802
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.10500240700083802, False)
Robot's weighted accuracy = 0.12783140270742593
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 1.0
True human's acting weight vector = [-100, -9.5, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.21000654452150003, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.3437165464086288, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595855, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.4492923398595855
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4492923398595855, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.22654736337775072)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.22654736337775072
True human's confidence = 0.48070515402728814, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.48070515402728814
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.48070515402728814, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.5413770316245772, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.5413770316245772
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5413770316245772, False)
Robot's weighted accuracy = 0.3769210318596377
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.6315893885871271, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.6315893885871271
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6315893885871271, False)
Robot's weighted accuracy = 0.4288414161902753
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.6528349233325377, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6528349233325377
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6528349233325377, False)
Robot's weighted accuracy = 0.4391387442720784
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.659380035285494, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.659380035285494
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.659380035285494, False)
Robot's weighted accuracy = 0.4391387442720784
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6607901863024207, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6607901863024207
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6607901863024207, False)
Robot's weighted accuracy = 0.4391387442720784
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.4391387442720784)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.4391387442720784
True human's confidence = 0.6610902553142691, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6610902553142691
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6610902553142691, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7240489505821456, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7240489505821456
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7240489505821456, False)
Robot's weighted accuracy = 0.4777879364172982
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7228171126451196, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7228171126451196
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7228171126451196, False)
Robot's weighted accuracy = 0.47260793631213416
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.713668445558397, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.713668445558397
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.713668445558397, False)
Robot's weighted accuracy = 0.4757511393140781
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7137285451106544, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7137285451106544
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137285451106544, False)
Robot's weighted accuracy = 0.4757511393140781
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7137425435671229, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7137425435671229
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137425435671229, False)
Robot's weighted accuracy = 0.4757511393140781
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4757511393140781)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.4757511393140781
True human's confidence = 0.7137454526300796, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7137454526300796
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7137454526300796, False)
Robot's weighted accuracy = 0.4757511393140781
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7717632218286734, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7717632218286734
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717632218286734, False)
Robot's weighted accuracy = 0.5506394732652901
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.761915160010201, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.761915160010201
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.761915160010201, False)
Robot's weighted accuracy = 0.5377516672822041
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7510786495647405, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7510786495647405
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510786495647405, False)
Robot's weighted accuracy = 0.5404535958787536
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7510729900426527, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7510729900426527
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510729900426527, False)
Robot's weighted accuracy = 0.5404535958787536
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7510731244007368, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7510731244007368
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510731244007368, False)
Robot's weighted accuracy = 0.5404535958787536
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5404535958787536)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.5404535958787536
True human's confidence = 0.7510731465699969, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7510731465699969
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7510731465699969, False)
Robot's weighted accuracy = 0.5404535958787536
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.803718628948884, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.803718628948884
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.803718628948884, False)
Robot's weighted accuracy = 0.6088072982878202
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7941191522875096, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7941191522875096
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7941191522875096, False)
Robot's weighted accuracy = 0.5945041046871641
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7841157671860204, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7841157671860204
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841157671860204, False)
Robot's weighted accuracy = 0.5967768195760019
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7841091757008031, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7841091757008031
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091757008031, False)
Robot's weighted accuracy = 0.5967768195760019
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7841091762923512, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7841091762923512
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091762923512, False)
Robot's weighted accuracy = 0.5967768195760019
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5967768195760019)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.5967768195760019
True human's confidence = 0.7841091758189433, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7841091758189433
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7841091758189433, False)
Robot's weighted accuracy = 0.5967768195760019
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8313437440000634, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8313437440000634
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313437440000634, False)
Robot's weighted accuracy = 0.6611457822130565
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.822732289283442, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.822732289283442
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.822732289283442, False)
Robot's weighted accuracy = 0.647194086272682
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8137743519325505, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8137743519325505
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137743519325505, False)
Robot's weighted accuracy = 0.6490680337113889
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8137675071579438, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8137675071579438
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137675071579438, False)
Robot's weighted accuracy = 0.6490680337113889
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.813767507027604, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.813767507027604
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.813767507027604, False)
Robot's weighted accuracy = 0.6490680337113889
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.6490680337113889)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.6490680337113889
True human's confidence = 0.8137675069543859, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8137675069543859
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8137675069543859, False)
Robot's weighted accuracy = 0.6490680337113889
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.855707882408424, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.855707882408424
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.855707882408424, False)
Robot's weighted accuracy = 0.7090225179505938
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8481076444066388, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8481076444066388
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8481076444066388, False)
Robot's weighted accuracy = 0.696019239223761
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8401813863926879, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8401813863926879
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401813863926879, False)
Robot's weighted accuracy = 0.69753487349481
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8401743215892592, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8401743215892592
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215892592, False)
Robot's weighted accuracy = 0.69753487349481
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8401743215110946, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8401743215110946
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215110946, False)
Robot's weighted accuracy = 0.69753487349481
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.69753487349481)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.69753487349481
True human's confidence = 0.8401743215034707, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8401743215034707
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8401743215034707, False)
Robot's weighted accuracy = 0.69753487349481
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.87706664526403, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.87706664526403
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.87706664526403, False)
Robot's weighted accuracy = 0.7523558483878449
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8704206931027546, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8704206931027546
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8704206931027546, False)
Robot's weighted accuracy = 0.7405478856460445
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8634713582879924, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8634713582879924
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634713582879924, False)
Robot's weighted accuracy = 0.7417513856728732
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8634640995435596, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8634640995435596
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640995435596, False)
Robot's weighted accuracy = 0.7417513856728732
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8634640994701803, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8634640994701803
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640994701803, False)
Robot's weighted accuracy = 0.7417513856728732
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.7417513856728732)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.7417513856728732
True human's confidence = 0.8634640994693933, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8634640994693933
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8634640994693933, False)
Robot's weighted accuracy = 0.7417513856728732
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8956487323231971, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8956487323231971
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956487323231971, False)
Robot's weighted accuracy = 0.7909682535668123
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8898813013004102, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8898813013004102
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8898813013004102, False)
Robot's weighted accuracy = 0.7804531653988123
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8838364881137106, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8838364881137106
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838364881137106, False)
Robot's weighted accuracy = 0.7813927680477675
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8838290598631652, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8838290598631652
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838290598631652, False)
Robot's weighted accuracy = 0.7813927680477675
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.883829059788793, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.883829059788793
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.883829059788793, False)
Robot's weighted accuracy = 0.7813927680477675
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.7813927680477675)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.7813927680477675
True human's confidence = 0.8838290597887094, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8838290597887094
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8838290597887094, False)
Robot's weighted accuracy = 0.7813927680477675
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9117046696944069, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9117046696944069
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9117046696944069, False)
Robot's weighted accuracy = 0.8248503671354916
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9067323494187258, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9067323494187258
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9067323494187258, False)
Robot's weighted accuracy = 0.815637165554022
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9015103257897921, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9015103257897921
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015103257897921, False)
Robot's weighted accuracy = 0.8163596515338328
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9015027504963864, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9015027504963864
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015027504963864, False)
Robot's weighted accuracy = 0.8163596515338328
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9015027504206174, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9015027504206174
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9015027504206174, False)
Robot's weighted accuracy = 0.8163596515338328
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158418
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083802, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, 0.5, -100]
True human's accuracy on robot = 0.10500240700083802
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.10500240700083802, False)
Robot's weighted accuracy = 0.12783140270742593
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.21000654452150003, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.3437165464086288, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595855, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.4492923398595855
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4492923398595855, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.22654736337775072)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.22654736337775072
True human's confidence = 0.48070515402728814, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.48070515402728814
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.48070515402728814, False)
Robot's weighted accuracy = 0.22654736337775072
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245772, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, 5.5, 6.0]
True human's accuracy on robot = 0.5413770316245772
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5413770316245772, False)
Robot's weighted accuracy = 0.2579129451622186
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069077, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, -100]
True human's accuracy on robot = 0.5884064503069077
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5884064503069077, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.6793929394751769, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6793929394751769
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6793929394751769, False)
Robot's weighted accuracy = 0.1711312626245115
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6973305740283453, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.6973305740283453
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6973305740283453, False)
Robot's weighted accuracy = 0.1711312626245115
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7182595441686, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7182595441686
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7182595441686, False)
Robot's weighted accuracy = 0.1711312626245115
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, 0.5, -0.5, 1.0), 0, 0.1711312626245115)
Robot's own rewards + human pref = [ 0.1 -0.4  0.   0.5]
Robot's confidence = 0.1711312626245115
True human's confidence = 0.7228767288415244, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7228767288415244
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7228767288415244, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.7760899422280437, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.7760899422280437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7760899422280437, False)
Robot's weighted accuracy = 0.28529912927083706
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7780627848696251, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.7780627848696251
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7780627848696251, False)
Robot's weighted accuracy = 0.29878949386657705
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.7710282978922527, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7710282978922527
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7710282978922527, False)
Robot's weighted accuracy = 0.3310614541417418
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7716026016584243, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.7716026016584243
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7716026016584243, False)
Robot's weighted accuracy = 0.3310614541417418
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7717262356440154, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.7717262356440154
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717262356440154, False)
Robot's weighted accuracy = 0.3310614541417418
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.3310614541417418)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.3310614541417418
True human's confidence = 0.7717524813754815, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.7717524813754815
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7717524813754815, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.820773635465447, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.820773635465447
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.820773635465447, False)
Robot's weighted accuracy = 0.3016515817260679
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8127689765620019, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8127689765620019
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8127689765620019, False)
Robot's weighted accuracy = 0.3111851956396094
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8037135765943846, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8037135765943846
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037135765943846, False)
Robot's weighted accuracy = 0.33999350781719573
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8037123078161096, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8037123078161096
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037123078161096, False)
Robot's weighted accuracy = 0.33999350781719573
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8037134705615637, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8037134705615637
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037134705615637, False)
Robot's weighted accuracy = 0.33999350781719573
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.33999350781719573)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.33999350781719573
True human's confidence = 0.8037137121944862, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8037137121944862
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8037137121944862, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.847468724457685, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.847468724457685
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.847468724457685, False)
Robot's weighted accuracy = 0.298421830441908
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8396028984479204, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8396028984479204
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8396028984479204, False)
Robot's weighted accuracy = 0.3083335396847572
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8313455536250145, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8313455536250145
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313455536250145, False)
Robot's weighted accuracy = 0.3341157083731251
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8313386165934259, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8313386165934259
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386165934259, False)
Robot's weighted accuracy = 0.3341157083731251
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8313386275298719, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8313386275298719
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386275298719, False)
Robot's weighted accuracy = 0.3341157083731251
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.3341157083731251)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.3341157083731251
True human's confidence = 0.8313386293616, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8313386293616
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8313386293616, False)
Robot's weighted accuracy = 0.0
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8699525633259175, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8699525633259175
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8699525633259175, False)
Robot's weighted accuracy = 0.357086697787293
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8629894850632587, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8629894850632587
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8629894850632587, False)
Robot's weighted accuracy = 0.34604685606716024
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8557097370300997, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8557097370300997
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557097370300997, False)
Robot's weighted accuracy = 0.36731022679398584
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8557025434006614, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8557025434006614
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025434006614, False)
Robot's weighted accuracy = 0.36731022679398584
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8557025433871235, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8557025433871235
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025433871235, False)
Robot's weighted accuracy = 0.36731022679398584
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.36731022679398584)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.36731022679398584
True human's confidence = 0.8557025433542109, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8557025433542109
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8557025433542109, False)
Robot's weighted accuracy = 0.36731022679398584
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.8894822051105004, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.8894822051105004
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8894822051105004, False)
Robot's weighted accuracy = 0.41881891791878184
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.8834189054137013, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.8834189054137013
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8834189054137013, False)
Robot's weighted accuracy = 0.40723236497586807
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8770684779450681, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8770684779450681
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770684779450681, False)
Robot's weighted accuracy = 0.42898949235806405
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8770611060192149, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8770611060192149
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770611060192149, False)
Robot's weighted accuracy = 0.42898949235806405
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8770611059414763, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8770611059414763
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8770611059414763, False)
Robot's weighted accuracy = 0.42898949235806405
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.42898949235806405)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.42898949235806405
True human's confidence = 0.877061105936558, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.877061105936558
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.877061105936558, False)
Robot's weighted accuracy = 0.42898949235806405
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9063884665121331, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9063884665121331
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9063884665121331, False)
Robot's weighted accuracy = 0.48186493810034164
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9011492328981039, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9011492328981039
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9011492328981039, False)
Robot's weighted accuracy = 0.47009831607796354
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8956505427646103, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8956505427646103
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956505427646103, False)
Robot's weighted accuracy = 0.4916684536002915
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8956430162165834, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.8956430162165834
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430162165834, False)
Robot's weighted accuracy = 0.4916684536002915
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8956430161408544, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8956430161408544
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430161408544, False)
Robot's weighted accuracy = 0.4916684536002915
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4916684536002915)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.4916684536002915
True human's confidence = 0.8956430161403883, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8956430161403883
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8956430161403883, False)
Robot's weighted accuracy = 0.4916684536002915
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9209378091828663, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9209378091828663
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9209378091828663, False)
Robot's weighted accuracy = 0.5443162950005734
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9164378806838094, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9164378806838094
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9164378806838094, False)
Robot's weighted accuracy = 0.5327297426849695
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9117064588878001, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9117064588878001
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9117064588878001, False)
Robot's weighted accuracy = 0.5534778304235699
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9116987987912082, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9116987987912082
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987912082, False)
Robot's weighted accuracy = 0.5534778304235699
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9116987987145572, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9116987987145572
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987145572, False)
Robot's weighted accuracy = 0.5534778304235699
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5534778304235699)
Robot's own rewards + human pref = [ 2.  -1.8  0.   0. ]
Robot's confidence = 0.5534778304235699
True human's confidence = 0.9116987987145133, confidence scalar = 1.0
True human's acting weight vector = [4.1, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9116987987145133
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9116987987145133, False)
Robot's weighted accuracy = 0.5534778304235699
robot blue, human blue --> [0, 6, 2, 2]

Current state = [0, 6, 2, 2]
True human's confidence = 0.9333919086913021, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.5, -4.5, 6.0]
True human's accuracy on robot = 0.9333919086913021
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9333919086913021, False)
Robot's weighted accuracy = 0.6043868834766862
robot red, human yellow --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9295467181432352, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -4.0]
True human's accuracy on robot = 0.9295467181432352
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9295467181432352, False)
Robot's weighted accuracy = 0.5933020730237648
robot red, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9254973598027871, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9254973598027871
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254973598027871, False)
Robot's weighted accuracy = 0.6127041728584918
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9254895850358145, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.5, -100, -100]
True human's accuracy on robot = 0.9254895850358145
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254895850358145, False)
Robot's weighted accuracy = 0.6127041728584918
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9254895849580554, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9254895849580554
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9254895849580554, False)
Robot's weighted accuracy = 0.6127041728584918
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -1.0999999999999996
