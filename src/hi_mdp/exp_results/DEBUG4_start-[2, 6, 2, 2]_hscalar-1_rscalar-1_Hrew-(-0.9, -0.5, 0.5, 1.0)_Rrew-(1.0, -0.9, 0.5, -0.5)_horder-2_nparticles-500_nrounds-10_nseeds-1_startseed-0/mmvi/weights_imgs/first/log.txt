
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.0, False)
Robot's weighted accuracy = 0.08415841584158418
robot red, human yellow --> [1, 6, 1, 0]

Current state = [1, 6, 1, 0]
True human's confidence = 0.1670811159029145, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, -100, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.0, False)
Robot's weighted accuracy = 0.1040316774658027
robot red, human green --> [1, 5, 0, 0]

Current state = [1, 5, 0, 0]
True human's confidence = 0.2157852439306359, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.2157852439306359
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.2157852439306359, False)
Robot's weighted accuracy = 0.2056394144825223
No need to update robot beliefs
robot blue, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.25229218899775163, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.25229218899775163
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.25229218899775163, False)
Robot's weighted accuracy = 0.2056394144825223
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.36168613917871645, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.36168613917871645
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.36168613917871645, False)
Robot's weighted accuracy = 0.2056394144825223
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, 0.5, -0.5, 1.0), 0, 0.2056394144825223)
Robot's own rewards + human pref = [ 0.1 -0.4  0.   0.5]
Robot's confidence = 0.2056394144825223
True human's confidence = 0.4678779898682239, confidence scalar = 1.0
True human's acting weight vector = [0.09999999999999998, 0.5, 1.5, 2.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.2056394144825223
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.4545915158286429, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.4545915158286429
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4545915158286429, False)
Robot's weighted accuracy = 0.23157011712569484
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5279276663069964, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.5279276663069964
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5279276663069964, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.5219577733468725, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5219577733468725
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5219577733468725, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5573371229040437, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5573371229040437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5573371229040437, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5654940462670671, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.5654940462670671
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5654940462670671, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.48422897792186553)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.48422897792186553
True human's confidence = 0.5672601927385797, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.5672601927385797
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5672601927385797, False)
Robot's weighted accuracy = 0.48422897792186553
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6392957949697735, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6392957949697735
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6392957949697735, False)
Robot's weighted accuracy = 0.5157507963435252
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.704352768665877, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.704352768665877
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.704352768665877, False)
Robot's weighted accuracy = 0.5165464589506601
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.6984828679488932, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6984828679488932
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6984828679488932, False)
Robot's weighted accuracy = 0.6159740545846393
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6990615906936481, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6990615906936481
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6990615906936481, False)
Robot's weighted accuracy = 0.6159740545846393
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6991857432285273, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6991857432285273
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6991857432285273, False)
Robot's weighted accuracy = 0.6159740545846393
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.6159740545846393)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.6159740545846393
True human's confidence = 0.6992120320252424, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6992120320252424
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6992120320252424, False)
Robot's weighted accuracy = 0.6159740545846393
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7586543187184298, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.7586543187184298
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7586543187184298, False)
Robot's weighted accuracy = 0.6417285473477786
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8093124528282364, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.8093124528282364
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8093124528282364, False)
Robot's weighted accuracy = 0.6255966559650372
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8022856498674722, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8022856498674722
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022856498674722, False)
Robot's weighted accuracy = 0.6272317907789923
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8022884283173412, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8022884283173412
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022884283173412, False)
Robot's weighted accuracy = 0.6272317907789923
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8022901362352866, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8022901362352866
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022901362352866, False)
Robot's weighted accuracy = 0.6272317907789923
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.6272317907789923)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.6272317907789923
True human's confidence = 0.802290453012042, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.802290453012042
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.802290453012042, False)
Robot's weighted accuracy = 0.6272317907789923
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8460784588146758, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.8460784588146758
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8460784588146758, False)
Robot's weighted accuracy = 0.6440115125811655
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8815252064990563, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.8815252064990563
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8815252064990563, False)
Robot's weighted accuracy = 0.6039853211189397
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8758939378606019, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8758939378606019
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758939378606019, False)
Robot's weighted accuracy = 0.5743843198299625
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8758880688835914, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8758880688835914
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880688835914, False)
Robot's weighted accuracy = 0.5743843198299625
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8758880732230843, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8758880732230843
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880732230843, False)
Robot's weighted accuracy = 0.5743843198299625
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.5743843198299625)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.5743843198299625
True human's confidence = 0.8758880587139404, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8758880587139404
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880587139404, False)
Robot's weighted accuracy = 0.5743843198299625
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.905383243607258, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.905383243607258
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.905383243607258, False)
Robot's weighted accuracy = 0.5841833461126257
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9284164433180065, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9284164433180065
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9284164433180065, False)
Robot's weighted accuracy = 0.5246020966908106
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9245598854443634, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9245598854443634
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245598854443634, False)
Robot's weighted accuracy = 0.4870716108757954
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9245535938959387, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9245535938959387
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535938959387, False)
Robot's weighted accuracy = 0.4870716108757954
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9245535879731215, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9245535879731215
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535879731215, False)
Robot's weighted accuracy = 0.4870716108757954
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.4870716108757954)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.4870716108757954
True human's confidence = 0.9245535818640491, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9245535818640491
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535818640491, False)
Robot's weighted accuracy = 0.4870716108757954
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9432602744717159, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9432602744717159
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9432602744717159, False)
Robot's weighted accuracy = 0.49250016436182914
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.957532291117815, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.957532291117815
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.957532291117815, False)
Robot's weighted accuracy = 0.42187193246623717
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.955089081450722, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.955089081450722
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.955089081450722, False)
Robot's weighted accuracy = 0.38536235253817747
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9550825900635137, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9550825900635137
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825900635137, False)
Robot's weighted accuracy = 0.38536235253817747
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9550825881282704, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9550825881282704
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825881282704, False)
Robot's weighted accuracy = 0.38536235253817747
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.38536235253817747)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.38536235253817747
True human's confidence = 0.9550825862546043, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9550825862546043
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825862546043, False)
Robot's weighted accuracy = 0.38536235253817747
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9665034117938786, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9665034117938786
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9665034117938786, False)
Robot's weighted accuracy = 0.3882905096500972
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9750914658365024, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9750914658365024
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9750914658365024, False)
Robot's weighted accuracy = 0.43439879422147587
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9736068478843118, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9736068478843118
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736068478843118, False)
Robot's weighted accuracy = 0.43628062577828547
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9736002351950578, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9736002351950578
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002351950578, False)
Robot's weighted accuracy = 0.43628062577828547
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9736002345734773, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9736002345734773
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002345734773, False)
Robot's weighted accuracy = 0.43628062577828547
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, -0.5, 1.0), 0, 0.43628062577828547)
Robot's own rewards + human pref = [ 1.5 -1.8  0.   0.5]
Robot's confidence = 0.43628062577828547
True human's confidence = 0.9736002340179467, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9736002340179467
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002340179467, False)
Robot's weighted accuracy = 0.43628062577828547
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9804132473537446, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.43864081787434456
robot red, human yellow --> [1, 6, 1, 0]

Current state = [1, 6, 1, 0]
True human's confidence = 0.9736108668256575, confidence scalar = 1.0
True human's acting weight vector = [-1.4, -0.5, -100, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [1, 5, 0, 0]

Current state = [1, 5, 0, 0]
True human's confidence = 0.9645267990149134, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9645267990149134
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9645267990149134, False)
Robot's weighted accuracy = 0.8803015995121243
No need to update robot beliefs
robot blue, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9665331847680361, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9665331847680361
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9665331847680361, False)
Robot's weighted accuracy = 0.8803015995121243
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9665254727107754, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9665254727107754
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9665254727107754, False)
Robot's weighted accuracy = 0.8803015995121243
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.8803015995121243)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8803015995121243
True human's confidence = 0.9665254726025144, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9665254726025144
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9665254726025144, False)
Robot's weighted accuracy = 0.8803015995121243
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9751192324461129, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9751192324461129
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9751192324461129, False)
Robot's weighted accuracy = 0.8820578541643489
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9815462717587198, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9815462717587198
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9815462717587198, False)
Robot's weighted accuracy = 0.8565523438380506
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9804216885029728, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9804216885029728
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9804216885029728, False)
Robot's weighted accuracy = 0.8343684237732231
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9804150312651589, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9804150312651589
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9804150312651589, False)
Robot's weighted accuracy = 0.8343684237732231
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9804150311894302, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9804150311894302
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9804150311894302, False)
Robot's weighted accuracy = 0.8343684237732231
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003
