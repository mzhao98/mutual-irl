
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, -0.5, 0.5), 0.0, False)
Robot's weighted accuracy = 0.041666666666666664
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.9, 0.5, -0.5), 0.0, False)
Robot's weighted accuracy = 0.08415841584158418
robot red, human yellow --> [1, 6, 1, 0]

Current state = [1, 6, 1, 0]
True human's confidence = 0.1670811159029145, confidence scalar = 0.0
True human's acting weight vector = [-0.9, -0.5, -100, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.0, False)
Robot's weighted accuracy = 0.1040316774658027
robot red, human green --> [1, 5, 0, 0]

Current state = [1, 5, 0, 0]
True human's confidence = 0.2157852439306359, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.2157852439306359
True human's belief of robot = ((0.5, -0.9, 1.0, -0.5), 0.2157852439306359, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot blue, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.25229218899775163, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.25229218899775163
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.25229218899775163, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.36168613917871645, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.36168613917871645
True human's belief of robot = ((0.5, -0.5, 1.0, -0.9), 0.36168613917871645, False)
Robot's weighted accuracy = 0.1309061729759762
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, 0.5, -0.9, 1.0), 1, 0.1309061729759762)
Robot's own rewards + human pref = [ 0.5 -0.4 -0.4  0.5]
Robot's confidence = 0.1309061729759762
True human's confidence = 0.4678779898682239, confidence scalar = 1.0
True human's acting weight vector = [0.09999999999999998, 0.5, 1.5, 2.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.0, False)
Robot's weighted accuracy = 0.1309061729759762
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.4545915158286429, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.4545915158286429
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.4545915158286429, False)
Robot's weighted accuracy = 0.15081269891655386
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5279276663069964, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.5279276663069964
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5279276663069964, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.5219577733468725, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5219577733468725
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5219577733468725, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5573371229040437, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.5573371229040437
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5573371229040437, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5654940462670671, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.5654940462670671
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5654940462670671, False)
Robot's weighted accuracy = 0.4528697683358175
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.4528697683358175)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.4528697683358175
True human's confidence = 0.5672601927385797, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.5672601927385797
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.5672601927385797, False)
Robot's weighted accuracy = 0.4528697683358175
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6392957949697735, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.6392957949697735
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6392957949697735, False)
Robot's weighted accuracy = 0.5065402005953551
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.704352768665877, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.704352768665877
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.704352768665877, False)
Robot's weighted accuracy = 0.5211726650175337
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.6984828679488932, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6984828679488932
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6984828679488932, False)
Robot's weighted accuracy = 0.6704956807777328
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6990615906936481, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.6990615906936481
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6990615906936481, False)
Robot's weighted accuracy = 0.6704956807777328
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6991857432285273, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.6991857432285273
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6991857432285273, False)
Robot's weighted accuracy = 0.6704956807777328
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.6704956807777328)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.6704956807777328
True human's confidence = 0.6992120320252424, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.6992120320252424
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.6992120320252424, False)
Robot's weighted accuracy = 0.6704956807777328
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7586543187184298, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.7586543187184298
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.7586543187184298, False)
Robot's weighted accuracy = 0.7273031916764845
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8093124528282364, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.8093124528282364
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8093124528282364, False)
Robot's weighted accuracy = 0.7607965463371584
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8022856498674722, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8022856498674722
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022856498674722, False)
Robot's weighted accuracy = 0.8044127749981211
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8022884283173412, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8022884283173412
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022884283173412, False)
Robot's weighted accuracy = 0.8044127749981211
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8022901362352866, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8022901362352866
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8022901362352866, False)
Robot's weighted accuracy = 0.8044127749981211
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8044127749981211)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8044127749981211
True human's confidence = 0.802290453012042, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.802290453012042
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.802290453012042, False)
Robot's weighted accuracy = 0.8044127749981211
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8460784588146758, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.8460784588146758
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8460784588146758, False)
Robot's weighted accuracy = 0.8460281049732941
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8815252064990563, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.8815252064990563
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8815252064990563, False)
Robot's weighted accuracy = 0.8742621259258953
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8758939378606019, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8758939378606019
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758939378606019, False)
Robot's weighted accuracy = 0.8861162916245486
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8758880688835914, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.8758880688835914
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880688835914, False)
Robot's weighted accuracy = 0.8861162916245486
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8758880732230843, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.8758880732230843
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880732230843, False)
Robot's weighted accuracy = 0.8861162916245486
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.8861162916245486)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.8861162916245486
True human's confidence = 0.8758880587139404, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.8758880587139404
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.8758880587139404, False)
Robot's weighted accuracy = 0.8861162916245486
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.905383243607258, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.905383243607258
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.905383243607258, False)
Robot's weighted accuracy = 0.9127895159590056
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9284164433180065, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9284164433180065
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9284164433180065, False)
Robot's weighted accuracy = 0.9319112371982653
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9245598854443634, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9245598854443634
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245598854443634, False)
Robot's weighted accuracy = 0.9341132969344035
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9245535938959387, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9245535938959387
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535938959387, False)
Robot's weighted accuracy = 0.9341132969344035
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9245535879731215, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9245535879731215
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535879731215, False)
Robot's weighted accuracy = 0.9341132969344035
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.9341132969344035)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.9341132969344035
True human's confidence = 0.9245535818640491, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9245535818640491
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9245535818640491, False)
Robot's weighted accuracy = 0.9341132969344035
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9432602744717159, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9432602744717159
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9432602744717159, False)
Robot's weighted accuracy = 0.9502625465511313
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.957532291117815, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.957532291117815
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.957532291117815, False)
Robot's weighted accuracy = 0.9622452423271952
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.955089081450722, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.955089081450722
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.955089081450722, False)
Robot's weighted accuracy = 0.9618068300601347
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9550825900635137, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9550825900635137
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825900635137, False)
Robot's weighted accuracy = 0.9618068300601347
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9550825881282704, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9550825881282704
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825881282704, False)
Robot's weighted accuracy = 0.9618068300601347
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.9618068300601347)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.9618068300601347
True human's confidence = 0.9550825862546043, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9550825862546043
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9550825862546043, False)
Robot's weighted accuracy = 0.9618068300601347
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9665034117938786, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9665034117938786
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9665034117938786, False)
Robot's weighted accuracy = 0.9713555755743956
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9750914658365024, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9750914658365024
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9750914658365024, False)
Robot's weighted accuracy = 0.9786262280851548
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9736068478843118, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9736068478843118
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736068478843118, False)
Robot's weighted accuracy = 0.9777416611432932
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9736002351950578, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9736002351950578
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002351950578, False)
Robot's weighted accuracy = 0.9777416611432932
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9736002345734773, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9736002345734773
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002345734773, False)
Robot's weighted accuracy = 0.9777416611432932
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.9777416611432932)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.9777416611432932
True human's confidence = 0.9736002340179467, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9736002340179467
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9736002340179467, False)
Robot's weighted accuracy = 0.9777416611432932
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9804132473537446, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9804132473537446
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9804132473537446, False)
Robot's weighted accuracy = 0.9833415703993
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9854910460627574, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9854910460627574
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9854910460627574, False)
Robot's weighted accuracy = 0.9876940675138329
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9846092234849286, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9846092234849286
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9846092234849286, False)
Robot's weighted accuracy = 0.9869488945162921
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9846025384541512, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9846025384541512
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9846025384541512, False)
Robot's weighted accuracy = 0.9869488945162921
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9846025382250787, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9846025382250787
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9846025382250787, False)
Robot's weighted accuracy = 0.9869488945162921
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.5, -0.9, 0.5, 1.0), 1, 0.9869488945162921)
Robot's own rewards + human pref = [ 0.5 -1.8  1.   0.5]
Robot's confidence = 0.9869488945162921
True human's confidence = 0.9846025380628495, confidence scalar = 1.0
True human's acting weight vector = [-0.4, -0.5, 0.5, 1.0]
True human's accuracy on robot = 0.9846025380628495
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9846025380628495, False)
Robot's weighted accuracy = 0.9869488945162921
robot blue, human yellow --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9886117638748712, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 1.0, 1.5]
True human's accuracy on robot = 0.9886117638748712
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9886117638748712, False)
Robot's weighted accuracy = 0.9902297434394881
robot blue, human yellow --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9915832252013791, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.0, 0.0, -100]
True human's accuracy on robot = 0.9915832252013791
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9915832252013791, False)
Robot's weighted accuracy = 0.9928228140023336
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9910658729644551, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9910658729644551
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9910658729644551, False)
Robot's weighted accuracy = 0.9923031354660191
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9910591454008757, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.0, -100, -100]
True human's accuracy on robot = 0.9910591454008757
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9910591454008757, False)
Robot's weighted accuracy = 0.9923031354660191
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9910591452866433, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.5, -100, -100]
True human's accuracy on robot = 0.9910591452866433
True human's belief of robot = ((1.0, -0.5, 0.5, -0.9), 0.9910591452866433, False)
Robot's weighted accuracy = 0.9923031354660191
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003
