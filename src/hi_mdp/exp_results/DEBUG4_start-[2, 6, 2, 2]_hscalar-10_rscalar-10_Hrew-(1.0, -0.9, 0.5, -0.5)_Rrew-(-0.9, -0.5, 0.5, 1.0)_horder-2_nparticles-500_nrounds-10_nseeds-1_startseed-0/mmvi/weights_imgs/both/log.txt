
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.21216027188954975
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.21216027188954975
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.21216027188954975
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.21216027188954975)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.21216027188954975
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.21216027188954975
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.24371137840326218
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6973305740283456, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.6973305740283456
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6973305740283456, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7182595441686002, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7182595441686002
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7182595441686002, False)
Robot's weighted accuracy = 0.12733760161121618
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, 0.5, -0.9), 0, 0.12733760161121618)
Robot's own rewards + human pref = [ 0.1 -1.   1.   0.1]
Robot's confidence = 0.12733760161121618
True human's confidence = 0.7228767288415244, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.7228767288415244
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7228767288415244, False)
Robot's weighted accuracy = 0.12733760161121618
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7760899422280438, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.14291817337446475
robot red, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7340074306427838, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.15734454149152008
robot red, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.674110727408236, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.674110727408236
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.674110727408236, False)
Robot's weighted accuracy = 0.2602001304428224
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.687385671201087, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.687385671201087
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.687385671201087, False)
Robot's weighted accuracy = 0.2602001304428224
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.688107066885893, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.688107066885893
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.688107066885893, False)
Robot's weighted accuracy = 0.2602001304428224
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.5, -0.9), 0, 0.2602001304428224)
Robot's own rewards + human pref = [0.1 0.  0.  0.1]
Robot's confidence = 0.2602001304428224
True human's confidence = 0.6882618977734306, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.6882618977734306
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6882618977734306, False)
Robot's weighted accuracy = 0.2602001304428224
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7495963549977057, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.7495963549977057
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7495963549977057, False)
Robot's weighted accuracy = 0.2864833057611543
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8022475657324729, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.8022475657324729
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8022475657324729, False)
Robot's weighted accuracy = 0.2557729834932134
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7931789886100943, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.7931789886100943
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7931789886100943, False)
Robot's weighted accuracy = 0.2829992532532878
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7832932238629796, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.7832932238629796
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7832932238629796, False)
Robot's weighted accuracy = 0.2829992532532878
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7833485446320243, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7833485446320243
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7833485446320243, False)
Robot's weighted accuracy = 0.2829992532532878
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.5, -0.9), 0, 0.2829992532532878)
Robot's own rewards + human pref = [0.1 0.  0.  0.1]
Robot's confidence = 0.2829992532532878
True human's confidence = 0.7833616283167085, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.7833616283167085
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7833616283167085, False)
Robot's weighted accuracy = 0.2829992532532878
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8307047389179626, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.8307047389179626
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8307047389179626, False)
Robot's weighted accuracy = 0.3150272681229344
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8694174664487154, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.8694174664487154
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8694174664487154, False)
Robot's weighted accuracy = 0.2591642904133199
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8624837932534377, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.8624837932534377
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8624837932534377, False)
Robot's weighted accuracy = 0.24021567646696526
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.855196511719034, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.855196511719034
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.855196511719034, False)
Robot's weighted accuracy = 0.24021567646696526
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8551948262199118, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8551948262199118
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8551948262199118, False)
Robot's weighted accuracy = 0.24021567646696526
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.5, -0.9), 0, 0.24021567646696526)
Robot's own rewards + human pref = [0.1 0.  0.  0.1]
Robot's confidence = 0.24021567646696526
True human's confidence = 0.855195900439133, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.855195900439133
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.855195900439133, False)
Robot's weighted accuracy = 0.24021567646696526
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8890770401764271, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.8890770401764271
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8890770401764271, False)
Robot's weighted accuracy = 0.26818667697993964
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9158080943426883, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.9158080943426883
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9158080943426883, False)
Robot's weighted accuracy = 0.22763084679618326
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9110482368910493, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9110482368910493
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9110482368910493, False)
Robot's weighted accuracy = 0.22307512043158728
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9060446267021991, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9060446267021991
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9060446267021991, False)
Robot's weighted accuracy = 0.22307512043158728
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9060379007759632, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9060379007759632
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9060379007759632, False)
Robot's weighted accuracy = 0.22307512043158728
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.22307512043158728)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.22307512043158728
True human's confidence = 0.9060379867207857, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.9060379867207857
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9060379867207857, False)
Robot's weighted accuracy = 0.22307512043158728
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9290130943547404, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.9290130943547404
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9290130943547404, False)
Robot's weighted accuracy = 0.24873575168106762
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9466983549655773, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.9466983549655773
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9466983549655773, False)
Robot's weighted accuracy = 0.291700312085904
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9435736872895667, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9435736872895667
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9435736872895667, False)
Robot's weighted accuracy = 0.28138664497891985
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9402792909355586, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9402792909355586
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9402792909355586, False)
Robot's weighted accuracy = 0.28138664497891985
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9402719269807243, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9402719269807243
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9402719269807243, False)
Robot's weighted accuracy = 0.28138664497891985
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.28138664497891985)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.28138664497891985
True human's confidence = 0.9402719336548323, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.9402719336548323
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9402719336548323, False)
Robot's weighted accuracy = 0.28138664497891985
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9552909586133317, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.9552909586133317
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9552909586133317, False)
Robot's weighted accuracy = 0.31270412808161796
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9666646794078555, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.9666646794078555
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9666646794078555, False)
Robot's weighted accuracy = 0.35457868175200974
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9646661117359278, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9646661117359278
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9646661117359278, False)
Robot's weighted accuracy = 0.3401643865228742
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9625546872847975, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9625546872847975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9625546872847975, False)
Robot's weighted accuracy = 0.3401643865228742
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9625471215385235, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9625471215385235
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9625471215385235, False)
Robot's weighted accuracy = 0.3401643865228742
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.3401643865228742)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.3401643865228742
True human's confidence = 0.962547121984189, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.962547121984189
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.962547121984189, False)
Robot's weighted accuracy = 0.3401643865228742
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9721324360049448, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.9721324360049448
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9721324360049448, False)
Robot's weighted accuracy = 0.37618738132195556
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9793147277881402, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.9793147277881402
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9793147277881402, False)
Robot's weighted accuracy = 0.41547047594580067
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9780569109337542, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9780569109337542
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9780569109337542, False)
Robot's weighted accuracy = 0.3979658319345536
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.976726830055896, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.976726830055896
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.976726830055896, False)
Robot's weighted accuracy = 0.3979658319345536
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9767191523505869, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9767191523505869
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9767191523505869, False)
Robot's weighted accuracy = 0.3979658319345536
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.3979658319345536)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.3979658319345536
True human's confidence = 0.976719152313646, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.976719152313646
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.976719152313646, False)
Robot's weighted accuracy = 0.3979658319345536
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9827439919627593, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.9827439919627593
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9827439919627593, False)
Robot's weighted accuracy = 0.4374632768753944
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.987227475266318, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.987227475266318
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.987227475266318, False)
Robot's weighted accuracy = 0.4733816427013991
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9864437175314269, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9864437175314269
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9864437175314269, False)
Robot's weighted accuracy = 0.4537061430521605
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9856150038884678, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.9856150038884678
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9856150038884678, False)
Robot's weighted accuracy = 0.4537061430521605
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9856072572394758, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9856072572394758
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9856072572394758, False)
Robot's weighted accuracy = 0.4537061430521605
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036
