
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.12783140270742602
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.2265473633777507
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.2265473633777507
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.2265473633777507
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2265473633777507)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2265473633777507
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.2265473633777507
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.25791294516221863
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.17113126262451156
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6973305740283456, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.6973305740283456
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6973305740283456, False)
Robot's weighted accuracy = 0.17113126262451156
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7182595441686002, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7182595441686002
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7182595441686002, False)
Robot's weighted accuracy = 0.17113126262451156
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.5, -0.9), 0, 0.17113126262451156)
Robot's own rewards + human pref = [0.1 0.  0.  0.1]
Robot's confidence = 0.17113126262451156
True human's confidence = 0.7228767288415244, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.7228767288415244
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7228767288415244, False)
Robot's weighted accuracy = 0.17113126262451156
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7760899422280438, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.7760899422280438
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7760899422280438, False)
Robot's weighted accuracy = 0.1837543256221993
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8202838770372749, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.8202838770372749
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8202838770372749, False)
Robot's weighted accuracy = 0.0
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.824031118706284, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.824031118706284
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.824031118706284, False)
Robot's weighted accuracy = 0.4012072656750759
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8183949735313252, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.8183949735313252
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8183949735313252, False)
Robot's weighted accuracy = 0.4012072656750759
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8202671240345191, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8202671240345191
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8202671240345191, False)
Robot's weighted accuracy = 0.4012072656750759
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.4012072656750759)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.4012072656750759
True human's confidence = 0.8206679194474161, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 4.5]
True human's accuracy on robot = 0.8206679194474161
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8206679194474161, False)
Robot's weighted accuracy = 0.4012072656750759
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.86092958311702, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, 5.5, -100]
True human's accuracy on robot = 0.86092958311702
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.86092958311702, False)
Robot's weighted accuracy = 0.4227735887191705
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8932074785109703, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -4.5, -100]
True human's accuracy on robot = 0.8932074785109703
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8932074785109703, False)
Robot's weighted accuracy = 0.5059055247190745
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.888492263110757, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.888492263110757
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.888492263110757, False)
Robot's weighted accuracy = 0.5679344395770786
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.882684205971246, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.882684205971246
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.882684205971246, False)
Robot's weighted accuracy = 0.5679344395770786
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.882830153925785, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.882830153925785
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.882830153925785, False)
Robot's weighted accuracy = 0.5679344395770786
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.5679344395770786)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.5679344395770786
True human's confidence = 0.8828626896633244, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5679344395770786
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.8475463888426342, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, -100, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5917322328444181
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.8038185052666111, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -100, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5903891831048507
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.7622449378965759, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.7150010845143514, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.6624931050795961, confidence scalar = 1.0
True human's acting weight vector = [-100, -100, -100, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5567955127238636
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.5567955127238636)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.5567955127238636
True human's confidence = 0.6055386514835747, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5567955127238636
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.5309257809238288, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, -100, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5659104636881979
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.544899382457021, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, 4.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.55230615886727
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.6041371701330541, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.6586654219428443, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.7020474375562169, confidence scalar = 1.0
True human's acting weight vector = [-100, -100, -100, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.4940392208304688
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.4940392208304688)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.4940392208304688
True human's confidence = 0.715282608716375, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.4940392208304688
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.6898122011894564, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.4970285389952386
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.6311600657240394, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -4.5, -100]
True human's accuracy on robot = 0.6311600657240394
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6311600657240394, False)
Robot's weighted accuracy = 0.4594677042852739
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.6460376459067265, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.6460376459067265
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6460376459067265, False)
Robot's weighted accuracy = 0.47995946961699115
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6602783663238873, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.6602783663238873
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6602783663238873, False)
Robot's weighted accuracy = 0.47995946961699115
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6602730284549951, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6602730284549951
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6602730284549951, False)
Robot's weighted accuracy = 0.47995946961699115
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.47995946961699115)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.47995946961699115
True human's confidence = 0.6602729323317725, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.47995946961699115
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5900516478460576, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.4819071995144898
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5149621920556278, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -4.5, -100]
True human's accuracy on robot = 0.5149621920556278
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5149621920556278, False)
Robot's weighted accuracy = 0.5439152742510813
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5300344493102119, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.5300344493102119
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5300344493102119, False)
Robot's weighted accuracy = 0.522797277046878
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.545034139839722, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.545034139839722
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.545034139839722, False)
Robot's weighted accuracy = 0.522797277046878
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5450298171550529, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.5450298171550529
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5450298171550529, False)
Robot's weighted accuracy = 0.522797277046878
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.522797277046878)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.522797277046878
True human's confidence = 0.5450298144536447, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 5.5, 9.5]
True human's accuracy on robot = 0.5450298144536447
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5450298144536447, False)
Robot's weighted accuracy = 0.522797277046878
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.619152644169236, confidence scalar = 1.0
True human's acting weight vector = [6.0, 4.1, -100, 4.5]
True human's accuracy on robot = 0.619152644169236
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.619152644169236, False)
Robot's weighted accuracy = 0.5242721340058323
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.6881027763686519, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, 4.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5231792032954599
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.7379374078486645, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.7817691184224893, confidence scalar = 1.0
True human's acting weight vector = [-100, 4.1, -100, -5.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8178598720847264, confidence scalar = 1.0
True human's acting weight vector = [-100, -100, -100, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7320466743967645
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.7320466743967645)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.7320466743967645
True human's confidence = 0.8409663494878852, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, 9.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7320466743967645
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8089534336135319, confidence scalar = 1.0
True human's acting weight vector = [11.0, 9.1, 10.5, -100]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7327341280144594
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7606514824922427, confidence scalar = 1.0
True human's acting weight vector = [-100, 9.1, -4.5, -100]
True human's accuracy on robot = 0.7606514824922427
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7606514824922427, False)
Robot's weighted accuracy = 0.6626782417643754
robot red, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7716818151402772, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.7716818151402772
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7716818151402772, False)
Robot's weighted accuracy = 0.6893901807754422
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7822901532720143, confidence scalar = 1.0
True human's acting weight vector = [-100, -5.9, -100, -100]
True human's accuracy on robot = 0.7822901532720143
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7822901532720143, False)
Robot's weighted accuracy = 0.6893901807754422
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7822838992603643, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.7822838992603643
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7822838992603643, False)
Robot's weighted accuracy = 0.6893901807754422
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036
