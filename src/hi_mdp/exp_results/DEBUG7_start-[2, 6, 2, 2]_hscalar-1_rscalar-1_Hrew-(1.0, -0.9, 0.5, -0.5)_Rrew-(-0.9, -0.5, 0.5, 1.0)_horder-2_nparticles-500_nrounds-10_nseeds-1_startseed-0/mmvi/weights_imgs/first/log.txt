
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, None, -0.5]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, -0.5]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 1.0, 0.5), 0.10500240700083806, False)
Robot's weighted accuracy = 0.127831402707426
robot yellow, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.21000654452150003, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.3437165464086288, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.4492923398595858, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -0.6999999999999997

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 0, 0.22654736337775072)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.22654736337775072
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.4807051540272881, False)
Robot's weighted accuracy = 0.22654736337775072
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.25791294516221863
robot yellow, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.5804850040137534, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot yellow, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.5381465903053595, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.5381465903053595
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5381465903053595, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5573419100575847, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.5573419100575847
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5573419100575847, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.565494046316355, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.565494046316355
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.565494046316355, False)
Robot's weighted accuracy = 0.48422897792186553
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.48422897792186553)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.48422897792186553
True human's confidence = 0.5672601927385804, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.5672601927385804
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5672601927385804, False)
Robot's weighted accuracy = 0.48422897792186553
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.6392957949697738, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.515750796343525
robot yellow, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.5731128031988155, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5416085384496131
robot yellow, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.49878947043841715, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.49878947043841715
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.49878947043841715, False)
Robot's weighted accuracy = 0.6026416066795229
No need to update robot beliefs
robot red, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5141192966812248, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.5141192966812248
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5141192966812248, False)
Robot's weighted accuracy = 0.6026416066795229
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.514554235499832, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.514554235499832
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.514554235499832, False)
Robot's weighted accuracy = 0.6026416066795229
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, -0.9, 0.5), 0, 0.6026416066795229)
Robot's own rewards + human pref = [ 0.1 -1.  -0.4  1.5]
Robot's confidence = 0.6026416066795229
True human's confidence = 0.5146477309594116, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.5146477309594116
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5146477309594116, False)
Robot's weighted accuracy = 0.6026416066795229
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.5899933355274242, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, None, 0.0]
True human's accuracy on robot = 0.5899933355274242
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5899933355274242, False)
Robot's weighted accuracy = 0.6258675288189717
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.661258628881156, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.661258628881156
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.661258628881156, False)
Robot's weighted accuracy = 0.0
robot yellow, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.6479502239296784, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6479502239296784
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6479502239296784, False)
Robot's weighted accuracy = 0.4718072721551929
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6341652302833531, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6341652302833531
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6341652302833531, False)
Robot's weighted accuracy = 0.4718072721551929
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6341984340182215, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.6341984340182215
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6341984340182215, False)
Robot's weighted accuracy = 0.4718072721551929
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.4718072721551929)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.4718072721551929
True human's confidence = 0.6342065648145402, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.6342065648145402
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6342065648145402, False)
Robot's weighted accuracy = 0.4718072721551929
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.7017538471396373, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, None, 0.0]
True human's accuracy on robot = 0.7017538471396373
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7017538471396373, False)
Robot's weighted accuracy = 0.481088544515326
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.7615113407099484, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.7615113407099484
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7615113407099484, False)
Robot's weighted accuracy = 0.4774857105616115
robot yellow, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.7504274441816681, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.7504274441816681
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7504274441816681, False)
Robot's weighted accuracy = 0.6465922509099846
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.7389809231027645, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.7389809231027645
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7389809231027645, False)
Robot's weighted accuracy = 0.6465922509099846
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7389783521492445, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.7389783521492445
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7389783521492445, False)
Robot's weighted accuracy = 0.6465922509099846
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.6465922509099846)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.6465922509099846
True human's confidence = 0.7389790456309275, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.6465922509099846
robot green, human blue --> [1, 5, 2, 2]

Current state = [1, 5, 2, 2]
True human's confidence = 0.7389435456988194, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.6541451283163214
robot green, human blue --> [0, 4, 2, 2]

Current state = [0, 4, 2, 2]
True human's confidence = 0.738912154229773, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.738912154229773
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.738912154229773, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 4, 0, 2]

Current state = [0, 4, 0, 2]
True human's confidence = 0.7934393353237673, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human yellow --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.8305749188451756, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.3677917499465657
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8617804620414012, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8617804620414012
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8617804620414012, False)
Robot's weighted accuracy = 0.4654757748275075
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = -0.29999999999999993

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, 0.5, -0.9), 0, 0.4654757748275075)
Robot's own rewards + human pref = [ 0.1 -1.   1.   0.1]
Robot's confidence = 0.4654757748275075
True human's confidence = 0.8550080787957824, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.8550080787957824
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8550080787957824, False)
Robot's weighted accuracy = 0.4654757748275075
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.8888725578775106, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, None, 0.0]
True human's accuracy on robot = 0.8888725578775106
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8888725578775106, False)
Robot's weighted accuracy = 0.46867707744474174
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.9155920449284827, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.9155920449284827
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.9155920449284827, False)
Robot's weighted accuracy = 0.5753930048556365
robot yellow, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.9109875463766388, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9109875463766388
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.9109875463766388, False)
Robot's weighted accuracy = 0.6156829207071576
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.906027883614054, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.906027883614054
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.906027883614054, False)
Robot's weighted accuracy = 0.6156829207071576
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9060207523640648, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9060207523640648
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.9060207523640648, False)
Robot's weighted accuracy = 0.6156829207071576
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.5, 0.5, -0.9), 0, 0.6156829207071576)
Robot's own rewards + human pref = [ 0.1 -1.   1.   0.1]
Robot's confidence = 0.6156829207071576
True human's confidence = 0.9060207511125328, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.9060207511125328
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.9060207511125328, False)
Robot's weighted accuracy = 0.6156829207071576
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.928995024640538, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.6188988478130533
robot yellow, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.9060379021589124, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot yellow, human green --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8766288063809101, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5283303918205726
robot green, human green --> [0, 3, 1, 0]

Current state = [0, 3, 1, 0]
True human's confidence = 0.8475458050010171, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7120787237937755
robot green, human green --> [0, 1, 1, 0]

Current state = [0, 1, 1, 0]
True human's confidence = 0.8131219432337932, confidence scalar = 1.0
True human's acting weight vector = [None, None, 0.5, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7958539128909451
No need to update robot beliefs
robot green, human red --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.7958539128909451)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.7958539128909451
True human's confidence = 0.773006322295958, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7958539128909451
robot green, human blue --> [1, 5, 2, 2]

Current state = [1, 5, 2, 2]
True human's confidence = 0.772950954039008, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7970845782260692
robot green, human blue --> [0, 4, 2, 2]

Current state = [0, 4, 2, 2]
True human's confidence = 0.7728075346645114, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.7728075346645114
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7728075346645114, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 4, 0, 2]

Current state = [0, 4, 0, 2]
True human's confidence = 0.8219251091718515, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human yellow --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.8543665067624087, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5636225258210416
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8799334144700589, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8799334144700589
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8799334144700589, False)
Robot's weighted accuracy = 0.5689881315537697
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = -0.29999999999999993

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, 0.5, -0.9, -0.5), 0, 0.5689881315537697)
Robot's own rewards + human pref = [ 0.1  0.  -0.4  0.5]
Robot's confidence = 0.5689881315537697
True human's confidence = 0.8757677232555648, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5689881315537697
robot green, human blue --> [1, 5, 2, 2]

Current state = [1, 5, 2, 2]
True human's confidence = 0.8735778442621543, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.5693905341899302
robot green, human blue --> [0, 4, 2, 2]

Current state = [0, 4, 2, 2]
True human's confidence = 0.8660686605044476, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, 1.0, 0.5]
True human's accuracy on robot = 0.8660686605044476
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8660686605044476, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 4, 0, 2]

Current state = [0, 4, 0, 2]
True human's confidence = 0.8949456700565711, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human yellow --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.8856640957526376, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.7927111301084023
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8121268890398462, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8121268890398462
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.8121268890398462, False)
Robot's weighted accuracy = 0.8127932156222096
No need to update robot beliefs
robot yellow, human green --> [0, 0, 0, 0]
final_reward = -0.29999999999999993
