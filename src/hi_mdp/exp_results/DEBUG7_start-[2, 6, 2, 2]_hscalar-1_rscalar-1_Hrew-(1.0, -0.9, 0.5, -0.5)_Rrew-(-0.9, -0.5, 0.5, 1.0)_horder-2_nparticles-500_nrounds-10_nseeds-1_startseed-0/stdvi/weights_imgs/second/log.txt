
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.0, False)
Robot's weighted accuracy = 0.0
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, None, -0.5]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, -0.5]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 1.0, 0.5), 0.10500240700083806, False)
Robot's weighted accuracy = 0.127831402707426
robot yellow, human yellow --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.21000654452150003, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.3437165464086288, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.4492923398595858, False)
Robot's weighted accuracy = 0.22654736337775072
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = -0.6999999999999997

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.22654736337775072)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.22654736337775072
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.4807051540272881, False)
Robot's weighted accuracy = 0.22654736337775072
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, None, 0.0]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5413770316245776, False)
Robot's weighted accuracy = 0.2796704140798031
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, -1.0]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.5884064503069079, False)
Robot's weighted accuracy = 0.348660016116845
robot yellow, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.679392939475177, False)
Robot's weighted accuracy = 0.5109777598792835
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6973305740283456, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6973305740283456
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.6973305740283456, False)
Robot's weighted accuracy = 0.5109777598792835
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.7182595441686002, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.7182595441686002
True human's belief of robot = ((-0.9, -0.5, 1.0, 0.5), 0.7182595441686002, False)
Robot's weighted accuracy = 0.5109777598792835
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036
