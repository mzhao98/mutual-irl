
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, None]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, 0.5, None]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.11327368168887536)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.11327368168887536
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.11327368168887536
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.12415027422637664
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.15864689755195557
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2455927251767097)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2455927251767097
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.2455927251767097
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.7472208884492556
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7472208884492556, False)
Robot's weighted accuracy = 0.26139296836891657
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7869952504818568, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.7869952504818568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7869952504818568, False)
Robot's weighted accuracy = 0.3329550827668498
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273282, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8214225257273282
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8214225257273282, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8216590931070864, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8217097224033024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8217097224033024, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.3544734171612952)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.3544734171612952
True human's confidence = 0.821719605437636, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.821719605437636
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.821719605437636, False)
Robot's weighted accuracy = 0.3544734171612952
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8576496009580737, False)
Robot's weighted accuracy = 0.3697238979507007
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603414, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.8861823382603414
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8861823382603414, False)
Robot's weighted accuracy = 0.4524046838665382
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948706087917568, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.894867546234916, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.894867546234916
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.894867546234916, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602975, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8948678929602975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948678929602975, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4500609082716315)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.4500609082716315
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8948676789039607
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948676789039607, False)
Robot's weighted accuracy = 0.4500609082716315
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9188500665403389, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9188500665403389
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9188500665403389, False)
Robot's weighted accuracy = 0.4624447823105862
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9373563415651059, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9373563415651059
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9373563415651059, False)
Robot's weighted accuracy = 0.5449018952400122
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9383457033307511, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383457033307511
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383457033307511, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9383392698173356, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383392698173356
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383392698173356, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9383391665376024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9383391665376024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383391665376024, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5364606038492142)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.5364606038492142
True human's confidence = 0.9383390559555314, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5364606038492142
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.9198774313773606, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5527228322585919
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.8947635572800908, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.4844437780668945
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.8691774674434641, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.8383839198911353, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8016504813376075, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.016009781388751167
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9206265180718907)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9206265180718907
True human's confidence = 0.7581905561119087, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.7581905561119087
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7581905561119087, False)
Robot's weighted accuracy = 0.016009781388751167
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8087918963472513, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8087918963472513
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8087918963472513, False)
Robot's weighted accuracy = 0.015067163002141566
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8505974865316012, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.013683350348313798
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8673892025989195, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.011057436942046545
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8520806234956934, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8520806234956934
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8520806234956934, False)
Robot's weighted accuracy = 0.009790104557655398
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8521001512844356, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8521001512844356
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8521001512844356, False)
Robot's weighted accuracy = 0.009790104557655398
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9462885121954525)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9462885121954525
True human's confidence = 0.8520968104697019, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8520968104697019
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8520968104697019, False)
Robot's weighted accuracy = 0.009790104557655398
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8728647243080279, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8728647243080279
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8728647243080279, False)
Robot's weighted accuracy = 0.00916516257502398
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8888217939546766, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.008283690737342914
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7785484891871439, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.007518722832649753
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5330264478012141, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.5330264478012141
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330264478012141, False)
Robot's weighted accuracy = 0.008320798097660616
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5330189793055785, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.5330189793055785
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330189793055785, False)
Robot's weighted accuracy = 0.008320798097660616
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9620155209781155)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9620155209781155
True human's confidence = 0.5330031561046968, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.5330031561046968
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330031561046968, False)
Robot's weighted accuracy = 0.008320798097660616
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5367109601883775, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.5367109601883775
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5367109601883775, False)
Robot's weighted accuracy = 0.0077640777743463495
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5394740760432081, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.007764285029240744
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7348699483604284, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.7348699483604284
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7348699483604284, False)
Robot's weighted accuracy = 0.007831964751107317
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9003582373439677, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, None]
True human's accuracy on robot = 0.9003582373439677
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003582373439677, False)
Robot's weighted accuracy = 0.007898403291404805
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9003663398968651, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9003663398968651
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003663398968651, False)
Robot's weighted accuracy = 0.007898403291404805
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9736149562292082)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9736149562292082
True human's confidence = 0.9003716266358951, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9003716266358951
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003716266358951, False)
Robot's weighted accuracy = 0.007898403291404805
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9029309700601413, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9029309700601413
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9029309700601413, False)
Robot's weighted accuracy = 0.007352910852731397
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9048227878091227, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.9048227878091227
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9048227878091227, False)
Robot's weighted accuracy = 0.0073375475387223105
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9665777741808735, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.9665777741808735
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9665777741808735, False)
Robot's weighted accuracy = 0.007398984564970012
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.985499859842575, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, None]
True human's accuracy on robot = 0.985499859842575
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.985499859842575, False)
Robot's weighted accuracy = 0.0074598356849295555
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9855012448378531, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9855012448378531
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9855012448378531, False)
Robot's weighted accuracy = 0.0074598356849295555
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 0, 0.020833333333333332)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.020833333333333332
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, None]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.04207920792079207
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, 0.5, None]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.06391570135371298
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.11327368168887536
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.11327368168887536)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.11327368168887536
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.11327368168887536
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.14504685503675685
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.2455927251767097
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.2455927251767097)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.2455927251767097
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.2455927251767097
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.7472208884492556
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7472208884492556, False)
Robot's weighted accuracy = 0.26139296836891657
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.7869952504818568, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.7869952504818568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7869952504818568, False)
Robot's weighted accuracy = 0.3329550827668498
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8214225257273282, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8214225257273282
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8214225257273282, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8216590931070864, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8216590931070864
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8216590931070864, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8217097224033024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8217097224033024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8217097224033024, False)
Robot's weighted accuracy = 0.3544734171612952
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.3544734171612952)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.3544734171612952
True human's confidence = 0.821719605437636, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.821719605437636
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.821719605437636, False)
Robot's weighted accuracy = 0.3544734171612952
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8576496009580737, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8576496009580737
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8576496009580737, False)
Robot's weighted accuracy = 0.3697238979507007
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8861823382603414, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.8861823382603414
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8861823382603414, False)
Robot's weighted accuracy = 0.4524046838665382
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8948706087917568, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8948706087917568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948706087917568, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.894867546234916, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.894867546234916
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.894867546234916, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8948678929602975, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8948678929602975
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948678929602975, False)
Robot's weighted accuracy = 0.4500609082716315
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.4500609082716315)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.4500609082716315
True human's confidence = 0.8948676789039607, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8948676789039607
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8948676789039607, False)
Robot's weighted accuracy = 0.4500609082716315
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9188500665403389, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9188500665403389
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9188500665403389, False)
Robot's weighted accuracy = 0.4624447823105862
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9373563415651059, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.9373563415651059
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9373563415651059, False)
Robot's weighted accuracy = 0.5449018952400122
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9383457033307511, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383457033307511
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383457033307511, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9383392698173356, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.9383392698173356
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383392698173356, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9383391665376024, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9383391665376024
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9383391665376024, False)
Robot's weighted accuracy = 0.5364606038492142
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, -0.5, 0.5), 0, 0.5364606038492142)
Robot's own rewards + human pref = [ 0.1 -1.4  0.   1.5]
Robot's confidence = 0.5364606038492142
True human's confidence = 0.9383390559555314, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5364606038492142
robot red, human blue --> [1, 6, 1, 2]

Current state = [1, 6, 1, 2]
True human's confidence = 0.9198774313773606, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5527228322585919
robot red, human blue --> [0, 6, 0, 2]

Current state = [0, 6, 0, 2]
True human's confidence = 0.8947635572800908, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, 0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.4844437780668945
robot green, human yellow --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.8691774674434641, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.0
robot green, human green --> [0, 3, 0, 1]

Current state = [0, 3, 0, 1]
True human's confidence = 0.8383839198911353, confidence scalar = 1.0
True human's acting weight vector = [None, 0.09999999999999998, None, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.7941361415322059
robot green, human green --> [0, 1, 0, 1]

Current state = [0, 1, 0, 1]
True human's confidence = 0.8016504813376075, confidence scalar = 1.0
True human's acting weight vector = [None, None, None, -0.5]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.9206265180718907
No need to update robot beliefs
robot green, human yellow --> [0, 0, 0, 0]
final_reward = -1.7999999999999998

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9206265180718907)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9206265180718907
True human's confidence = 0.7581905561119087, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.7581905561119087
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.7581905561119087, False)
Robot's weighted accuracy = 0.9206265180718907
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8087918963472513, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8087918963472513
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8087918963472513, False)
Robot's weighted accuracy = 0.934376868848611
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8505974865316012, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.9452719334470685
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.8673892025989195, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.9476568170088325
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8520806234956934, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.8520806234956934
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8520806234956934, False)
Robot's weighted accuracy = 0.9462885121954525
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8521001512844356, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.8521001512844356
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8521001512844356, False)
Robot's weighted accuracy = 0.9462885121954525
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9462885121954525)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9462885121954525
True human's confidence = 0.8520968104697019, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8520968104697019
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8520968104697019, False)
Robot's weighted accuracy = 0.9462885121954525
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.8728647243080279, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.8728647243080279
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8728647243080279, False)
Robot's weighted accuracy = 0.9553641144844955
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8888217939546766, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.9618920875141219
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7785484891871439, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 0.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.963455289064259
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.5330264478012141, confidence scalar = 1.0
True human's acting weight vector = [None, -1.4, None, None]
True human's accuracy on robot = 0.5330264478012141
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330264478012141, False)
Robot's weighted accuracy = 0.9620155209781155
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.5330189793055785, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.5330189793055785
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330189793055785, False)
Robot's weighted accuracy = 0.9620155209781155
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9620155209781155)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9620155209781155
True human's confidence = 0.5330031561046968, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.5330031561046968
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5330031561046968, False)
Robot's weighted accuracy = 0.9620155209781155
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5367109601883775, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.5367109601883775
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5367109601883775, False)
Robot's weighted accuracy = 0.9680537806391192
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5394740760432081, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.9716387381989738
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.7348699483604284, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.7348699483604284
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.7348699483604284, False)
Robot's weighted accuracy = 0.9727390835365319
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9003582373439677, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, None]
True human's accuracy on robot = 0.9003582373439677
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003582373439677, False)
Robot's weighted accuracy = 0.9736149562292082
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9003663398968651, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9003663398968651
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003663398968651, False)
Robot's weighted accuracy = 0.9736149562292082
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9736149562292082)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9736149562292082
True human's confidence = 0.9003716266358951, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9003716266358951
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9003716266358951, False)
Robot's weighted accuracy = 0.9736149562292082
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9029309700601413, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, None]
True human's accuracy on robot = 0.9029309700601413
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9029309700601413, False)
Robot's weighted accuracy = 0.9774616917048394
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9048227878091227, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.9048227878091227
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9048227878091227, False)
Robot's weighted accuracy = 0.9790054649638806
robot green, human red --> [0, 5, 1, 0]

Current state = [0, 5, 1, 0]
True human's confidence = 0.9665777741808735, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, 1.0, None]
True human's accuracy on robot = 0.9665777741808735
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9665777741808735, False)
Robot's weighted accuracy = 0.9797800668618546
robot green, human red --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.985499859842575, confidence scalar = 1.0
True human's acting weight vector = [None, -0.4, None, None]
True human's accuracy on robot = 0.985499859842575
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.985499859842575, False)
Robot's weighted accuracy = 0.9804106722995621
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9855012448378531, confidence scalar = 1.0
True human's acting weight vector = [None, -0.9, None, None]
True human's accuracy on robot = 0.9855012448378531
True human's belief of robot = ((-0.9, 0.5, -0.5, 1.0), 0.9855012448378531, False)
Robot's weighted accuracy = 0.9804106722995621
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 1.2000000000000002
