
ROUND = 0


Current state = [2, 6, 2, 2]
Robot's top human model = ((-0.9, -0.5, 0.5, 1.0), 1, 0.041666666666666664)
Robot's own rewards + human pref = [-1.8 -1.   1.   2. ]
Robot's confidence = 0.041666666666666664
True human's confidence = 0.041666666666666664, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.041666666666666664
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.041666666666666664, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.085584540188054, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -100]
True human's accuracy on robot = 0.085584540188054
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.085584540188054, False)
Robot's weighted accuracy = 0.08415841584158416
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.10500240700083806, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, 0.5, -100]
True human's accuracy on robot = 0.10500240700083806
True human's belief of robot = ((-0.5, -0.9, 0.5, 1.0), 0.10500240700083806, False)
Robot's weighted accuracy = 0.0
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.21000654452150003, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.21000654452150003
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.21000654452150003, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.3437165464086288, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.3437165464086288
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.3437165464086288, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.4492923398595858, confidence scalar = 0.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.4492923398595858
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4492923398595858, False)
Robot's weighted accuracy = 0.292238297014615
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 1


Current state = [2, 6, 2, 2]
Robot's top human model = ((0.5, -0.9, 1.0, -0.5), 1, 0.292238297014615)
Robot's own rewards + human pref = [-0.4 -1.4  1.5  0.5]
Robot's confidence = 0.292238297014615
True human's confidence = 0.4807051540272881, confidence scalar = 0.0
True human's acting weight vector = [1.0, -0.9, 0.5, -0.5]
True human's accuracy on robot = 0.4807051540272881
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.4807051540272881, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.5413770316245776, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.5413770316245776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5413770316245776, False)
Robot's weighted accuracy = 0.0
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.5884064503069079, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.5884064503069079
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.5884064503069079, False)
Robot's weighted accuracy = 0.26806260663795894
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.679392939475177, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.679392939475177
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.679392939475177, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6947308595183347, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6947308595183347
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6947308595183347, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6980829022075373, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6980829022075373
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6980829022075373, False)
Robot's weighted accuracy = 0.3734290603858591
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 2


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.3734290603858591)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.3734290603858591
True human's confidence = 0.6987978089480568, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6987978089480568
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6987978089480568, False)
Robot's weighted accuracy = 0.3734290603858591
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.7472208884492556, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.448376931105453
robot red, human blue --> [0, 6, 1, 1]

Current state = [0, 6, 1, 1]
True human's confidence = 0.7354725378756957, confidence scalar = 1.0
True human's acting weight vector = [-100, 0.09999999999999998, -100, -1.0]
True human's accuracy on robot = 0.0
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.0, False)
Robot's weighted accuracy = 0.5211958970642625
robot red, human green --> [0, 5, 0, 1]

Current state = [0, 5, 0, 1]
True human's confidence = 0.6850856199947247, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6850856199947247
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6850856199947247, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot yellow, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.6990671485886669, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.6990671485886669
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6990671485886669, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.6991857432841315, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.6991857432841315
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6991857432841315, False)
Robot's weighted accuracy = 0.5249337765793578
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.40000000000000036

ROUND = 3


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.5249337765793578)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.5249337765793578
True human's confidence = 0.6992120320252431, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.6992120320252431
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.6992120320252431, False)
Robot's weighted accuracy = 0.5249337765793578
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.75865431871843, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.75865431871843
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.75865431871843, False)
Robot's weighted accuracy = 0.5942508763576115
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8093124528282366, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.8093124528282366
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8093124528282366, False)
Robot's weighted accuracy = 0.6480443593486472
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8022856498674722, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8022856498674722
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8022856498674722, False)
Robot's weighted accuracy = 0.6743241151161714
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8022884283173412, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8022884283173412
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8022884283173412, False)
Robot's weighted accuracy = 0.6743241151161714
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8022901362352867, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8022901362352867
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8022901362352867, False)
Robot's weighted accuracy = 0.6743241151161714
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 4


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.6743241151161714)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.6743241151161714
True human's confidence = 0.802290453012042, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.802290453012042
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.802290453012042, False)
Robot's weighted accuracy = 0.6743241151161714
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.846078458814676, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.846078458814676
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.846078458814676, False)
Robot's weighted accuracy = 0.7365256783352294
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.8815252064990564, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.8815252064990564
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8815252064990564, False)
Robot's weighted accuracy = 0.7892308298411828
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.8758939378606022, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8758939378606022
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8758939378606022, False)
Robot's weighted accuracy = 0.7854316219550541
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.8758880688835915, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.8758880688835915
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8758880688835915, False)
Robot's weighted accuracy = 0.7854316219550541
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.8758880732230844, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.8758880732230844
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8758880732230844, False)
Robot's weighted accuracy = 0.7854316219550541
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 5


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.7854316219550541)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.7854316219550541
True human's confidence = 0.8758880587139404, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.8758880587139404
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.8758880587139404, False)
Robot's weighted accuracy = 0.7854316219550541
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.905383243607258, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.905383243607258
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.905383243607258, False)
Robot's weighted accuracy = 0.8318555940496253
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9284164433180067, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.9284164433180067
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9284164433180067, False)
Robot's weighted accuracy = 0.870802558208544
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9245598854443633, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9245598854443633
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9245598854443633, False)
Robot's weighted accuracy = 0.8638473661351472
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9245535938959388, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9245535938959388
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9245535938959388, False)
Robot's weighted accuracy = 0.8638473661351472
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9245535879731216, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9245535879731216
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9245535879731216, False)
Robot's weighted accuracy = 0.8638473661351472
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 6


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.8638473661351472)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.8638473661351472
True human's confidence = 0.9245535818640491, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9245535818640491
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9245535818640491, False)
Robot's weighted accuracy = 0.8638473661351472
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.943260274471716, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.943260274471716
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.943260274471716, False)
Robot's weighted accuracy = 0.895304375049299
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9575322911178151, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.9575322911178151
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9575322911178151, False)
Robot's weighted accuracy = 0.9213037015058559
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9550890814507222, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9550890814507222
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9550890814507222, False)
Robot's weighted accuracy = 0.9158102268546641
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9550825900635136, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9550825900635136
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9550825900635136, False)
Robot's weighted accuracy = 0.9158102268546641
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9550825881282703, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9550825881282703
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9550825881282703, False)
Robot's weighted accuracy = 0.9158102268546641
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 7


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9158102268546641)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9158102268546641
True human's confidence = 0.9550825862546044, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9550825862546044
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9550825862546044, False)
Robot's weighted accuracy = 0.9158102268546641
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9665034117938786, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9665034117938786
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9665034117938786, False)
Robot's weighted accuracy = 0.9359419927402466
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9750914658365025, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.9750914658365025
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9750914658365025, False)
Robot's weighted accuracy = 0.9524495985309004
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9736068478843118, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9736068478843118
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9736068478843118, False)
Robot's weighted accuracy = 0.9487324622350211
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9736002351950579, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9736002351950579
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9736002351950579, False)
Robot's weighted accuracy = 0.9487324622350211
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9736002345734776, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9736002345734776
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9736002345734776, False)
Robot's weighted accuracy = 0.9487324622350211
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 8


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9487324622350211)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9487324622350211
True human's confidence = 0.9736002340179467, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9736002340179467
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9736002340179467, False)
Robot's weighted accuracy = 0.9487324622350211
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9804132473537446, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9804132473537446
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9804132473537446, False)
Robot's weighted accuracy = 0.961197284858758
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.9854910460627576, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.9854910460627576
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9854910460627576, False)
Robot's weighted accuracy = 0.9714006213952474
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9846092234849286, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9846092234849286
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9846092234849286, False)
Robot's weighted accuracy = 0.9690297039584054
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9846025384541512, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9846025384541512
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9846025384541512, False)
Robot's weighted accuracy = 0.9690297039584054
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9846025382250788, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9846025382250788
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9846025382250788, False)
Robot's weighted accuracy = 0.9690297039584054
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003

ROUND = 9


Current state = [2, 6, 2, 2]
Robot's top human model = ((1.0, -0.9, 0.5, -0.5), 1, 0.9690297039584054)
Robot's own rewards + human pref = [ 0.1 -1.4  1.   0.5]
Robot's confidence = 0.9690297039584054
True human's confidence = 0.9846025380628495, confidence scalar = 1.0
True human's acting weight vector = [2.0, 0.09999999999999998, 1.5, 0.0]
True human's accuracy on robot = 0.9846025380628495
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9846025380628495, False)
Robot's weighted accuracy = 0.9690297039584054
robot yellow, human blue --> [1, 6, 2, 1]

Current state = [1, 6, 2, 1]
True human's confidence = 0.9886117638748714, confidence scalar = 1.0
True human's acting weight vector = [1.5, -0.4, 1.0, -100]
True human's accuracy on robot = 0.9886117638748714
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9886117638748714, False)
Robot's weighted accuracy = 0.9766093145099936
robot yellow, human blue --> [0, 6, 2, 0]

Current state = [0, 6, 2, 0]
True human's confidence = 0.991583225201379, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.4, 0.0, -100]
True human's accuracy on robot = 0.991583225201379
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.991583225201379, False)
Robot's weighted accuracy = 0.9828271173673431
robot red, human red --> [0, 6, 0, 0]

Current state = [0, 6, 0, 0]
True human's confidence = 0.9910658729644551, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9910658729644551
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9910658729644551, False)
Robot's weighted accuracy = 0.9813566558659174
No need to update robot beliefs
robot green, human green --> [0, 4, 0, 0]

Current state = [0, 4, 0, 0]
True human's confidence = 0.9910591454008758, confidence scalar = 1.0
True human's acting weight vector = [-100, -1.4, -100, -100]
True human's accuracy on robot = 0.9910591454008758
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9910591454008758, False)
Robot's weighted accuracy = 0.9813566558659174
No need to update robot beliefs
robot green, human green --> [0, 2, 0, 0]

Current state = [0, 2, 0, 0]
True human's confidence = 0.9910591452866433, confidence scalar = 1.0
True human's acting weight vector = [-100, -0.9, -100, -100]
True human's accuracy on robot = 0.9910591452866433
True human's belief of robot = ((-0.9, -0.5, 0.5, 1.0), 0.9910591452866433, False)
Robot's weighted accuracy = 0.9813566558659174
No need to update robot beliefs
robot green, human green --> [0, 0, 0, 0]
final_reward = 0.8000000000000003
